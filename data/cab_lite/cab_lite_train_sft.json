[
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a room with a whiteboard and a table, engaged in a discussion or presentation, with diagrams and notes on the whiteboard and a notebook and pen on the table.\"\nPersona Context: \n\n",
    "output": "<think>The user is actively engaged in a virtual meeting, which requires full attention and participation. Proactive intervention could be distracting and not beneficial at this moment.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, standing near a calm, greenish river surrounded by lush vegetation, observing the natural surroundings.\"\nPersona Context: \nThe user likes relaxing music to unwind in peaceful settings.\n",
    "output": "<think>The user is in a peaceful setting by the lake, which is a perfect opportunity to enjoy some relaxing music. Since the user likes to unwind with music, it would be beneficial to suggest playing a calming playlist.\n Actions:\n[\"Use <play_music> to play a relaxing playlist to enhance the user's experience by the lake.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a room with a wooden floor, looking at a suitcase containing a red hoodie and a folded blanket with the word 'MARS' on it. The schedule indicates that the user is about to leave for Irvine, USA.\"\nPersona Context: \n\n",
    "output": "<think>The contextual information indicates that the user is packing a suitcase with winter clothes, such as down jackets or cotton coats. Additionally, the agenda reveals that the user is about to leave for Irvine, USA. When visiting other places, it is important to first check the local weather and temperature. I should use <get_city_weather> to check the weather in Irvine, USA, and provide the user with the latest weather forecast.\n Actions:\n[\"Use <get_city_weather> to check the latest weather forecast for both the user's current location and their destination.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Irvine, USA\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in an electronics store browsing a display of Sony headphones, including various models such as the LinkBuds series and Best-in-class Noise Cancelling headphones, with prices from $98 to $1,649.\nPersona Context: \nThe user is a music enthusiast who values sound quality and comfort in headphones.\n",
    "output": "<think>The user might be interested in reviews or feature comparisons of the headphones. I should use <vllm> to identify the models and <google_search> to find reviews or feature comparisons.\n Actions:\n['Use <vllm> to identify the headphone models the user is comparing.', 'Use <google_search> to find reviews or feature comparisons for the identified models.', 'Use <get_online_product_price> to check the price of the headphones online.', 'Use <search_rednote> to find user reviews and recommendations for the headphones.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can identify electronic devices based on the given image.\", \"parameters\": {\"prompt\": \"Identify the headphone models the user is comparing.\", \"image_path\": \"\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"reviews or feature comparisons for headphones\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"headphones\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"headphones reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is walking on a red brick sidewalk alongside a road, bordered by a yellow and green chain barrier, with trees and a building visible in the background. The user appears to be moving forward and observing the surroundings.\nPersona Context: \n\n",
    "output": "<think>Contextual information shows user is walking on the sidewalk of a road that appears to be going downhill, with an intersection ahead. There are many bushes on both sides of the road. Without explicit input or additional contextual information, no proactive actions are required. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an electronics store, looking at various air purifiers and dehumidifiers on display and comparing their features and prices.\"\nPersona Context: \nThe user is a tech-savvy individual interested in smart home automation.\n",
    "output": "<think>The user might benefit from comparisons of different smart home devices and their features. I should use <vllm> to identify the devices and <google_search> to find reviews or comparisons.\n Actions:\n['Use <vllm> to identify the smart home devices the user is looking at.', 'Use <google_search> to find reviews or feature comparisons of the identified devices.', 'Use <get_online_product_price> to check the price of the smart home devices online.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can identify smart home devices based on the given image.\", \"parameters\": {\"prompt\": \"Identify the smart home devices the user is looking at.\", \"image_path\": \"\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"reviews or feature comparisons of smart home devices\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smart home devices\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a garden filled with vibrant tulips, including yellow, red, and pink varieties, all in full bloom with lush green leaves, indicating a well-maintained setting with vivid colors.\"\nPersona Context: \n\n",
    "output": "<think>The user is likely enjoying the beauty and tranquility of the botanical garden. There is no indication of a need for assistance, as they seem to be appreciating the moment. Proactive intervention would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is at a bus stop at night, waiting for a bus, with several people in line. A bus with the number '67K' is approaching, and the area is well-lit with buildings in the background.\"\nPersona Context: \n\n",
    "output": "<think>According to the contextual information, the user is at the bus stop and may be waiting for the next bus. Providing real-time bus schedule updates could be helpful. I need to check the user's location and the current time, and then provide the bus schedule using <check_bus_schedule> tool. If it is too late, I can assist the user in calling an Uber or taxi and ask if they need that service..\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to check the current time.', 'Use <check_bus_schedule> to look up the next bus arrival times at the current bus stop.', 'If the bus schedule is not suitable, use <book_uber> to suggest alternative transportation.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in an office setting, sitting in front of a desk with a computer monitor displaying financial charts and data, likely related to stock market analysis, and engaged in analyzing the financial information. The user's agenda indicates a presentation of quarterly results to the board next Monday.\"\nPersona Context: \nThe user is a financial manager responsible for preparing financial presentations.\n",
    "output": "<think>The user needs to ensure the presentation is ready and includes all necessary financial data. I should check their calendar for any conflicts and suggest dedicating time to prepare the presentation.\n Actions:\n['Use <get_current_datetime> to obtain the current date and identify next Monday.', 'Use <check_agenda_time_conflict> to check for any scheduling conflicts on next Monday.', 'If free, suggest blocking time to prepare the presentation and ensure all data is included.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Monday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare for quarterly results presentation\", \"time\": \"next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, looking at various HONOR smartphones displayed on a shelf, with price tags and promotional signs providing details about the models and their prices.\nPersona Context: \n\n",
    "output": "<think>It seems that the user is comparing two smartphone models in an electronics store, potentially interested in camera quality based on the overheard sales representative's comment. I can use <get_online_product_price> to search the online prices for both models and use <search_rednote> to provide detailed feature comparisons to help the user make an informed decision.\n Actions:\n['Use <get_online_product_price> to compare online prices for both smartphone models.', 'Use <search_rednote> to search for comments of Model X and Model Y.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"smartphone models\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"feature comparison of Model X and Model Y smartphones\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a restaurant, seated at a table with a plate of noodles and vegetables in front of them. The user is wearing a white hoodie and a smartwatch. The content of conversation is: \"Have you watched the new superhero movie that just came out?\"\nPersona Context: \nThe user is not frequently watching movies.\n",
    "output": "<think>Contextual information shows the user is having a conversation with others. The partner asks the user whether they have watched the new superhero movie that just came out. Since the user's persona shows he is not frequently watching movies,p roactively providing information about the movie, such as its showtimes or reviews, could enhance the conversation. I can use <google_search> to look up details about the new superhero movie, including showtimes and reviews.\n Actions:\n['Use <google_search> to look up details about the new superhero movie, including reviews and showtimes.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new superhero movie showtimes and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a kitchen, boiling pasta in a large pot on a stove, using tongs to stir it, in a modern kitchen with white countertops and a white backsplash.\nPersona Context: \n\n",
    "output": "<think>The user is boiling pasta, a simple task that does not require any proactive assistance. The process appears to be under control.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user walking along a cobblestone path in a park, surrounded by greenery, benches, and red flowers, with a stone wall and a yellow barrier marking the path's sides.\"\nPersona Context: \nThe user enjoys listening to energetic music while exercising.\n",
    "output": "<think>The user is jogging, which is an activity that could be enhanced with music. Given the user's preference for listening to energetic music while exercising, it would be beneficial to play an upbeat playlist to motivate them.\n Actions:\n['Use <play_music> to play an energetic playlist to motivate the user during their jog.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a room with a whiteboard, writing tasks for the week with a marker, suggesting they are organizing their schedule or to-do list.\"\nPersona Context: \nResearcher\n",
    "output": "<think>The user is working from a home office. The presence of books and a whiteboard suggests they are engaged in planning or research activities. But without other cues, there is no need for proactive assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is in a room, possibly a workshop or craft area, surrounded by beads and jewelry-making tools, holding and adjusting a bracelet made of colorful beads on their wrist, with a wooden box filled with more beads and jewelry pieces visible in the background.\nPersona Context: \nThe user appreciates handcrafted items and unique designs.\n",
    "output": "<think>The user might be interested in learning more about the jewelry or finding similar items online. Offering information on similar products or the artist's details could be valuable.\n Actions:\n['Use <google_search> to find more information about the artist or similar handmade jewelry available online.', 'Use <wikipedia_search> to provide background information on the craft fair or the type of jewelry.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"handmade jewelry artist information\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"craft fair\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a gym, standing in front of a rowing machine with a view of an outdoor soccer field through a large window.\"\nPersona Context: \nThe user prefers listening to upbeat music while working out to maintain high energy levels.\n",
    "output": "<think>The user is about to start a workout on the rowing machine. Based on their preference for upbeat music during exercise, I should suggest playing a motivational playlist to keep their energy levels high.\n Actions:\n[\"Use <play_music> to play an upbeat workout playlist to enhance the user's rowing session.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is sitting on a bed with a laptop open on their lap, typing on the keyboard, with a pen placed on the screen. The laptop screen displays a webpage with text and a button. The user is wearing white pants and has a white bracelet on their wrist, and the room has a textured rug under the bed.\"\nPersona Context: \n\n",
    "output": "<think>The user is engaged in a routine task of managing emails, which is a typical part of his workday. There is no indication of a need for assistance or intervention. Proactive engagement might disrupt their workflow.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, sitting on a bench near a large tree, with neatly trimmed bushes and a stone path nearby. The content of conversation is: \\\"I heard there is a Great Jays concert happening downtown this Saturday. Do you know anything about it?\\\"\"\nPersona Context: \n\n",
    "output": "<think>Contexual information shows the user is engaging in a conversation with a friend. Since the user's friend is asking about an event, they might want to check details such as time, location, and ticket availability. Proactively providing this information would be useful and enhance the conversation. So I can use <google_search> to look up details about the jazz concert happening downtown this Saturday.\n Actions:\n['Use <google_search> to look up details about the jazz concert happening downtown this Saturday, including location, time, and ticket information.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"jazz concert downtown this Saturday.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a shopping mall, looking at a store display with a mannequin wearing a red shirt, and the store appears to sell health and wellness products. The user is wearing a backpack and is in motion, likely exploring the mall. The content of conversation is: \"I want to buy a new watch. Do you know where the best watch stores around here?\"\nPersona Context: \n\n",
    "output": "<think>The contextual information shows the user is shopping with a friend and they are having a conversation. According to the content of the conversation, the friend is looking for watch stores nearby. So I should proactively help user by giving him some suggestions. I can use <get_current_gps_coordinates> to determine the user's current location, <get_current_datetime> to get the current date and time, <google_map> to find and list nearby watch stores that sell watch, and <google_search> to find and list nearby watch stores that sell watch, and check their opening hours.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to get the current date and time.', 'Use <google_map> to find and list nearby watch stores that sell watch.', 'Use <google_search> to find and list nearby watch stores that sell watch, and check their opening hours ites.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"watch stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"watch stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a McDonald's restaurant, browsing through the digital menu on a touch-screen kiosk, and pointing at the screen to make a selection.\"\nPersona Context: \nThe user is trying to balance fast food convenience with healthier eating options.\n",
    "output": "<think>The user could benefit from detailed calorie counts and health-related information about fast food items. Offering healthier alternatives or portion control tips could help them make better choices.\n Actions:\n['Use <wikipedia_search> to find calorie counts and heating information for a double cheeseburger, large fries, and a milkshake.', 'Use <get_medical_knowledge> to provide health-related advice for fast food options.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for double cheeseburger, large fries, and milkshake\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for double cheeseburger, large fries, and milkshake\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a clothing store, looking at a display of T-shirts in various colors, with a price tag of $9.99. The mobile agenda shows a meeting in 2 hours at Central Plaza.\nPersona Context: \n\n",
    "output": "<think>The user is currently shopping but has a meeting soon. I can assist by checking the travel time to the meeting location. Using <get_current_gps_coordinates>, I can determine the current location and then use <google_map> to estimate the travel time. If needed, I can also suggest a taxi via <book_uber> to ensure the user arrives on time.\n Actions:\n[\"Use <get_current_gps_coordinates> to check the user's current location.\", 'Use <google_map> to estimate travel time to Central Plaza.', 'Offer to book an Uber if time is tight.', 'Ask the user if they need assistance.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Get the route and travel time from the current location to the destination.\", \"parameters\": {\"current_location\":\"Shopping Mall\", \"destination\":\"Central Plaza\"}},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Shopping Mall\", \"destination\":\"Central Plaza\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a bustling city street at night, surrounded by pedestrians and illuminated storefronts, observing the lively street scene with seating areas and greenery, possibly considering dining or shopping options.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a leisurely moment at a caf\u00e9, likely appreciating the ambiance and people-watching. There is no immediate need for assistance, and proactive engagement would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is holding a hose and spraying water onto a green lawn, actively engaged in watering the grass.\nPersona Context: \nThe user is new to gardening and does not water plants regularly.\n",
    "output": "<think>Since the personas shows the user is new to gardening and does not water plants regularly, the user might be interested in gardening tips or plant care information. They could benefit from advice on how to care for their plants. I can use <search_rednote> to search for tips on planting and watering flowers.\n Actions:\n['Use <search_rednote> to search for tips on planting and watering flowers.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Tips for planting and watering flowers\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting at an outdoor caf\u00e9 table on a sunny day, holding a coffee cup, wearing a black t-shirt with red lips printed on it, and a necklace with two chains. Another person's hand is visible, suggesting company.\nPersona Context: \nSociable\n",
    "output": "<think>The user is engaged in a social interaction, which they likely enjoy given their sociable persona. Proactive assistance is unnecessary, as it might interrupt their conversation and enjoyment.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a room with a wooden floor, looking down at a suitcase filled with clothes, including a green and black plaid shirt, a gray shirt, gray pants, and blue jeans, with their feet in red and white sneakers on top of the clothes. The agenda indicates that the user is departing for Japan.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows The user is preparing to travel to Japan. It's crucial to check the local weather conditions in the destination to ensure they are packing appropriately. I should use the <get_city_weather> tool to get the latest updates for Japan. To provide the weather forecast for the user's current location, I can use the <get_current_gps_coordinates> tool.\n Actions:\n[\"Use <get_current_gps_coordinates> to check the user's current location.\", \"Use <get_city_weather> to check the latest weather forecast for both the user's current location and their destination.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Japan\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a library or bookstore, browsing through a row of books on a shelf with a focus on selecting a specific book.\"\nPersona Context: \n\n",
    "output": "<think>The user is exploring book options in a bookstore, which is a leisurely activity. There is no need for proactive assistance, as they seem to be enjoying browsing.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an art gallery, observing various paintings, including a prominent painting of two women in different colored dresses, along with a wooden bench and a small table displaying metal pitchers and other items.\"\nPersona Context: \nArt enthusiast\n",
    "output": "<think>The user may appreciate learning more about the painting or the Impressionist movement. Providing historical context or artist information could enhance their experience.\n Actions:\n['Use <wikipedia_search> to find information about Impressionism and the artist of the painting.', 'Provide insights into the historical context and significance of the painting.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Impressionism and artist information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an office environment, sitting in front of a laptop displaying a code editor with multiple lines of programming code.\"\nPersona Context: \n\n",
    "output": "<think>The user is deeply engaged in coding, an activity that requires high concentration. There is no indication of a need for assistance, and proactive engagement might interrupt their workflow.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a tent, sitting on a wooden platform outside, looking at a map, wearing a pink dress, and surrounded by a forest with tall trees.\nPersona Context: \n\n",
    "output": "<think>The user is likely enjoying a camping experience. Unless they are in need of nearby trail information or weather updates, proactive assistance is not necessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is driving on a rural road, following a red car with foggy weather conditions and windshield wipers in use, maintaining a steady speed and safe distance.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information indicates that the person is seated in the driver's seat, driving a Toyota car, with a clear view of the steering wheel and dashboard. However, since there are no other events requiring my proactive assistance and no additional information about other personas, I will not provide proactive assistance and have set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a kitchen, grating cheese over a dish in a frying pan containing pasta, vegetables, and a creamy sauce, suggesting the preparation of a homemade meal.\"\nPersona Context: \n\n",
    "output": "<think>The user is performing a simple and routine task of grating cheese. There are no indications of any challenges or need for assistance. Proactive engagement is not necessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a room with a treadmill, possibly preparing to use it or observing it, with a computer monitor and keyboard visible in the background.\nPersona Context: \nThe user is new to fitness and does not exercise regularly.\n",
    "output": "<think>Since the user's persona indicates the user is new to fitness and do not exercise regularly, I should use vllm (visual large language model) to identify the equipment they currently use, explain how to use it, and provide suitable fitness tips.\n Actions:\n[\"Use the <get_health_data> tool to check the user's fitness level.\", 'Use the <vllm> to identify the equipment they currently use.', 'Search the <search_rednote> and search some tips for using this equipment in the gym.', \"Generate suitable fitness tips based on the user's fitness level.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"identify the equipment they currently use.\",\"image_path\":\"\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"suitable fitness tips based on the user's fitness level.\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Tips for using this equipment in the gym.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a restaurant, looking at a menu displayed on a table, which features various dishes with illustrations and descriptions in both English and Chinese, as the user appears to be considering their meal options.\nPersona Context: \nThe user is health-conscious and wants to make informed decisions about their diet.\n",
    "output": "<think>Contextual information shows the user is in a restaurant, looking at a menu with various food options. The user could benefit from detailed nutritional information about the menu items to make a healthier choice. Providing calorie counts and heating information would aid in their decision-making process. I can use <wikipedia_search> and <get_medical_knowledge> to accomplish this.\n Actions:\n['Use <wikipedia_search> to search the approximate calorie counts and heating information of pasta, steak, and salad.', 'Use <get_medical_knowledge> to search for any health-related information about these food items.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \" calorie counts and heating information of pasta, steak, and salad.\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related information about pasta, steak, and salad.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a room with a wooden floor, looking at an open suitcase containing a pair of beige shorts and a blue sweater. The agenda shows that the user is departing for Japan.\nPersona Context: \n\n",
    "output": "<think>The contextual information shows that the user is packing a suitcase with spring or autumn clothes like light sweaters and trousers. The agenda shows that the user is departing for Japan. When visiting other places, it is important to first check the local weather and temperature. I should use <get_city_weather> to check the weather in Japan, and provide the user with the latest weather forecast.\n Actions:\n[\"Use <get_city_weather> to check the latest weather forecast for both the user's current location and their destination.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Japan\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an art gallery, observing various paintings and sculptures on display, with several other people present.\"\nPersona Context: \n\n",
    "output": "<think>The user is appreciating art in a gallery setting. Proactive assistance is not necessary, as they are likely enjoying the experience.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a natural outdoor setting, possibly a park or garden, observing a brown bird with a long tail foraging among dry leaves and small plants at the base of a tree.\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user 's hands holding a small black bird, possibly a chick, on a wooden surface. The setting appears to be outdoors, possibly in a rural or semi-rural area. However, without additional persona information or events indicating a specific need for assistance, it is likely that the user is enjoying the moment and does not require assistance. Therefore, I will give the proactive score as 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a cozy room with a burning fireplace, a basket containing a loaf of bread and rosemary on a wooden table, and a blue cup of coffee, creating a warm, inviting atmosphere with a rustic touch.\nPersona Context: \nThe user appreciates listening to jazz music during cozy moments.\n",
    "output": "<think>Since the persona shows the user appreciates listening to jazz music during cozy moments. The user is in a cozy setting by the fireplace, which could be enhanced with jazz music. Offering to play such music could enhance their relaxation and enjoyment.\n Actions:\n[\"Use <play_music> to play jazz music to enhance the user's cozy experience by the fireplace.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a room with a wooden table, surrounded by four individuals, engaged in a card game, possibly Uno, with various cards on the table, indicating a casual gathering or friendly game session.\"\nPersona Context: \n\n",
    "output": "<think>The user is engaging in a fun social activity with friends. No assistance is needed, as they are enjoying the game and company.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a store, looking at various Physiogel products displayed on shelves and examining the items, possibly considering a purchase.\"\nPersona Context: \n\n",
    "output": "<think>The user might appreciate knowing the price of the skincare product online or reading reviews from other users to make an informed purchase decision. So I should use <get_online_product_price> to check the price of the skincare product online and <search_rednote> to find user reviews and recommendations for the product.\n Actions:\n['Use <get_online_product_price> to check the price of the skincare product online.', 'Use <search_rednote> to find user reviews and recommendations for the skincare product.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"skincare product\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"skincare product reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user walking along a brick-paved path in a park, with neatly trimmed green bushes on both sides, and wearing a black smartwatch on the left hand. The path appears to be wet, possibly from recent rain.\"\nPersona Context: \n\n",
    "output": "<think>The user appears to be resting in the park, possibly after some physical activity. There are no evident health risks or needs requiring immediate assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is at a bus terminal, observing several buses, including one marked '66K', with a sign indicating '66K' visible and surrounded by modern buildings and a mountain in the background.\"\nPersona Context: \n\n",
    "output": "<think>The user may need real-time bus schedule updates to confirm if they can catch the next bus or need alternative transportation. Proactively offering this information could save time and reduce uncertainty. I need to use <get_current_gps_coordinates> to determine the user's location and <check_bus_schedule> to provide real-time bus updates. I also need to use <get_current_datetime> to check the current time so that I can suggest alternative transportation if needed.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", \"Use <check_bus_schedule> to confirm the real-time status of the bus to the user's destination.\", 'Use <get_current_datetime> to check the current time.', 'If the bus is delayed, use <book_uber> to suggest booking alternative transportation.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"check_bus_schedule\", \"description\": \"Check real-time bus schedules for a specific route.\", \"parameters\": {\"bus_stop\": \"user current location\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"},{\"name\": \"book_uber\", \"description\": \"Book a ride to a specified location.\", \"parameters\": {\"current_location\":\"user current location\", \"destination\": \"User's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a shoe store, browsing through various athletic shoes displayed on shelves, each with price tags attached.\"\nPersona Context: \nFitness enthusiast. Frequently engages in running activities\n",
    "output": "<think>Since the user's persona shows that he frequently engages in running activities, he would benefit from suggestions regarding shoe comfort, durability, and suitability for long-distance running. Checking online reviews and competitive pricing could provide valuable insights to aid his decision.\n Actions:\n['Check online prices for the running shoe model displayed using <get_online_product_price> tool.', 'Use <search_rednote> to search for user reviews and recommended running shoes for marathon events.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"running shoes\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"best running shoes for marathon events\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is stirring a pot of soup with visible ingredients like vegetables and spices, boiling gently on a gray surface.\"\nPersona Context: \n\n",
    "output": "<think>The user is engaged in cooking soup, a common and manageable cooking task. There are no signs of need for intervention. Without additional persona information, proactive assistance would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is walking along a sandy beach shoreline, surrounded by people engaging in activities such as playing in the sand and swimming in the ocean, with houses and trees visible on a hillside in the background.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is leisurely walking on the beach. It seems like a relaxing experience. Without other contextual events of personas, health concerns, or immediate needs, I set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a kitchen, stirring a pot of boiling water on a stove with a wooden spoon, with a digital display on the stove showing a temperature of 9 degrees Celsius.\nPersona Context: \n\n",
    "output": "<think>The user is actively engaged in cooking, stirring a pot on the stove. This is a routine cooking activity with no signs of distress or need for assistance. Proactive intervention may disrupt their focus.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a garden surrounded by lush greenery and vibrant flowers, including white foxgloves and red poppies, with a tree providing shade.\"\nPersona Context: \nThe user is a nature enthusiast and enjoys learning about different plants.\n",
    "output": "<think>The user might be interested in learning more about the plants they are observing. I should use the <vllm> tool to provide information about the specific plants they are looking at. I can also use <wikipedia_search> to search for information about the plants.\n Actions:\n['Use <vllm> to identify the plants the user is observing and provide interesting facts about them.', 'Use <wikipedia_search> to search for more detailed information about the plants.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify and provide information about the plants.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Ghost Orchid\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user standing in a well-lit hallway, wearing a white t-shirt with a colorful graphic design and a lanyard. The content of conversation is: \"Hey, did you hear about the upcoming concert by next week? Any idea where it's taking place?\"\nPersona Context: \n\n",
    "output": "<think>Contexual information shows the user standing in a hallway. Audio information indicates the user is having a conversation with a colleague. The colleague asks: \"Hey, did you hear about the upcoming concert of that popular band happening next week? Any idea where it's taking place?\". Since the colleague is asking about the upcoming concert of that popular band happening next week, they might want to check details such as time, location, and ticket availability. Proactively providing this information would be useful and enhance the conversation. So I can use <google_search> to look up details about the upcoming concert of that popular band happening next week.\n Actions:\n['Use <google_search> to look up details about the upcoming concert of that popular band happening next week, including location, time, and ticket information.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"the upcoming concert of that popular band happening next week.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a forested area sitting at a picnic table with two other individuals, surrounded by various food items, including apples and sandwiches, in a natural outdoor environment with trees and greenery.\"\nPersona Context: \n\n",
    "output": "<think>The user is having a relaxed lunch outdoors. There is no indication of a need for assistance, as they are likely enjoying their meal and the environment. Proactive engagement would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in an office setting, sitting at a desk with a laptop and two monitors, appearing to be working on a computer. The content of conversation is: 'We should finalize the budget report by tomorrow afternoon. Yes, I agree.' The agenda indicates that the budget report deadline is tomorrow afternoon.\"\nPersona Context: \nThe user is responsible for financial planning and analysis.\n",
    "output": "<think>The user needs to ensure they have sufficient time blocked out to work on the budget report before the deadline. I should check for any scheduling conflicts and remind them to start preparing if they haven't already.\n Actions:\n['Use <get_current_datetime> to obtain the current date and time.', 'Use <check_agenda_time_conflict> to verify if the user is free tomorrow afternoon.', 'If no conflicts exist, remind the user to allocate time for the budget report and add it to the agenda if necessary.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"tomorrow afternoon\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Work on budget report\", \"time\": \"tomorrow afternoon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is sitting on a bench in a park, reading a book with a cover that has a text and a yellow star design, surrounded by trees and lamp posts in the background, while wearing headphones and having a tattoo on their shoulder.\nPersona Context: \n\n",
    "output": "<think>The user is immersed in music, enjoying a moment of relaxation. There is no visible need for assistance, as they are likely savoring the music and the park atmosphere. Proactive intervention would disrupt their enjoyment.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a shopping mall, walking through a corridor with various stores and shops. The content of conversation is: \"Do you think we can go to the theater soon here?\"\nPersona Context: \n\n",
    "output": "<think>Providing walking directions to the theater would assist the user in making their decision and enhance their experience.\n Actions:\n['Use <google_map> to find the walking route to the theater.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"shopping district\", \"destination\": \"theater\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a kitchen preparing a mixture in a large glass bowl with a yellowish batter, adding a small amount of white powder from a measuring spoon.\"\nPersona Context: \nThe user enjoys baking and trying out new dessert recipes.\n",
    "output": "<think>The user might benefit from a new dessert recipe or baking tips to ensure their dessert turns out perfectly.\n Actions:\n['Use <search_rednote> to find new dessert recipes or baking tips.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"new dessert recipes or baking tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a store, looking at a display of hiking boots, examining them and possibly considering a purchase.\"\nPersona Context: \nOutdoor enthusiast, frequently goes on hiking trips.\n",
    "output": "<think>The user might appreciate a price comparison for the hiking boots online. Additionally, providing reviews and performance information could help make a better purchase decision.\n Actions:\n['Use <get_online_product_price> to compare online prices for the hiking boots.', 'Use <search_rednote> to find reviews and performance feedback on the hiking boots.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"hiking boots\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"hiking boots reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a kitchen, standing over a stove with a frying pan, cooking a piece of meat using tongs.\nPersona Context: \nThe user is new to cooking and doesn't cook often.\n",
    "output": "<think>The user is cooking in the kitchen. Since their persona indicates they are new to cooking and don't cook often, I might proactively generate some helpful tips, such as using <search_rednote> to find advice related to what they are cooking.\n Actions:\n['Use <search_rednote> to search for tips related to what the user is cooking.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"tips for cooking minced meat\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, observing a small hill with a stone retaining wall covered in green grass and red flowers, with a tree near the top and a sloped hill with a white railing and trees in the background.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is sitting in a garden, surrounded by blooming flowers and plants. The user is enjoying the peaceful environment, and there are no apparent health concerns or immediate needs. Proactive intervention is not necessary. So I will set the proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a living room, cleaning a wooden TV stand with a feather duster, focusing on removing dust from the surface, where a clock, a speaker, and a stack of books are placed.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information indicates that the user is holding a blue object that appears to be a cleaning tool or duster, suggesting they are in the living room for cleaning. However, without additional information about the user's persona or other personal events, I don't have enough context to determine their needs or preferences. Therefore, I will assign a proactive score of 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking on a sidewalk next to a road in an urban environment, with indications of construction or maintenance work on the road.\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is at a digital intersection, crossing the road. Without explicit input or additional contextual information, no proactive actions are required. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a restaurant, seated at a table with a wooden surface, eating a meal that includes a bowl of clear soup with green onions, fried rice with vegetables and a red pepper, and grilled dumplings with shredded cabbage and cheese.\"\nPersona Context: \n\n",
    "output": "<think>The user is dining in a restaurant and seems to be engaged in socializing. There is no indication of a need for assistance, as they are likely enjoying the environment and company.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an electronics store, looking at a display of laptops with detailed specifications on their screens, amidst various electronic products and software packages.\"\nPersona Context: \nThe user is tech-savvy and enjoys finding the best deals.\n",
    "output": "<think>The user is interested in purchasing a tablet and is looking for deals. Providing information on current promotions could help them make a purchase decision.\n Actions:\n['Use <get_online_product_price> to find current deals on tablets.', 'Provide a comparison of options and promotions available.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"tablet\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a kitchen, washing lettuce under a running faucet in a metal sink, with their hand visible as they handle the leaves.\"\nPersona Context: \n\n",
    "output": "<think>Washing vegetables is a basic cooking task that does not require proactive assistance. The user seems to be handling it effectively.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a pharmacy, holding and examining a bottle of Ostelin Calcium & Vitamin D3 supplements, which is white with blue and green labeling and contains 250 tablets, likely considering purchasing it.\"\nPersona Context: \n\n",
    "output": "<think>Given the user's interest in vitamin D, providing information on its benefits and recommended dosages could be helpful. This proactive intervention offers clear value by helping the user make an informed decision. Make the response eaier to understand by using simple language is more helpful.\n Actions:\n['Use <get_medical_knowledge> to provide information on the benefits of vitamin D and recommended dosages.', 'Use <wikipedia_search> to find additional information about vitamin D.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"benefits and recommended dosages of vitamin D\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Vitamin D\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user walking through a corridor in an office building with tiled floors, boxes stacked against the wall, and a red ladder leaning against the wall near a window. The corridor is well-lit with overhead lights.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is walking in the corridor. Without other contextual events of personas, health concerns, or immediate needs, I set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user walking near a small stream in a forested area with a dog ahead on a gravel path, while navigating muddy ground with scattered rocks and leaves.\"\nPersona Context: \n\n",
    "output": "<think>The user is walking a dog on a paved outdoor path. Without additional information, I should not proactively generate content that might burden the user.\n Actions:\n[]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is at a taxi stand at night, observing several taxis parked under a covered area, with a woman walking towards a red taxi and a green taxi passing by in the foreground, under the illumination of streetlights and a sign indicating 'TAXI STAND' in both English and Chinese.\"\nPersona Context: \n\n",
    "output": "<think>The user is on the street, next to the taxi rank. The user is probably waiting for a taxi. I can help him call a taxi or a Uber. But without an exact destination, I can only provide general assistance.\n Actions:\n[\"Use <get_current_gps_coordinates> to check the user's current location.\", 'Use <get_current_datetime> to provide the current date and time.', 'Ask user for the destination and book a taxi or Uber.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lying down in a tent, holding an open book and reading it, with visible adornments on their hands and a tattoo on the left wrist, while the tent's interior and a blurred outdoor view are seen.\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a leisurely day in a hammock, likely immersed in their book. There is no need for assistance, as they appear content and focused on reading. Proactive engagement would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a grocery store, looking at various bags of rice on a shelf and examining the options available, which come in different colors and packaging, including brown, blue, and purple bags.\nPersona Context: \n\n",
    "output": "<think>It seems that the user is shopping and is deciding which brand of cereal to buy. It would be helpful to provide price comparisons and nutritional information to help them make an informed decision.\n Actions:\n['Use the <get_online_product_price> tool to compare prices of the cereals.', 'Use <search_rednote> to find nutritional information about the cereals.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Brand A cereal, Brand B cereal, Brand C cereal\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"nutritional information for cereal brands\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user walking along a waterfront promenade, observing people engaged in activities like walking, cycling, and pushing a stroller, with a backdrop of trees, a stone wall, a railing along the water's edge, tall buildings, and a clear blue sky.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a peaceful walk by the river. There is no indication of a need for assistance, as they are likely appreciating the view and the walk. Proactive engagement would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, looking at various backpacks displayed on a wall in a well-lit environment with a product advertisement sign in the background.\nPersona Context: \n\n",
    "output": "<think>The user explicitly mentions interest in checking prices online. Immediate proactive assistance is highly relevant and valuable for making an informed purchasing decision.\n Actions:\n['Use <get_online_product_price> to check current online pricing of the bag the user is viewing.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"bag\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is on a busy city street, observing a fire truck moving through an intersection, with various vehicles and construction equipment present. Buildings with signs for AT&T, Skechers, and UNIQLO are visible, and the sidewalk is busy with pedestrians and black garbage bags on the ground.\"\nPersona Context: \n\n",
    "output": "<think>The user is walking down a busy city street. I lack further contextual information or details about the user's persona. Interrupting them with proactive assistance may not be necessary unless they show signs of needing help. Therefore, I will assign a proactive score of 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a restaurant, looking at a sushi menu displayed on a wooden stand, featuring various sushi items with photographs and descriptions in Japanese. A sign below the menu shows the restaurant's operating hours from 11:30 to 22:00.\nPersona Context: \nThe user is trying to maintain a healthy diet while enjoying their meal.\n",
    "output": "<think>Sushi can be a healthy option, but some items like tempura can be high in calories and fat. Providing calorie counts and suggesting healthier alternatives can help the user make better choices.\n Actions:\n['Use <wikipedia_search> to find calorie counts and health information for nigiri, sashimi, and tempura.', 'Use <get_medical_knowledge> to offer advice on healthier sushi options.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for nigiri, sashimi, and tempura\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for nigiri, sashimi, and tempura\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a shopping mall, standing in front of a Thai market store with a green and white color scheme, holding a yellow bag and looking at the menu board.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is walking into what appears to be a Thai restaurant. The user might appreciate assistance in deciding what to order. So I can use <get_current_gps_coordinates> to confirm the restaurant's location and <search_rednote> to find recommendations for popular items or dietary-specific options at this restaurant.\n Actions:\n[\"Use <get_current_gps_coordinates> to confirm the restaurant's location.\", 'Use <search_rednote> to find recommendations for popular items or dietary-specific options at this restaurant.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"Popular menu options at this restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking on a curved sidewalk near a road with yellow double lines, lined with a white railing and street lamp, with buildings and greenery in the background under an overcast sky. The content of conversation is: \"We haven't had a team building for a long time. How about having a team building this weekend? Okay, I agree.\"\nPersona Context: \n\n",
    "output": "<think>When planning hiking activities, various factors should be considered, including the weather, whether it is the off-season or peak season for tourism, passenger flow, schedule, and more. Since the hiking location has not been specified, it may be in the city where the user is currently located. I need to use GPS to determine the user's location.\n Actions:\n[\"Check the user's location using the <get_current_gps_coordinates> tool.\", 'Use <get_city_weather> tool to check the weather forecast for location this weekend.', 'Use <get_current_datetime> to check the current time and season, and analyze whether it is a peak tourist period, considering passenger flow and overall tourist experience.', \"Use <check_agenda_time_conflict> tool to check the user's agenda to see if there are any conflicts.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\": \"this weekend\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a conference room, standing in front of a whiteboard with a marker in hand, presenting or explaining to a group of seated individuals who are attentively listening.\"\nPersona Context: \n\n",
    "output": "<think>The user is in a meeting room with notes on the whiteboard, suggesting they are engaged in planning or reviewing. There is no indication of distress or need for proactive assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, playing soccer with a group of children on a grassy field, surrounded by trees and bushes.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying watching the children play soccer. There is no indication of a need for assistance since the user seems to be enjoying the moment. Proactively offering assistance would likely be unnecessary and potentially disruptive.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a restaurant, holding an open menu with breakfast and main course options like avocado toast, quinoa salad, and tofu scramble, in a cozy dining atmosphere.\"\nPersona Context: \nThe user is interested in starting their day with a balanced and healthy meal.\n",
    "output": "<think>Breakfast diner meals can be high in calories and sugar. Providing calorie counts and alternative meal suggestions can help the user make a healthier choice.\n Actions:\n['Use <wikipedia_search> to find calorie counts and heating information for pancakes, scrambled eggs, and bacon.', 'Use <get_medical_knowledge> to provide advice on healthier breakfast options.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for pancakes, scrambled eggs, and bacon\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for pancakes, scrambled eggs, and bacon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a busy restaurant, seated at a table with a plate of noodles, a bowl of soup, and a plate of meat, alongside a QR code menu. The content of conversation is: \"I heard that AI can write stories.\"\nPersona Context: \nTech-savvy. Creative\n",
    "output": "<think>Although interesting, the user's persona indicates that they are tech-savvy and creative. Therefore, in the current context (AI), proactive intervention is not necessary unless explicitly requested. I should refrain from providing unsolicited information that may interfere with their conversation. I have set the proactive score to 1.\n Actions:\n[]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is cleaning a white surface, possibly a refrigerator or a door, using a blue cloth in a kitchen or similar indoor setting, with a green leafy plant visible in the background.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is cleaning the freezer compartment of an open refrigerator. The user is using a cloth to wipe down the interior, and the freezer has a wire shelf and some items stored inside. Without additional information about the user's persona or preferences, I don't have enough context to determine their needs or preferences. Therefore, I will assign a proactive score of 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a yoga studio, practicing a yoga pose with arms outstretched and legs apart on a wooden floor, surrounded by shelves with yoga mats and other equipment, along with other individuals practicing yoga on mats of various colors.\"\nPersona Context: \nThe user enjoys listening to serene music during pilates to maintain focus and rhythm.\n",
    "output": "<think>The user is about to begin a pilates session. Playing serene music could help the user maintain focus and rhythm, enhancing their session.\n Actions:\n[\"Use <play_music> to play serene music to aid in the user's pilates session.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park surrounded by greenery and trees, standing near a path with a person in a white hoodie and glasses nearby. The content of conversation is: \"Did you heard about the beach soccer game this weekend?\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is having a conversation with others. The partner asks the user whether he knows the big soccer game this weekend. Proactively providing information about the big soccer game, such as its showtimes or ticket price, could enhance the conversation. I can use <google_search> to look up details about the big soccer game, including showtimes and reviews.\n Actions:\n['Use <google_search> to look up details about the big soccer game, including its showtimes or ticket price.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"big soccer game, including its showtimes or ticket price\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in an office setting, sitting in front of a large monitor displaying a chart of various GLM and GPT models, suggesting a focus on technical or research work.\"\nPersona Context: \n\n",
    "output": "<think>The user is focused on viewing a presentation, indicating that he is engaged in his work. There is no visible sign of distress or need for assistance. Proactive engagement might disrupt their focus.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVision information suggests the user is in an office setting, sitting at a desk with a computer setup, and possibly engaged in a conversation or presentation. The content of conversation is: \"Do you know if there is a good place to grab lunch? Well, let me think.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is having a conversation with others. The partner asks the user if there is a good place nearby to grab lunch. Providing details about highly-rated places nearby could enhance the interaction. Since they are talking about the places nearby, I need to first use <get_current_gps_coordinates> to determine the user's current location. Then, I can use <google_search> or <search_rednote> tool to find well-reviewed lunch spots near the coworking space.\n Actions:\n[\"Use <get_current_gps_coordinates> to confirm the user's current location.\", 'Use <google_search> to find nearby lunch spots.', 'Use <search_rednote> to find highly-rated lunch spots with good reviews.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"find nearby lunch spots\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"highly-rated lunch spots near coworking space\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user sitting at a bus stop under a large overpass, wearing a white hat and looking at their phone, while other people are waiting in the background. The agenda reveals the user has a meeting scheduled at 9:00 AM downtown.\"\nPersona Context: \n\n",
    "output": "<think>The user is likely on their way to a meeting scheduled at 9:00 AM, which suggests a need for timely arrival. I should check the bus schedule to ensure they can reach downtown on time. If the bus schedule doesn't align with their meeting time, I can suggest an alternative mode of transportation.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to check the current time.', 'Use <check_bus_schedule> to provide the next available bus schedule.', 'If the bus schedule is not suitable, use <book_uber> to suggest alternative transportation.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"downtown\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user seated in a room, holding and reading a newspaper titled \"Los Angeles Times,\" with a wooden cabinet and a chair visible in the background.\nPersona Context: \n\n",
    "output": "<think>The user is sitting in a waiting room, likely waiting for an appointment or service. There is no indication of a need for proactive assistance, as they seem to be occupying themselves while they wait. Proactive intervention would not provide any immediate benefit.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a cozy living room, watching a projected movie on a large screen displaying black-and-white images, including a man eating a sandwich and a young boy playing with a toy. The room is dimly lit, and the user is seated on a couch, facing the screen, creating a relaxed atmosphere.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is watching a movie, which is a leisure activity. There is no indication of any need for assistance or interruption. Proactive engagement would be unnecessary and potentially disruptive. Proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in an electronics store, looking at a display of HP laptops and comparing the features and prices of different models.\"\nPersona Context: \nThe user is a gamer who frequently upgrades his gaming gear for better performance.\n",
    "output": "<think>The user might be interested in comparing the price of the gaming laptop online to ensure they are getting the best deal. Providing a price comparison and reviews could help them decide.\n Actions:\n['Use <get_online_product_price> to find the current price of the gaming laptop online.', \"Use <search_rednote> to find reviews and comments about the gaming laptop's performance.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"gaming laptop\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"gaming laptop reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a grocery store, looking at a shelf stocked with various milk products, including cartons from brands like \"meiji\" and \"KOWLOON DAIRY,\" in different colors and sizes, and the user appears to be examining the options available.\nPersona Context: \nUser is lactose intolerant.. User avoids dairy and prefers lactose-free alternatives.\n",
    "output": "<think>Since the user is lactose intolerant, they may need an alternative to regular milk. I should suggest lactose-free options and compare their prices with online products.\n Actions:\n['Use <get_online_product_price> to check lactose-free milk prices online.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"lactose-free milk\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is descending a staircase in a modern building, heading towards a lower level, with a view of the greenery outside through a glass wall.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is walking down stairs with handrails and windows nearby. Without explicit input or additional contextual information, no proactive actions are required. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, sitting on a bench under a tree with a sketchbook open in front of them, displaying a drawing of a tree and a bench, and the user is holding a pencil, seemingly preparing to sketch or draw.\"\nPersona Context: \n\n",
    "output": "<think>The user is engaged in a creative activity in a peaceful park setting. There is no immediate need for assistance, as they are likely focused and enjoying their sketching. Proactive intervention would be disruptive.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is seated at a desk in an office setting, holding and reviewing a document titled 'Advantages of Visual Charts' while comparing it to content displayed on an active laptop screen.\"\nPersona Context: \n\n",
    "output": "<think>The user is likely waiting for a medical appointment while reading a pamphlet. There is no indication of distress or need for intervention. Proactive assistance could be intrusive and unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user ascending a staircase with a red handrail and a tiled, grid-patterned surface, with a door at the top.\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is walking up the stairs with a handrail on the left and a white wall on the right. Without explicit input or additional contextual information, no proactive actions are required. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is sitting on a rocky cliff overlooking the ocean, with feet crossed, wearing black sneakers and white socks, enjoying the view of the sea as waves crash against the rocks below.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a day at the beach. There is no indication of a need for assistance. Interrupting this leisure activity could be intrusive.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a grocery store, looking at the vegetable section, examining various types of vegetables such as leafy greens, cucumbers, and bell peppers, with prices visible on labels beneath the shelves.\"\nPersona Context: \nUser often struggles with deciding what to cook.. The user has mentioned they often feel unsure about what to cook.\n",
    "output": "<think>Contextual information shows the user is in a vegetable market and looking at the vegetables. The user is having difficulty deciding what to cook. They should first check the current time to determine whether to prepare lunch or dinner. Then, they can search for popular recipes on the Rednote app. Additionally, since the user is in the supermarket, the prices of ingredients for online dishes can be provided for reference.\n Actions:\n['Use <get_current_datetime> tool to check the current time and date.', 'Search <search_rednote> tool to search for recipe ideas and suggest ingredients.', 'Search for the prices of similar ingredients on an online shopping app to provide the user with a reference.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"recipe ideas and suggest ingredients\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"The user is riding a bicycle on a paved road, surrounded by green grass and fields, with a digital speedometer visible on the handlebars and their hands on the handlebars, indicating a clear road ahead.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows that the user is riding a bicycle on a paved road. The rider's hands are gripping the handlebars. The scene suggests a leisurely ride on a clear day. But without additional information, I don't have enough context to determine the user's needs or preferences. Therefore, I will set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, standing near a small pond surrounded by trees and shrubs, observing the natural surroundings.\"\nPersona Context: \n\n",
    "output": "<think>The user seems to be enjoying a peaceful moment by the lake. Proactively offering assistance might interrupt their experience, so it would be best to wait for an explicit query.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a kitchen, slicing a loaf of bread on a wooden cutting board, with a striped kitchen towel placed nearby on the wooden countertop.\"\nPersona Context: \n\n",
    "output": "<think>Visual information shows the user is simply slicing bread, which is a straightforward task. No proactive intervention is needed. So I will set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, observing a pond with ducks swimming, surrounded by trees with autumn-colored leaves, with a bridge visible in the background.\"\nPersona Context: \n\n",
    "output": "<think>The user is engaged in a leisurely activity at the park. There is no indication of a need for proactive assistance, as they are likely enjoying the tranquil moment.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a zoo enclosure, observing a tiger walking on a snowy path with a metal fence surrounding the area and rocks and trees in the background.\"\nPersona Context: \nAnimal lover\n",
    "output": "<think>The user may be interested in learning more about tigers, their habitat, and conservation efforts. Providing information about these aspects could enrich the user's zoo visit.\n Actions:\n['Use <wikipedia_search> to find information about tigers, their natural habitat, and conservation status.', 'Use <google_search> to provide insights into tiger conservation efforts and their importance in the ecosystem.', 'Provide educational insights about tigers and efforts to protect them.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Tigers habitat and conservation\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tiger conservation efforts and their importance in the ecosystem.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates that the user is in an electronics store, browsing various gadgets such as power banks, earphones, and speakers, with the possibility of considering a purchase.\"\nPersona Context: \n\n",
    "output": "<think>The user might be considering purchasing wireless earbuds. They could benefit from a price comparison with online stores and reviews of different brands. Additionally, checking for any applicable store discounts could be helpful. I can use <get_online_product_price> to inform the user of online prices for these products, and the <search_rednote> tool to find useful tips about them.\n Actions:\n['Use <get_online_product_price> to check the price of the earbuds on online shopping platforms.', 'Use <search_rednote> to find user reviews and recommendations for the most reliable wireless earbuds.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"wireless earbuds\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"wireless earbuds reviews and best recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a dimly lit room with neon lighting, surrounded by young adults holding disposable cups and engaged in conversation, with abstract graffiti art in the background contributing to an urban atmosphere.\"\nPersona Context: \nOutgoing\n",
    "output": "<think>The user is enjoying a night out with friends in a social setting. Given his outgoing persona, proactive assistance is not needed, as it may disrupt their social engagement.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a room with a large monitor displaying a linear algebra lesson, with a laptop connected to it, indicating the user is studying or working on the material. Mobile data suggests the user has been seated for an extended period.\"\nPersona Context: \n\n",
    "output": "<think>If the user sits for only a short time, I don't need to remind them to move. However, the current context indicates that the user has been sitting for studing or working for a long time. I need to use <get_health_data> tool to check whether the health data from their wearable device is normal and suggest that they get up and move around. I can also use <wikipedia_search> and <get_medical_knowledge> tools to provide professional medical knowledge, including recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\n Actions:\n['Use the <get_health_data> tool to check their physiological indicators over the past period of time, such as heart rate, breathing, and blood samples.', 'Use <get_medical_knowledge> and <wikipedia_search> tools for professional medical knowledge, including recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user seated at a desk in an office environment, working on a laptop with papers and handwritten notes while holding a pen. Another person is partially visible in the background, also working on a laptop.\nPersona Context: \n\n",
    "output": "<think>The user is in a conference room, indicating they might be in a meeting or preparing for one. There is no indication of a need for proactive assistance as they appear to be focused on their tasks.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user standing on a sidewalk at night, observing a line of red taxis parked under a covered area with their lights on, indicating availability for hire. The user has booked a hotel room at The Ritz-Carlton, Hong Kong for tonight.\nPersona Context: \n\n",
    "output": "<think>The user is on the street, next to the taxi rank, likely waiting for a taxi or wanting to call an Uber. According to the agenda, the user has booked a hotel room at The Ritz-Carlton, Hong Kong for tonight. I can assist by calling a taxi or an Uber. By using <get_current_gps_coordinates>, I can obtain the current location, and since I already know the destination, I can help book a taxi or an Uber using <book_uber>. After booking, I should ask him to confirm if he needs this and inquire if he requires any other assistance.\n Actions:\n[\"Use <get_current_gps_coordinates> to check the user's current location.\", \"Use the <book_uber> tool to book an Uber from the current location to the user's destination.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"None\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a room with a desk setup, typing on a laptop, with shelves in the background containing various items. The user is wearing a white t-shirt with a colorful graphic design. The content of conversation is: \"Can we schedule a quick chat later to discuss the new client proposal?\" The user's calendar shows no free slots until 6 PM.\nPersona Context: \nThe user frequently manages a busy schedule and coordinates with multiple team members.\n",
    "output": "<think>The user might struggle to find a free slot for the chat. Proactively suggesting the next available time slot or rearranging the schedule could be beneficial.\n Actions:\n['Use <check_agenda_time_conflict> to identify the next available time slot for a meeting.', 'Suggest a time for the quick chat and send a meeting invite.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"today after 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a comfortable chair, reading a book indoors, possibly in a living room or cozy reading area, wearing a white sweater with a ring on their finger.\nPersona Context: \nThe user enjoys reading and listening to audiobooks during relaxation.\n",
    "output": "<think>Since the persona shows the user enjoys reading and listening to audiobooks during relaxation. The user is relaxing in a hammock, which is an ideal time for listening to an audiobook. Offering to play an audiobook or calming music could enhance their relaxation experience.\n Actions:\n[\"Use <play_music> to play an audiobook or calming music to enhance the user's relaxation.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a cozy bedroom, standing in front of a large mirror and holding a gray shirt on a hanger, while wearing a mustard yellow sweater and olive green pants. The room is decorated with plants and has a warm, inviting atmosphere.\nPersona Context: \n\n",
    "output": "<think>The user might be seeking an opinion on how the outfit looks or considering whether to purchase it. They could benefit from fashion advice or price comparison.\n Actions:\n['Use the vllm to analyze the outfit and provide feedback on how it looks.', 'Check prices of the outfit on various online shopping platforms using <get_online_product_price> tool.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"analyze the outfit and provide feedback on how it looks.\",\"image_path\":\"\"}},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"the new outfit the user is wearing.'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in an outdoor garden area surrounded by various potted plants and a brick pathway, with signs in front of each pot likely indicating plant names or care instructions, suggesting it may be part of a larger outdoor space such as a park or community garden.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying photography in a botanical garden. Assistance with photo tips or information about plants could be useful, but only if requested.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a cozy caf\u00e9 setting, seated at a circular table with four cups of coffee, and is with three others, preparing to enjoy their beverages in a warm, inviting atmosphere.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information indicates that the user is social and enjoys spending time with friends. However, I don't have any specific conversation content, so I don't know what information the user needs. Directly interrupting their conversation with proactive suggestions would be inappropriate, as they are likely enjoying the moment and do not require assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a kitchen kneading dough on a floured surface, with hands covered in flour and wearing a beige sweater.\"\nPersona Context: \n\n",
    "output": "<think>The task of kneading dough is common in baking. The user seems to be proceeding with the task without any indications of needing assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a caf\u00e9, seated at a table with a tray holding two Starbucks drinks and two cupcakes, eating the cupcakes with a spoon in a cozy ambiance.\"\nPersona Context: \n\n",
    "output": "<think>The user is in a relaxed environment, enjoying a conversation with a friend. Proactive intervention is unnecessary as they are likely enjoying their time.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a busy shopping mall, looking at a store display with mannequins dressed in summer clothing, while another person also observes the display. The content of conversation is: \"I want to buy a smart speaker. Do you know where the best smart speaker stores around here?\"\nPersona Context: \n\n",
    "output": "<think>The contextual information shows the user is shopping with a friend and they are having a conversation. According to the content of the conversation, the friend is looking for smart speaker stores nearby. So I should proactively help user by giving him some suggestions. I can use <get_current_gps_coordinates> to determine the user's current location, <get_current_datetime> to get the current date and time, <google_map> to find and list nearby smart speaker stores that sell smart speaker, and <google_search> to find and list nearby smart speaker stores that sell smart speaker, and check their opening hours.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to get the current date and time.', 'Use <google_map> to find and list nearby smart speaker stores that sell smart speaker.', 'Use <google_search> to find and list nearby smart speaker stores that sell smart speaker, and check their opening hours ites.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"smart speaker stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"smart speaker stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a laboratory setting, sitting at a desk with a laptop and a monitor displaying code, indicating they are working on a project related to programming or data analysis. The content of conversation is: \"I think we should finalize the project plan by next Monday. Maybe we can have a meeting in the afternoon that day. I agree.\"\nPersona Context: \n\n",
    "output": "<think>The user is discussing plans for a meeting next Monday afternoon. I should check their agenda for availability and suggest a time to finalize the plan proactively.\n Actions:\n['Use <get_current_datetime> to check the current date and time.', \"Use <check_agenda_time_conflict> to check the user's agenda for availability next Monday afternoon.\", 'Suggest a specific time for the meeting and add it to the agenda if no conflicts exist.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, looking at various electronic products displayed on shelves, including different models of smartwatches and earphones, each with a price tag and product information. The user appears to be examining the products, possibly considering a purchase.\nPersona Context: \nTech enthusiast who enjoys staying updated with the latest gadgets.\n",
    "output": "<think>The user might appreciate knowing the price of the smartwatch online or reading reviews from other users to make an informed purchase decision. So I should use <get_online_product_price> to check the price of the smartwatch online and <search_rednote> to find user reviews and recommendations for the product.\n Actions:\n['Use <get_online_product_price> to check the price of the smartwatch online.', 'Use <search_rednote> to find user reviews and recommendations for the smartwatch.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smartwatch\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"smartwatch reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a park, standing on a stone path surrounded by greenery, and appears to be looking around. The content of conversation is: \\\"Have you heard about the next Saturday's opening farmer market?\\\"\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is having a conversation with others. The partner asks the user whether they have watched the new superhero movie that just came out. Providing information about the farmers' market, such as its location, opening hours, or featured vendors, could enhance the conversation. I can use <google_search> to gather details about the new farmers' market.\n Actions:\n[\"Use <google_search> to find details about the new farmers' market, including location, opening hours, and featured vendors.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new farmers' market next weekend downtown\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a classroom setting, seated in front of a projector screen displaying a presentation titled 'Multi-Head Latent Attention (MLA),' indicating they are attending a presentation or lecture.\"\nPersona Context: \nUser is a third-year PhD student majoring in computer science and AI.\n",
    "output": "<think>Multi-head attention is a core concept in transformer architecture and should be very familiar to PhD students majoring in computer science and AI techniques, so it does not require additional contextual explanation.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in an electronics store, examining a display stand with various headphones priced at $699, $3999, and $1299. The store has a modern, clean layout with other electronic products visible in the background.\"\nPersona Context: \nThe user often tests new audio devices by playing their favorite music.\n",
    "output": "<think>The user is likely considering testing the headphones with their own music. Providing access to their music library could assist in making an informed decision.\n Actions:\n['Use <play_music> to allow the user to test headphones with their favorite songs.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a grocery store browsing the pet food section, examining various brands of dog treats and snacks, including Nudges and Pup Peroni.\"\nPersona Context: \nThe user is a pet owner who is attentive to pet nutrition.\n",
    "output": "<think>The user is likely looking for the best nutritional options for their pet. Offering price comparisons or nutritional information could be helpful.\n Actions:\n['Use <get_online_product_price> to compare prices of the pet food online.', 'Use <wikipedia_search> to provide nutritional information about the pet food.', 'Use <search_rednote> to find user reviews or tips on the best pet food.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"pet food\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"nutritional information on pet food\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best pet food reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is on a train, observing a busy urban scene with multiple cars and buses on the road, a pedestrian bridge, and a fenced area with blue barriers and a building in the background. The weather appears overcast.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a peaceful train ride. Without any signs of distress or need for assistance, proactive engagement is unnecessary and could disrupt their enjoyment of the scenery.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing on a rooftop, looking out over a cityscape with modern buildings, a body of water, and distant hills under an overcast sky, while wearing a white t-shirt with a colorful graphic design. The content of conversation is: \"Should we plan a rooftop party next Friday night? Yeah, that's awesome!\"\nPersona Context: \n\n",
    "output": "<think>Planning a rooftop party involves checking the weather forecast to ensure clear skies and no rain. Providing this information will assist in deciding whether the event can go ahead.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", \"Use <get_city_weather> to check the weather forecast for next Friday night in the user's location.\", \"Use <check_agenda_time_conflict> to confirm the user's availability for next Friday night.\", 'Use <add_to_agenda> to schedule the rooftop party.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"next Friday night\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday night\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Rooftop party\", \"time\": \"next Friday night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a room with a wooden floor, packing clothes into a suitcase, including a white shirt and a blue sweater. The agenda indicates that the user is departing for Switzerland.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is preparing to travel to Switzerland. When visiting other places, it is important to first check the local weather and temperature. Therefore, I need to use the <get_city_weather> tool to check the current conditions in Switzerland. To provide the weather forecast for the user's current location, I should use the <get_current_gps_coordinates> tool.\n Actions:\n[\"Use <get_city_weather> to check the latest weather forecast for both the user's current location and their destination.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Switzerland\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a grocery store, looking at a shelf stocked with various bottles of olive oil, examining the labels and prices of different brands and types, including extra virgin and regular varieties.\"\nPersona Context: \n\n",
    "output": "<think>The user might want to buy Olive oil. Typically, a person buying some general products will be concerned about the current market prices, online platform prices, and some tips or recomendations. User might need to compare prices with online options and get tips on product selection. Therefore, I can use the <get_online_product_price> tool to check the online prices of olive oil. Additionally, I can use the <search_rednote> and <wikipedia_search> tool to provide product selection tips.\n Actions:\n['Use <get_online_product_price> to search for similar olive oil products on an online shopping app.', 'Use <search_rednote> to provide product selection tips for olive oil.', 'Use <wikipedia_search> to provide basic knowledge for olive oil.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"olive oil\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"product selection tips for olive oil\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"basic knowledge for olive oil\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a shopping mall, walking past storefronts and kiosks. The content of conversation is: \"I'm not sure where the electronics store is.\"\nPersona Context: \n\n",
    "output": "<think>The user is likely trying to find an electronics store within the mall. Proactively providing directions to the store would be beneficial. I should use <google_map> to find the store's location within the mall and provide clear directions.\n Actions:\n['Use <google_map> to find the location of the electronics store within the mall and provide directions.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"shopping mall entrance\", \"destination\": \"electronics store\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park, observing a small hill with a stone retaining wall, green grass, a few red flowers, and a nearby tree with green leaves. The background features a large, sloped hill with a metal railing along the top edge, and the scene is calm and natural with no other people visible in the immediate vicinity.\nPersona Context: \nThe user is a plant enthusiast with a keen interest in botany.\n",
    "output": "<think>The user might appreciate learning more about the red flowers they are viewing. Providing detailed information could enrich their visit.\n Actions:\n['Use <vllm> to identify the specific flowers the user is admiring.', 'Use <wikipedia_search> to provide detailed information about these flowers species.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the orchids the user is observing.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Hippeastrum\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a cozy living room, surrounded by friends, with one person using a laptop to browse a photo gallery and another holding a tablet, possibly reading or watching something, in a relaxed atmosphere with colorful decor.\"\nPersona Context: \n\n",
    "output": "<think>The user might be planning a trip and could benefit from travel recommendations, booking assistance, or itinerary planning. I can use <search_rednote> to search for popular tourist destinations and tips. Without additional information, I rate this proactive score at 3 points. This indicates a potential for proactivity, but the necessity is not very high. Since you are not confident about the user's preferences, you should ask the user to confirm whether they need this service. If not, it should be canceled and this information should be summarized in the user's persona.\n Actions:\n['User <search_rednote> to search for popular tourist destinations and tips.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Popular tourist destinations and tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a grocery store, browsing through the vegetable section, with shelves stocked with various vegetables such as packaged celery, lettuce, and cabbage.\"\nPersona Context: \nUser often struggles with deciding what to cook.. The user prefers quick and easy recipes due to their busy schedule.\n",
    "output": "<think>Contextual information shows the user is shopping in a grocery store, with lots of vegetables and eggs in front of him. The user might be unsure about what to cook and could benefit from quick and easy recipe suggestions. They should first check the current time to determine whether they are planning for lunch, dinner, or meal prep. Then, they can search for simple recipes on the Rednote app. Additionally, since the user is in the grocery store, providing online prices for common ingredients could help them plan their budget.\n Actions:\n['Use <get_current_datetime> tool to check the current time and date.', 'Search <search_rednote> tool to find quick and easy recipe ideas.', 'Search for the prices of similar ingredients on an online shopping app to provide the user with a reference.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"quick and easy recipes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a store, looking at a display of Apple iPad models, including an iPad with a keyboard attachment, an iPad with a stylus, and another iPad with a different keyboard, with price tags and information cards next to each iPad.\"\nPersona Context: \n\n",
    "output": "<think>The user might be looking to upgrade their tablet. Providing price comparisons, user reviews, and detailed specifications could be highly beneficial in making an informed purchasing decision.\n Actions:\n['Use <get_online_product_price> to compare prices for the tablet models online.', 'Use <search_rednote> to find user reviews and recommendations for the tablets.', 'Use <google_search> to provide detailed specifications and comparisons for the different models.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"tablet\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tablet reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tablet specifications and comparisons\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is relaxing on a hammock in an outdoor park setting with clear blue skies and a few people around.\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a peaceful moment in their backyard hammock. There is no evident need for assistance, as they are likely savoring the tranquility. Proactive intervention would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a gym, standing in front of a treadmill with a digital display showing a green screen, and appears to be preparing to start a workout.\nPersona Context: \nThe user is new to fitness and concerned about heart rate during exercise.\n",
    "output": "<think>Given the user's concern about heart rate and newness to fitness, it would be beneficial to monitor their heart rate during the workout. I should use <get_health_data> to track the user's heart rate and <get_medical_knowledge> to provide safe exercise guidelines.\n Actions:\n[\"Use <get_health_data> to monitor the user's heart rate during the workout.\", 'Use <get_medical_knowledge> to provide guidelines for safe exercise heart rate.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"safe exercise heart rate guidelines\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a shoe store, looking at a display of trail running shoes, including a pair with the brand name 'HOKA' visible, and possibly considering a purchase.\"\nPersona Context: \nThe user is budget-conscious and prefers finding deals online before making purchases.\n",
    "output": "<think>The user might want to compare the price of these shoes online to see if they can find a better deal. I should proactively provide price comparison information without interrupting their shopping experience unnecessarily.\n Actions:\n['Use <get_online_product_price> to find the current price of the running shoes online.', 'Determine if there are any significant discounts or deals.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the current price of a product from online retailers.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park, sitting on a wet wooden bench, wearing a black smartwatch, with a large tree and a small pond in the background. The scene is peaceful, with no other people visible in the immediate vicinity.\nPersona Context: \n\n",
    "output": "<think>The user appears to be resting in the park, possibly after some physical activity. There are no evident health risks or needs requiring immediate assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a bakery or pastry shop, observing a display case filled with various baked goods, including cookies, pastries, and donuts.\nPersona Context: \nThe user loves baked goods but wants to make healthier choices.\n",
    "output": "<think>Baked goods can be high in calories, sugar, and fat. Providing calorie counts and suggesting healthier alternatives or portion control tips can assist the user.\n Actions:\n['Use <wikipedia_search> to find calorie counts and health information for croissants, muffins, and cookies.', 'Use <get_medical_knowledge> to provide advice on healthier baked goods options or portion control.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for croissants, muffins, and cookies\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for croissants, muffins, and cookies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a meeting room, seated at a table with colleagues, focusing on a laptop screen displaying text and engaging in the meeting. The mobile API data suggests the user is set to work for an extended period.\nPersona Context: \n\n",
    "output": "<think>If the user sits for only a short time, I don't need to remind them to move. However, the current context indicates that the user has been sitting for studing or working for a long time. I need to use <get_health_data> tool to check whether the health data from their wearable device is normal and suggest that they get up and move around. I can also use <wikipedia_search> and <get_medical_knowledge> tools to provide professional medical knowledge, including recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\n Actions:\n['Use the <get_health_data> tool to check their physiological indicators over the past period of time, such as heart rate, breathing, and blood samples.', 'Use <get_medical_knowledge> and <wikipedia_search> tools for professional medical knowledge, including recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is standing at a bus stop, waiting for a bus, with a sign indicating bus number 582 to 'University Station,' as a double-decker bus approaches and other pedestrians walk around the area.\"\nPersona Context: \n\n",
    "output": "<think>The user is at a bus stop named 'University.'. The user might need real-time bus arrival information or route suggestions. I need to first verify the user's current location, date, and time. Then, I should provide real-time bus arrival information and suggest alternative routes if the bus is delayed. If it is too late, I can also recommend alternative transportation methods such as a taxi or Uber and ask the user if they need me to book it for them.\n Actions:\n['Use a public transport app to provide real-time bus arrival times for the nearest stop.', 'Suggest alternative routes if the bus is delayed.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'University'\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a gym, standing in front of a treadmill with a digital display and handrails, appearing to prepare for a workout.\"\nPersona Context: \nUsers exercise frequently.\n",
    "output": "<think>Visual information suggests that the user is in a gym, standing in front of a treadmill. However, the user's persona indicates that the user exercise regularly, so the user should be very familiar with fitness equipment and do not require any assistance from me.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is at a bus stop, observing a green bus with the destination 'Kowloon' on its front, near an orange information board possibly checking the bus schedule, with several people waiting or walking around.\"\nPersona Context: \n\n",
    "output": "<think>In a crowded environment, providing bus schedule updates can be helpful for planning and reducing stress. I will offer the next bus arrival information to assist in managing the user's expectations.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to get the current date and time.', 'Use <check_bus_schedule> to check the arrival time of the next bus.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a gym, tying the laces of their shoe, with two red dumbbells and a coiled jump rope on the floor nearby.\"\nPersona Context: \nThe user enjoys guided workouts and tracking fitness progress.\n",
    "output": "<think>The user is likely about to start a workout on the rowing machine. Providing a guided workout plan and tracking their progress would enhance their experience. I should use <get_health_data> to check the user's recent performance and <search_rednote> to find an appropriate rowing workout plan.\n Actions:\n[\"Use <get_health_data> to check the user's recent performance metrics.\", 'Use <search_rednote> to find a guided rowing workout plan.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"guided rowing workout plan\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a cozy living room, standing in front of a large mirror, wearing a green sports bra and patterned leggings, and adjusting their outfit.\"\nPersona Context: \n\n",
    "output": "<think>The user is looking in the mirror and may be preparing to go out, wearing minimal clothing such as short sleeves and shorts. I need to check the weather for the user's location. If the temperature is expected to drop or if rain is forecasted for the day, I can proactively remind the user to dress warmly to avoid catching a cold.\n Actions:\n[\"Use <get_current_gps_coordinates> tool to check the user's current location.\", \"Use <get_city_weather> to check the latest weather forecast for both the user's current location.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is seated at a wooden table, holding a fork and knife, and eating a meal consisting of black pasta, shrimp, and green leafy vegetables, accompanied by a glass of dark liquid and a wooden bowl of additional salad.\"\nPersona Context: \n\n",
    "output": "<think>The user is having a healthy meal, which is a positive habit. There is no need for proactive intervention as this is a normal part of their daily routine.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a kitchen, reaching for a refrigerator and interacting with the refrigerator door, where a bag of potatoes, a carton of eggs, and a box of butter are visible on the top shelf.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is looking at an open refrigerator, with various ingredients visible such as milk, eggs, and vegetables. The user is browsing the refrigerator, possibly to decide on meal ingredients. Without additional information about their plans or preferences, proactive assistance isn't necessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a subway station, looking at a large map of the MTR system, possibly planning a route or checking their current position.\"\nPersona Context: \n\n",
    "output": "<think>The user might need assistance finding the best train route to reach their destination. Providing route options and travel times could enhance their travel experience.\n Actions:\n[\"Use <google_map> to find the best train route to the user's destination, including travel times and any necessary transfers.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"train station\", \"destination\": \"[user's destination]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a pharmacy, looking at various boxes of medication on a shelf, including a prominent green box labeled 'PROSPAN.' The content of conversation is: 'I need a new pair of running shoes. Do you know where is the best store around here?'\"\nPersona Context: \n\n",
    "output": "<think>The friend is looking for sports stores nearby. The user might appreciate a quick lookup of nearby stores and their reviews.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to get the current date and time.', 'Use <google_map> to find and list nearby sports stores that sell running shoes.', 'Use <google_search> to find and list nearby sports stores that sell running shoes, and check their opening hours ites.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"sports stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"sports stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user standing at a bus stop, looking at a bus schedule board under an overpass, with several people waiting and a green and white bus nearby. The content of conversation is: \\\"Do you know how long the next bus arrives?\\\"\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the conversation is focused on the bus schedule. Checking the arrival time of the next bus would provide helpful information for the user and their conversation partner. I should first use <get_current_gps_coordinates> to determine the user's current location. Then, I can use <get_current_datetime> to get the current date and time. Finally, I can use <check_bus_schedule> to find the arrival time of the next bus. If the bus is arriving too late, I can use <book_uber> to help the user book a ride and ask if they need this service.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to get the current date and time.', 'Use <check_bus_schedule> to find the arrival time of the next bus.', 'If the bus is delayed, use <book_uber> to suggest booking alternative transportation.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current location'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user standing at a busy street intersection, observing traffic and pedestrians, with a red double-decker bus crossing and the JR Kanda Station visible, while appearing to wait to cross the street.\"\nPersona Context: \n\n",
    "output": "<think>Context information shows the user is at a busy intersection, possibly trying to navigate. However, without any specific signs of confusion or need for assistance, proactive engagement may not be necessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is in a kitchen arranging cupcakes on a tray, with various decorations such as berries, cookies, and sprinkles, among other ingredients and tools like strawberries, raspberries, macarons, a measuring cup, and a bowl of flour on the kitchen counter.\nPersona Context: \nThe user enjoys baking and experimenting with new recipes.\n",
    "output": "<think>The user is decorating cupcakes, which suggests an interest in baking. I can suggest new decorating techniques or recipes to try next.\n Actions:\n['Use <search_rednote> to find new cupcake decorating techniques or recipes.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"new cupcake decorating techniques or recipes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a restaurant, sitting at a table with a plate of food and a drink, in a modern interior with other patrons present. The content of conversation is: \\\"I'm thinking about getting a new phone. Do you have any recommendations?\\\"\"\nPersona Context: \n\n",
    "output": "<think>Contextual information indicates that the user is chatting with a friend, who is asking for phone recommendations. Providing information about popular and well-reviewed phones could be helpful. Therefore, I can use <google_search> to find information about popular and well-reviewed phones and <search_rednote> to find user reviews and recommendations for these phones.\n Actions:\n['Use <google_search> to find information about popular and well-reviewed phones.', 'Use <search_rednote> to find user reviews and recommendations for these phones.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"popular phones\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"phone reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in an airport terminal holding a passport and boarding pass, wearing a blue jacket and neck pillow, and a blue wristwatch, appearing to prepare for a flight. The agenda shows that the user has a hotel check-in at Victoria Hotel at 7 PM, and GPS detects that the user has arrived in a new city.\"\nPersona Context: \n\n",
    "output": "<think>The agenda shows that the user has a hotel check-in at Victoria Hotel at 7 PM. I can assist by calling a taxi or an Uber. By using <get_current_gps_coordinates>, I can obtain the current location, and since I already know the destination, I can help book a taxi or an Uber using <book_uber>. After booking, I should ask him to confirm if he needs this and inquire if he requires any other assistance. The user might need transportation assistance to the hotel.\n Actions:\n[\"use <get_current_gps_coordinates> to check the user's current location.\", 'Use <google_map> to search for route information.', 'Use <book_uber> to book an Uber from the current location to that Hotel.', 'Ask the user if they need this service and if they need any other assistance.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"Victoria Hotel\"}},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"Victoria Hotel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user sitting at a bus stop, waiting for a bus, wearing a brown coat and glasses. The agenda indicates a meeting at Business Park at 2 PM.\"\nPersona Context: \n\n",
    "output": "<think>The user appears to be waiting for a bus, but the meeting at Business Park at 2 PM requires timely arrival. Verifying the bus schedule and offering an Uber ride if the bus is delayed would be beneficial. Use <get_current_gps_coordinates> to pinpoint the user's location, <get_current_datetime> for the current time, and <check_bus_schedule> to see if the bus will arrive in time. If not, <book_uber> to arrange a ride.\n Actions:\n[\"Use <get_current_gps_coordinates> to pinpoint the user's location.\", 'Use <get_current_datetime> to check the current time.', 'Use <check_bus_schedule> to verify the next bus to Business Park.', 'If the bus is delayed, use <book_uber> to arrange a ride.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current_location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"Business Park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a bicycle store, looking at various road bikes displayed on racks, with a modern, well-lit atmosphere focused on cycling equipment.\"\nPersona Context: \nInterested in fitness and outdoor activities.\n",
    "output": "<think>The user might be looking for a bicycle to start cycling as a new hobby. Providing price comparisons, reviews, and recommendations for beginner-friendly bicycles could be extremely useful.\n Actions:\n['Use <get_online_product_price> to compare prices for the bicycles online.', 'Use <search_rednote> to find user reviews and recommendations for beginner bicycles.', 'Use <google_search> to provide insights on choosing the right bicycle for fitness and outdoor activities.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"bicycle\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"beginner bicycle reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"choosing the right bicycle for fitness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a restaurant, browsing through a digital menu on a tablet with various pasta dishes, beverages, and other food items, appearing to make a decision on what to order.\"\nPersona Context: \nThe user enjoys Italian food but is looking for healthier options.\n",
    "output": "<think>Italian cuisine can be high in calories, especially with dishes like pizza and gelato. Providing calorie counts and suggesting healthier options can help the user make better choices.\n Actions:\n['Use <wikipedia_search> to find calorie counts and health information for pizza, pasta, and gelato.', 'Use <get_medical_knowledge> to provide advice on healthier Italian food options.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for pizza, pasta, and gelato\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for pizza, pasta, and gelato\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a kitchen, preparing vegetables for cooking by placing chopped carrots, squash, and bell peppers on a baking sheet, and then sprinkling olive oil, spices, and dijon mustard over them while mixing.\"\nPersona Context: \n\n",
    "output": "<think>The user is arranging sliced vegetables on a tray, a routine task that doesn't necessitate any assistance. The task appears to be proceeding smoothly.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a desk in a well-lit room, typing on a laptop with a blank white screen, in a comfortable and modern workspace with green plants and a window in the background.\nPersona Context: \n\n",
    "output": "<think>The user is focused on their work and does not appear to require any assistance. Providing proactive suggestions might interrupt their workflow unnecessarily.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is at a bus stop waiting for a bus labeled '88X' and 'TO PING TIN,' with several people nearby, some with luggage, in an urban area with modern buildings and an overcast sky. The content of conversation is: 'We don't know how long until the next bus arrives.'\"\nPersona Context: \n\n",
    "output": "<think>The user is concerned about potential delays caused by the rain. Providing real-time bus schedule updates would be beneficial. I should determine the user's location using <get_current_gps_coordinates>, check the current time using <get_current_datetime>, and use <check_bus_schedule> to provide the next bus time.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <get_current_datetime> to get the current date and time.', 'Use <check_bus_schedule> to find the arrival time of the next bus.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"'current location'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a classroom setting, sitting at a desk with a purple cushion on the floor. The user appears to be engaged in a discussion or meeting with another individual. The content of conversation is: 'We need to finalize the project timeline by tomorrow. Yes, I'll agree.'\"\nPersona Context: \n\n",
    "output": "<think>The user might need to add this event deadline to their calendar or agenda app. So I should first use <get_current_datetime> to check today's date and find out tomorrow's date. Then I should use the <add_to_agenda> to write down this event on the corresponding time.\n Actions:\n[\"Use <get_current_datetime> to check today's date and find out tomorrow's date.\", 'Use <add_to_agenda> and write down this events on the corresponding time .', 'Provide a reminder to finalize the timeline by tomorrow.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"finalize the project timeline\",\"time\": \"tomorrow\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a shopping mall, walking through a spacious area with polished white flooring, moving towards an escalator. The content of conversation is: \\\"I will try the new Italian restaurant on the third floor. Everyone is talking about this.\\\"\"\nPersona Context: \nFoodie\n",
    "output": "<think>Since the contextual information shows there is a conversation, and the partner asks the user: \"Have you tried that new Italian restaurant on the third floor? Everyone's talking about it.\". The user's persona as a 'Foodie' indicates they might be interested in trying new restaurants. Proactively providing information about the restaurant, such as its menu, hours, or reviews, could enhance the conversation. So I can use <google_search> to look up details about the new Italian restaurant on the third floor of the mall, including the menu, opening hours, and reviews. This information can be shared with the user to enrich their conversation.\n Actions:\n['Use <google_search> to look up details about the new Italian restaurant on the third floor of the mall, including the menu, opening hours, and reviews.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new Italian restaurant third floor shopping mall\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a dimly lit room with neon lighting, surrounded by a group of young adults holding disposable cups and engaged in conversation, in front of a graffiti-covered wall, suggesting they are at a club or party.\"\nPersona Context: \nOutgoing\n",
    "output": "<think>The user is enjoying a night out with friends in a social setting. Given their outgoing persona, proactive assistance is not needed, as it may disrupt their social engagement.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a hallway of a building, walking towards an elevator with wet floors reflecting the overhead lights. The elevator doors are closed, and a trash bin is placed next to the elevator.\nPersona Context: \n\n",
    "output": "<think>Based on the available context, the user is near an elevator in a hallway. No further action is implied without user input or additional contextual clues. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is hiking along a dirt path surrounded by lush greenery and coniferous trees, heading towards a prominent mountain peak under a clear blue sky.\"\nPersona Context: \n\n",
    "output": "<think>The user is likely enjoying a solitary hiking experience in nature. There is no indication of a need for assistance, as they are probably relishing the tranquility. Proactive intervention would not be necessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user relaxing on a hammock in an outdoor park setting with clear, sunny weather.\nPersona Context: \n\n",
    "output": "<think>The user is in a perfect setting for relaxation. Without any explicit interest or need for assistance, proactive service is not necessary. They seem to be enjoying their leisure time.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a grocery store, browsing a display case filled with various packaged meats and cheeses labeled 'Top Pick,' possibly considering which items to purchase.\"\nPersona Context: \nUser often struggles with deciding what to cook.. The user prefers quick and easy recipes due to their busy schedule.\n",
    "output": "<think>Contextual information shows the user is browsing the meat and seafood section in a large supermarket. The user might be unsure about what to cook and could benefit from quick and easy recipe suggestions. They should first check the current time to determine whether they are planning for lunch, dinner, or meal prep. Then, they can search for simple recipes on the Rednote app. Additionally, since the user is in the supermarket, providing online prices for common food could help them plan their budget.\n Actions:\n['Use <get_current_datetime> tool to check the current time and date.', 'Search <search_rednote> tool to find healthy and balanced recipes featuring meat or seafood.', 'Provide the user with online prices for the type of meat or seafood they are considering to help them budget.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"salmon\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"healthy recipes with chicken or seafood\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user seated on a couch, holding a stack of restaurant menus and browsing through them, possibly deciding what to order.\"\nPersona Context: \nThe user is health-conscious and wants to make informed dietary choices.\n",
    "output": "<think>The user could benefit from information about the calorie counts and heating information of these foods. Providing insights into which dishes are lighter or healthier could assist their decision-making.\n Actions:\n['Use <wikipedia_search> to find calorie counts and heating information for Kung Pao chicken, sweet and sour pork, and fried rice.', 'Use <get_medical_knowledge> to gather health-related insights about these dishes.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information of these foods for Kung Pao chicken, sweet and sour pork, fried rice\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts and heating information about Kung Pao chicken, sweet and sour pork, and fried rice\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user walking along a cobblestone path in a park, surrounded by lush greenery and approaching a bench on the right side of the path, with trees and a building visible in the background.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is in a park, enjoying a walk. Without additional persona information or events indicating a specific need for assistance, it is likely that the user is enjoying the tranquility. Therefore, it would be inappropriate to interrupt their experience. So I will give the proactive score as 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is driving a vehicle on a sunny day, approaching a gas station with a '76' sign and a green canopy, and preparing to stop at a traffic light.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows that the user is driving a car, with their hand on the steering wheel. The sky is clear and blue, indicating a sunny day. Because driving demands full attention and I do not have additional information about the user's persona or preferences, I think it is best not to interrupt. Therefore, I will set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park focusing on a vintage camera with a large lens, capturing a view of a white church with a golden dome surrounded by trees and a parked car.\nPersona Context: \n\n",
    "output": "<think>The user is engaged in a leisurely activity of exploring and taking photos in a city square. There is no indication of a need for assistance, as they seem to be enjoying the experience. Proactive intervention would be unnecessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a clothing store, looking at a display of T-shirts priced at $99 each, with a variety of colors including gray and beige.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information indicates that the user is browsing through a clothing store. When the user wants to buy something, they may wonder about the online price of the product for comparison, as well as reviews and comments from other customers. Therefore, providing the user with the online price and customer reviews of the product could be helpful.\n Actions:\n['Use <get_online_product_price> to find the prices of the shirts the user is looking at.', 'Use <search_rednote> to find customer reviews and comments on the shirts.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"shirt\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"shirt reviews and comments\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an urban setting on a balcony or terrace with a red cup filled with a brown liquid, likely tea or coffee, placed near potted plants with green leaves, and there are tall buildings and a street with cars and pedestrians in the background.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a moment of relaxation on a balcony with a cup of coffee. There is no indication of a need for assistance, as the user is likely savoring the tranquility. Proactive assistance would be unnecessary and potentially disruptive.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is walking on a brick-paved sidewalk adjacent to a road, lined with greenery and trees, with a white car parked on the street.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows user is walking on the road. There are many trees on both sides of the road, and the road seems to be going uphill. Without explicit input or additional contextual information, no proactive actions are required. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a McDonald's restaurant, browsing through the digital menu on a touch-screen kiosk and pointing at different menu options, indicating they are making a selection.\"\nPersona Context: \nThe user is aware of their diet and is looking to make healthier choices even in a fast-food setting.\n",
    "output": "<think>Fast food can be high in calories, fat, and sugar. Providing nutritional information and suggesting healthier alternatives can help the user make a better choice.\n Actions:\n['Use <wikipedia_search> to find calorie counts and health information for cheeseburgers, fries, and soda.', 'Use <get_medical_knowledge> to provide insights on healthier fast-food options.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for cheeseburgers, fries, and soda\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for cheeseburgers, fries, and soda\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a dance studio, participating in a lively dance class with a group of women, all dressed in workout clothes and following the instructor's lead.\"\nPersona Context: \nThe user likes to listen to high-energy music during workouts to enhance performance.\n",
    "output": "<think>The user is about to start an aerobic dance class. High-energy music could enhance their workout performance and enjoyment.\n Actions:\n[\"Use <play_music> to play high-energy music to enhance the user's aerobic dance workout.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a gym, standing in front of a stationary treadmill, appearing to be preparing to use it.\"\nPersona Context: \nThis user likes to listen to music while running.\n",
    "output": "<think>The user might be planning to start a workout session on the treadmill. They could benefit from a personalized workout plan or motivation tips. Since the user's persona indicates the user likes to listen to music while running, I should open the music app to suggest a playlist.\n Actions:\n[\"Use the <get_health_data> tool to check the user's fitness level.\", \"Play a song from the user's music library to enhance the workout experience.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\":\"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a room with a wooden floor, looking at a suitcase filled with various items including a blue sweater and a patterned bag, suggesting the user is packing or unpacking. The agenda indicates that the user is departing for Canada.\"\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is preparing to travel to Canada. When traveling to a different country, it's essential to check the local weather to ensure the clothing packed is suitable. I need to use the <get_city_weather> tool to check the current and upcoming conditions in Canada. To provide the weather forecast for the user's current location, I can use the <get_current_gps_coordinates> tool.\n Actions:\n[\"Use <get_current_gps_coordinates> to check the user's current location.\", \"Use <get_city_weather> to check the latest weather forecast for both the user's current location and their destination.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Canada\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a gardening or planting setup, surrounded by various gardening tools and materials, wearing white gloves, and holding a small shovel while digging into a bag of soil, with several empty biodegradable pots, a potted plant, and plant tags nearby.\nPersona Context: \n\n",
    "output": "<think>The user is gardening. Without additional information, I should not proactively generate content that might burden the user.\n Actions:\n[]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a gym, holding a barbell with both hands and preparing to perform an exercise, with gym equipment like a treadmill visible in the background.\"\nPersona Context: \n\n",
    "output": "<think>The user might need guidance on proper weightlifting techniques or reminders to take breaks between sets. However, without detailed persona information, such as their fitness level, I would rate this proactive behavior at 2 points. This rating indicates some potential for proactivity, but the necessity is not very high. After collecting more detailed persona information, I could provide more accurate proactive services.\n Actions:\n['Use <vllm> to identify the equipment the user currently uses.', 'Refer to <wikipedia_search> or <google_search> for guidance on properly using the current equipment.', \"Use <get_health_data> to check the user's current physiological indicators, such as heart rate, SpO2, and respiration rate, using the fitness app.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"identify the equipment they currently use.\",\"image_path\":\"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"guidance on properly using the current equipment.\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"guidance on properly using the current equipment.\"}},{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking along a cobblestone path in a park bordered by lush greenery and red flowers, with a yellow barrier and a white post visible on the left side, indicating it is daytime.\nPersona Context: \n\n",
    "output": "<think>The user usually exercises outdoors, so it might be helpful to provide weather updates and current physiological indicators. I can also provide a hydration reminder if the jog exceeds 30 minutes. However, without additional personal and contextual information, I can only assign a proactive score of 2.\n Actions:\n[\"Use the <get_current_gps_coordinates> tool to track the user's location and confirm they are jogging in a park.\", 'Use the <get_current_datetime> tool to calculate the duration of the jog.', 'Use the <get_health_data> tool to provide basic physiological indicators for the user, such as heart rate, blood samples, respiration, steps, and more.', 'Provide a hydration reminder if the jog exceeds 30 minutes.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in a kitchen, using a turquoise KitchenAid stand mixer to mix a creamy mixture in a stainless steel bowl, with the mixer actively blending the ingredients to create a smooth consistency.\"\nPersona Context: \n\n",
    "output": "<think>The user is engaged in a common cooking task using an electric mixer. There are no challenges or complexities visible that would necessitate proactive assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is packing a suitcase on a bed, which contains clothes, a pink bag, and a book titled 'The Story of Philosophy,' while placing a framed picture into the suitcase.\"\nPersona Context: \n\n",
    "output": "<think>The user is comfortably settled in their hotel room and engaged in the task of unpacking. There is no immediate need for proactive assistance as they seem well-acquainted with their surroundings.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in an office setting, sitting at a desk with a laptop open, reviewing or organizing documents amid a cluttered desk with various documents, folders, and a smartphone.\"\nPersona Context: \n\n",
    "output": "<think>The user appears to be engaged in routine work in their cubicle, focused on a document. There are no signs of need for assistance. Proactive intervention might disrupt their workflow.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a busy indoor shopping mall, New Town Plaza, walking through a crowded area. The user's agenda shows a meeting at 6 PM.\nPersona Context: \n\n",
    "output": "<think>Given the crowded situation and the upcoming meeting, offering to book an Uber could help the user avoid delays and ensure they arrive on time. I should use <get_current_gps_coordinates> to determine the user's current location and then <book_uber> to arrange transportation to the meeting.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <book_uber> to book an Uber to the meeting location.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"meeting location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a grocery store, looking at the produce section and holding a yellow container with a lid. The content of conversation is: \"Are these banana strips enough to eat today?\"\nPersona Context: \n\n",
    "output": "<think>The user might be wondering whether the bananas are ripe enough to eat immediately. I should use vllm (visual language model) to assess the ripeness of the bananas.\n Actions:\n['Use vllm (visual language model) to analyze the ripeness of the bananas based on their color and appearance.', 'Provide a recommendation on whether the bananas are ready to eat or need more time to ripen.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"Detect the ripeness of the bananas.\",\"image_path\":\"\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a store, looking at a display of office furniture, including a wooden desk with a clock and books, a black rolling cart with papers, and a white folding chair, with a metal wire basket under the desk.\"\nPersona Context: \nWorks from home and values comfort and ergonomics in furniture.\n",
    "output": "<think>The user might be selecting furniture for their home office, focusing on ergonomics. Providing price comparisons, reviews, and ergonomic recommendations could help them make a comfortable and informed choice.\n Actions:\n['Use <get_online_product_price> to check prices for the desks and chairs online.', 'Use <search_rednote> to find user reviews and ergonomic recommendations for office furniture.', 'Use <google_search> to provide insights on the best ergonomic furniture for home offices.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"desk and chair\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"ergonomic office furniture reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"best ergonomic furniture for home office\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a kitchen, preparing pancakes by pouring batter into a frying pan on the stove, with a hexagonal tile backsplash and a bowl of eggs on the counter. A stack of pancakes is visible on a plate in the foreground.\"\nPersona Context: \n\n",
    "output": "<think>The user is cooking pancakes, a simple and routine breakfast task. There are no indications of any challenges or need for assistance. Without additoinal persona information, proactive engagement is not necessary.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in an Apple store, looking at a display of iPhone 16 Plus models arranged on a wooden table.\"\nPersona Context: \n\n",
    "output": "<think>The user might appreciate assistance in comparing prices and reviews for the smartphones they are looking at. Providing this information could help them make an informed decision.\n Actions:\n['Use <get_online_product_price> to compare the prices of the smartphones online.', 'Use <search_rednote> to retrieve user reviews and recommendations for the models being compared.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smartphone\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"smartphone reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in an office setting, sitting at a desk with a laptop displaying a spreadsheet, typing or navigating it, in a tech or programming environment. The content of conversation is: \"Please prepare the final budget report by next Friday.\" Mobile data indicates the final budget report is due next Friday.\nPersona Context: \nThe user is a financial analyst responsible for budget management.\n",
    "output": "<think>The user should prioritize preparing the budget report by next Friday. I should check their agenda for any conflicts and suggest scheduling dedicated time to work on it.\n Actions:\n[\"Use <get_current_datetime> to determine the current date and next Friday's date.\", 'Use <check_agenda_time_conflict> to ensure there are no conflicts for preparing the budget report.', \"Suggest adding a dedicated time block to the user's agenda to work on the report.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare final budget report\", \"time\": \"before next Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user seated at an outdoor caf\u00e9 table, surrounded by other patrons, with cups, saucers, and a glass of milk on the table, while engaging with their smartphone in a busy urban setting.\"\nPersona Context: \n\n",
    "output": "<think>The user is at a caf\u00e9, likely enjoying a break during their travels. Without signs of needing directions or assistance, proactive engagement would be unnecessary and could disrupt their leisure.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a gym, standing in front of a rack of kettlebells, with a gray gym floor marked by a white 'X.'\"\nPersona Context: \nNew to fitness and unfamiliar with proper lifting techniques.\n",
    "output": "<think>The user appears unsure about how to use the free weights correctly. Given their persona of being new to fitness, they could benefit from guidance on proper form to prevent injury. Proactively providing this information will enhance their workout experience and safety.\n Actions:\n['Use <search_rednote> to find guides on proper lifting techniques for beginners.', 'Use <vllm> to identify the specific weights and provide visual cues for correct form.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"proper lifting techniques for beginners\"}}, {\"name\": \"vllm\", \"description\": \" Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"correct form for lifting weights\",\"image_path\":\"\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a serene, natural landscape with rolling green hills, a clear blue sky, and a winding dirt road bordered by a stone fence and lush greenery, with several people scattered along the path.\nPersona Context: \nThe user enjoys uplifting music while exploring nature.\n",
    "output": "<think>The user is hiking, an activity where music can enhance the experience. Since the user enjoys uplifting music while exploring nature, offering to play such a playlist could elevate their hiking adventure.\n Actions:\n[\"Use <play_music> to play an uplifting playlist to enhance the user's hiking experience.\"]\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking on a sidewalk with tactile paving, a yellow line, and surrounded by greenery. The user appears to be walking towards a bus stop marked on the road, with a speed limit of 30 km/h, and there is another person on the sidewalk holding a blue bag.\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user is walking on the road. Without explicit input or additional contextual information, no proactive actions are required. The proactive score is set to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is in a grocery store, pushing a shopping cart filled with various items including a container of cherries, a bag of bananas, a box of eggs, a bag of cookies, and a melon wrapped in netting, indicating the user is actively shopping.\"\nPersona Context: \n\n",
    "output": "<think>The user is browsing produce at a supermarket, indicating they might be grocery shopping. Without additional information, there is no need for proactive assistance. The user appears to be making decisions independently.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park, observing a serene pond with lush greenery, a stone bridge, and vibrant pink flowers. The content of conversation is: \"It's peaceful here. Do you know is there a cafe nearby where we can grab some coffee?\"\nPersona Context: \n\n",
    "output": "<think>The user is interested in finding a nearby caf\u00e9. Providing directions and options for well-reviewed caf\u00e9s could enhance their experience.\n Actions:\n[\"Use <get_current_gps_coordinates> to determine the user's current location.\", 'Use <google_search> to find nearby caf\u00e9s with good reviews and provide directions.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"caf\\u00e9s near the park with good reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user in an office setting, typing on a white keyboard in front of a computer monitor and occasionally writing on a notepad with red writing. The user is wearing a suit and a pink tie.\"\nPersona Context: \n\n",
    "output": "<think>The user is focused on writing or responding to emails, an activity that demands concentration. Proactive assistance is not needed, as it might interfere with their task.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a serene outdoor setting, observing a beautiful sunset over a calm body of water, framed by a wooden structure with intricate carvings and a hanging bell in the foreground. The user appears to be stationary, taking in the tranquil view.\nPersona Context: \n\n",
    "output": "<think>Contextual information shows the user enjoying the view of a sunset from a balcony. The user is likely unwinding and enjoying the moment. However, the current information does not support generating proactive service, as proactive assistance might disrupt their relaxation. Therefore, I have set the proactive score to 1.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is sitting on the grass in a park, holding a sketchbook and drawing a flower, with various drawings of plants and flowers visible in the sketchbook.\nPersona Context: \nThe user is an amateur artist with an interest in plants.\n",
    "output": "<think>The user might be interested in learning more about the flowers they are sketching. Providing botanical information could enrich their artistic process. I should use <vllm> to identify the flowers and <wikipedia_search> for detailed botanical information.\n Actions:\n['Use <vllm> to identify the flowers the user is sketching.', 'Use <wikipedia_search> to provide information on these flower species.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify flowers in the sketch.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Hibiscus flower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a restaurant, looking at an open menu displayed on a stand, featuring various noodle dishes with pictures, and considering their order.\nPersona Context: \nThe user likes Chinese food but wants to make healthier choices.\n",
    "output": "<think>Chinese food can be high in calories and sodium. Providing calorie counts and suggesting healthier options can help the user make better choices.\n Actions:\n['Use <wikipedia_search> to find calorie counts and health information for dumplings, fried rice, and sweet and sour chicken.', 'Use <get_medical_knowledge> to provide insights on healthier Chinese food options.']\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for dumplings, fried rice, and sweet and sour chicken\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for dumplings, fried rice, and sweet and sour chicken\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a caf\u00e9, standing at the counter of \"WeCafe Salad & Coffee,\" wearing a black shirt with the text \"Salad Lovers' Cafe\" and a green apron. There are two other individuals behind the counter, one of whom is talking on a phone, in a caf\u00e9 with a modern, rustic design.\nPersona Context: \n\n",
    "output": "<think>The user is waiting in line at a coffee shop, an ordinary activity with no immediate need for assistance. The user is likely to place an order once it is their turn. Proactive intervention is not required.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates that the user is in a dining setting, observing a plate of assorted sliced fruits, including a green pear, sliced apples, bananas, and tangerines, on a table set with a white tablecloth, wine glasses, and a neatly folded napkin.\"\nPersona Context: \n\n",
    "output": "<think>The user is preparing to work with fruits, likely for a salad or snack. This is a straightforward task with no signs of difficulty or need for assistance. Without additional persona information, I think there is no need for proactive assistance.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information shows the user is inside a moving train, looking out the window at the passing scenery, with blue and white seats and yellow handrails visible.\"\nPersona Context: \n\n",
    "output": "<think>The user is on a subway journey, possibly heading to a destination. Without more context on their plans or destination, proactive assistance isn't necessary unless they exhibit signs of confusion or need.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking on a sidewalk in an urban area, holding a white mug with black text, and following a child in a pink dress.\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a walk through the park with a coffee in hand. There are no indications of a need for assistance, as they appear to be enjoying their leisure time.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \n\"Visual information indicates the user is in a backyard setting, grilling food on a barbecue while holding a glass of wine and a towel over their shoulder, with another person nearby holding a beer bottle and watching the grilling process, surrounded by greenery and plants.\"\nPersona Context: \n\n",
    "output": "<think>The user is enjoying a social event with friends at a barbecue. Proactive assistance is unnecessary, as it could interrupt their social interactions.\n Actions:\nNone\n <\\think>\n ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  }
]