[
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a pharmacy comparing different pain relievers, specifically ibuprofen and acetaminophen.\nPersona Context: \nA working professional who suffers from occasional migraines and is seeking the most effective over-the-counter treatment\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"ibuprofen versus acetaminophen for migraine treatment effectiveness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is stirring a pot of soup on the stove. The task seems to be progressing without any issues.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is camping in a remote wooded area and shows signs of a possible allergic reaction with swelling and red marks while setting up camp.\nPersona Context: \nA nature enthusiast with documented mild nut allergies\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"managing mild allergic reactions in remote wilderness settings\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a small meeting room, possibly reviewing or preparing notes on the whiteboard.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing a souvenir shop with clearly marked prices, examining various local items and crafts while other customers are also shopping.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is consuming a healthy meal, consisting of a salad with various vegetables, at their dining table.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a meeting about performance reviews. Audio indicates a deadline for completing reviews by next Monday.\nPersona Context: \nThe user is a manager responsible for conducting performance reviews.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Monday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete performance reviews\", \"time\": \"before next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is enjoying a meal at a restaurant.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at home, watching a movie on their TV.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a desk, focused on a slide presentation on a large computer monitor.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a workspace with a computer setup. The main focus is on a large monitor displaying a colorful desktop background featuring geometric shapes in vibrant colors. The user may be working.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing at a bus stop with a timetable visible on a nearby pole.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting on a park bench, gazing at a small pond where ducks are swimming. The park is peaceful with trees providing shade.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is washing fresh vegetables in the kitchen sink, a routine task in meal preparation.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a fast-food restaurant, browsing a digital menu with options like a double cheeseburger, large fries, and a milkshake.\nPersona Context: \nThe user is trying to balance fast food convenience with healthier eating options.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for double cheeseburger, large fries, and milkshake\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for double cheeseburger, large fries, and milkshake\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a public beach, sitting on a towel while observing other beachgoers swimming and sunbathing. A lifeguard station is visible nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is chatting with a colleague in a break room. There\u2019s a small whiteboard showing brainstorm notes in the background. There is a conversation: \"How about a weekend trip to Seoul? I really want to explore Myeongdong and maybe go up N Seoul Tower.\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Seoul\", \"time\": \"this weekend\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is socializing with friends or family in a living room setting, where someone is sharing a humorous anecdote about their cousin's embarrassing situation.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is washing lettuce, likely preparing ingredients for a salad. They have the necessary tools (colander, cutting board, knife) ready for food preparation.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook pasta on the stove.\nPersona Context: \nThe user is a beginner cook who often seeks simple recipes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tips for cooking pasta and quick sauce recipes\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"10 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a farmer's market examining unusual heirloom eggplants called 'Listada de Gandia'. The vendor mentioned they're less bitter and good for grilling.\nPersona Context: \nAn amateur home cook interested in experimenting with unique ingredients\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Listada de Gandia eggplant recipes cooking methods origin\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API.\", \"parameters\": {\"query\": \"Listada de Gandia eggplant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a meal at home, eating a sandwich in their kitchen.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a light stretching routine in front of a mirror, possibly as part of a morning ritual.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having dinner at a restaurant with someone they haven't seen in a while, engaging in casual catch-up conversation about their lives.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a flyer for a blood donation drive happening this Saturday from 9 AM to 4 PM at the local community center.\nPersona Context: \nAn active community member who regularly participates in local volunteer activities\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Saturday 9 AM to 4 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Blood Donation Drive at Community Center\", \"time\": \"this Saturday 10 AM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in the kitchen with various spices on the counter.\nPersona Context: \nUser enjoys learning about international dishes and experimenting with new flavors.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"international recipes using spices\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is peeling potatoes, with some already peeled in a bowl and others waiting to be peeled. They're using a peeler and have a knife ready on a cutting board.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the process of food preparation, specifically chopping vegetables including bell pepper and onion.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting on a park bench, enjoying the view of children playing.\nPersona Context: \nNature lover\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is knitting with blue yarn in their living room, following a pattern from an open book nearby. They have tea within reach and a cat sleeping on a couch in the same room.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a hammock in their backyard, enjoying the sunlight filtering through the trees.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is carefully reviewing printed documents, which suggests focused and detailed work.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a video conference with several participants, likely discussing work-related topics.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a grocery store comparing different pasta sauce options, appearing indecisive.\nPersona Context: \nA health-conscious home cook who enjoys preparing Italian meals but must monitor sodium intake due to high blood pressure\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"low sodium pasta sauce options\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"low sodium pasta sauce\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"low sodium pasta sauce\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working in a cubicle, likely reviewing or preparing a progress report on their desktop computer, surrounded by relevant files.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is constructing a model airplane.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to bake a dessert following a recipe from the cookbook.\nPersona Context: \nThe user enjoys baking but sometimes struggles with precise measurements.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"measuring techniques and conversion charts for baking\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is weighing themselves on a bathroom scale as part of what appears to be a personal health monitoring routine.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is waiting in line at a theme park for a roller coaster ride.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is practicing golf at a driving range.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a doctor's office, reading a pamphlet on a small table.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop with a suitcase, likely heading to JFK Airport for a flight at 3 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current_location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"JFK Airport\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is performing a precise technical repair or maintenance task on an electronic device, following a methodical process with organized tools and reference materials.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is driving a car, with their hand on the steering wheel. The sky is clear and blue, indicating a sunny day.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a hotel lobby browsing tourist information about local attractions.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"top-rated attractions in [location]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a scenic mountain viewpoint. Several mountain peaks are visible in the distance, with snow caps visible on the tallest ones. A wooden information board stands nearby but is too far to read clearly.\nPersona Context: \nA travel enthusiast who enjoys learning about geographical features and landmarks\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Rocky Mountain National Park notable peaks Longs Peak\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is discussing their upcoming half-marathon participation while consuming caffeine at a coffee shop.\nPersona Context: \nAn amateur runner who participates in occasional races but struggles with pre-race anxiety\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a bakery, browsing a display with options such as croissants, muffins, and cookies.\nPersona Context: \nThe user loves baked goods but wants to make healthier choices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for croissants, muffins, and cookies\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for croissants, muffins, and cookies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is collecting printed documents from a functioning printer in an office setting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a panoramic view from a hilltop, with a valley below and mountains in the distance.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a forest trail and has encountered a distinctive bright red mushroom with white spots growing near the path.\nPersona Context: \nAn amateur naturalist who enjoys identifying flora and fauna during outdoor excursions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Amanita muscaria fly agaric mushroom identification toxicity\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a grocery store aisle, examining pasta sauces and possibly having trouble reading the labels, which might indicate a need for assistance with nutritional information or price comparison.\nPersona Context: \nA health-conscious shopper who carefully reads nutrition labels.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"pasta sauce\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"pasta sauce nutritional information health ratings\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is setting up camp as daylight is fading. They have started to set up their tent but haven't completed the process.\nPersona Context: \nAn occasional camper who enjoys weekend getaways but lacks extensive outdoor survival skills\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"quick tent setup guide and cold weather camping preparation tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking through a park, holding a take-out coffee cup.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden photographing a distinctive purple flowering plant. Someone nearby has asked about the identity of the plant, suggesting interest in learning more about it.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this purple flowering plant species\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Passiflora incarnata purple passionflower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual informatin shows the user is standing in front of a shelf in a grocery store, looking at different brands of cereal.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Brand A cereal, Brand B cereal, Brand C cereal\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"nutritional information for cereal brands\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is boiling pasta in a pot of water on the stove.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a park with a group of friends enjoying a picnic. Audio captures a suggestion to play some music to enhance the atmosphere.\nPersona Context: \nThe user enjoys music and likes to create a joyful ambiance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in an open-plan office with a whiteboard showing project timelines. Audio captures a conversation. A colleague says: 'Let's schedule a team meeting to go over the project milestones next Thursday.'\nPersona Context: \nThe user is a project manager responsible for coordinating team efforts.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Thursday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Team meeting to discuss project milestones\", \"time\": \"next Thursday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a meeting about submitting the marketing strategy document by Wednesday.\nPersona Context: \nThe user is a marketing manager responsible for strategy development.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Wednesday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete marketing strategy document\", \"time\": \"by Wednesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is operating a forklift, transporting pallets of boxes within a warehouse.\nPersona Context: \nA warehouse worker prioritizing safety and efficiency while operating heavy machinery.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a train station platform viewing a departures board showing delayed trains. They appear concerned about time, repeatedly checking their watch. According to their mobile data, they have a client meeting at Millennium Tower scheduled for 10:30 AM.\nPersona Context: \nA business consultant who values punctuality and professionalism with clients\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current train station\", \"destination\": \"Millennium Tower\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"current train station\", \"destination\": \"Millennium Tower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an art gallery, observing a painting labeled 'Impressionism.'\nPersona Context: \nArt enthusiast\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Impressionism and artist information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining a series of animal tracks in mud along a woodland trail. The tracks appear to be from a medium-sized animal with four toes and claw marks..\nPersona Context: \nAn urban dweller on a weekend nature trip who has limited knowledge of wildlife but is curious about animal identification\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify what animal made these tracks based on paw print pattern and size\", \"image_path\": \"\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Coyote behavior Pacific Northwest wildlife safety\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport where their flight to San Francisco has been delayed by over 3 hours, from 2:15 PM to 5:30 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Today evening after 7:30 PM in San Francisco\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a bus stop in heavy rain. Their view shows several people huddled under the small shelter, which is already crowded. Water is pooling on the ground and the user's shoes are visible at the bottom of the frame, getting soaked.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current location bus stop\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"current GPS coordinates\", \"destination\": \"user's likely destination based on routine\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is hiking in a forest. The audio information shows the user appears lost and unsure of their location.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Use Google Maps to provide navigation instructions.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"trailhead\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a technology expo, interested in smart home technology.\nPersona Context: \nThe user is tech-savvy and interested in smart home innovations.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"smart home technology features and compatibility\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"smart home technology\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a caf\u00e9 in a foreign city, enjoying a drink and the view of passersby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is enjoying a comedy movie with friends in a living room setting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach, lying on a towel with personal items nearby, and appears to be enjoying the sunshine and peaceful atmosphere.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to bake chocolate chip cookies, following a recipe from a cookbook. They have gathered ingredients including flour, eggs, sugar, and butter.\nPersona Context: \nA home baker who enjoys trying new recipes but sometimes struggles with measurements and timing\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tips for perfect chocolate chip cookies\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"baking time\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a hike on a well-marked trail with clear weather conditions. The environment is calm and scenic.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a park while reading a book. The environment is peaceful with other park visitors engaged in their own activities.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the person is packing a suitcase with summer clothes like t-shirts and shorts. The agenda indicates that the user is departing for Switzerland.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Switzerland\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a Chinese restaurant, browsing a menu with various options such as Kung Pao chicken, sweet and sour pork, and fried rice.\nPersona Context: \nThe user is health-conscious and wants to make informed dietary choices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information of these foods for Kung Pao chicken, sweet and sour pork, fried rice\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts and heating information about Kung Pao chicken, sweet and sour pork, and fried rice\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting at a park bench. Audio information shows the user is engaged in a conversation with a friend. The friend says: \"I heard there's a great jazz concert happening downtown this Saturday. Do you know anything about it?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"jazz concert downtown this Saturday.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user has been sitting at the desk at home, studying for an extended period.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user standing at a bus stop with a suitcase, looking at the bus schedule.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook a vegetable stir-fry. They have fresh vegetables ready on a cutting board, and a pot of water is starting to boil on the stove. They're following a recipe displayed on a tablet.\nPersona Context: \nA health-conscious cook who likes to prepare nutritious meals but often gets timing wrong when cooking multiple ingredients\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"optimal cooking times for vegetables in stir-fry\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"vegetable blanching time\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a companion are on a beach as the sky darkens. There is a conversation: \"These waves look stronger than usual. Do you think a storm\u2019s rolling in?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is studying from a textbook in a library, taking notes and using highlighters to mark important information in a quiet, focused environment.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing fiction books in a bookstore.\nPersona Context: \nThe user enjoys listening to classical music while reading and browsing books.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a sunset view from their balcony, surrounded by potted plants while birds fly across the colorful evening sky.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is setting up a campsite in a forest clearing at sunset, having pitched a tent and now arranging logs for a campfire.\nPersona Context: \nAn outdoor enthusiast who enjoys ambient folk music during evening camping activities\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a 4-person camping tent priced at $329.95 in an outdoor equipment store.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"4-person premium camping tent\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"camping tent waterproof rating rain performance setup time\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a coffee shop with a friend. Audio captures a conversation where a friend suggests going to an art exhibition this weekend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for details about the art exhibition.\", \"parameters\": {\"query\": \"art exhibition this weekend\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Visit art exhibition\", \"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is exploring a community garden with medicinal plants and herbs, overhearing a conversation about the plants' healing properties.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a focused coding session at their desk in an open-plan office, referencing documentation while writing code.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the middle of a structured arm workout at the gym, following what appears to be a planned routine tracked on their fitness app. They're maintaining proper form and staying hydrated.\nPersona Context: \nA fitness enthusiast who follows structured workout plans and tracks progress through mobile apps\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an art gallery that's closing soon. It's dark and raining heavily outside. They have a dinner reservation at Bella Italia Restaurant at 8:30 PM.\nPersona Context: \nA cultural enthusiast who enjoys fine dining experiences after visiting artistic exhibitions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get directions and estimated time to a destination.\", \"parameters\": {\"origin\": \"current location\", \"destination\": \"Bella Italia Restaurant\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Art Gallery\", \"destination\": \"Bella Italia Restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop, indicating potential travel plans.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading and taking notes in a library environment, with other people studying nearby in the quiet space.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a knitting project in a comfortable home environment, with organized supplies and a relaxed setting.\nPersona Context: \nA hobbyist who finds peace in creating handmade items and enjoys the meditative aspects of repetitive crafting\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting in a park, observing children playing soccer in an open field. The atmosphere is lively and joyful.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a professional panel discussion on AI in supply chain optimization. The speaker's name and company are visible, and they are discussing AI-driven logistics.\nPersona Context: \nThe user is interested in AI applications in business.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"Acme Corp AI initiatives in logistics.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is hiking on a trail in a dense forest under a clear blue sky.\nPersona Context: \nThe user enjoys uplifting music while exploring nature.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing zucchini noodles with a spiralizer, with a pan heating on the stove and sauce ingredients ready nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a kitchen, carefully chopping vegetables in an organized manner, suggesting they are preparing ingredients for a meal. The process appears deliberate and controlled.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is rolling out dough on a countertop, likely preparing to bake or cook.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop near an office park, holding a briefcase, and has an important presentation scheduled for 11:00 AM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"office park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a library, browsing titles.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is walking near a busy street and looking at a bus stop named 'University.'.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'University'\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a theme park that's closing. A text message indicates their expected ride has had car troubles and can't pick them up.\nPersona Context: \nA teenager enjoying a day at the theme park who was expecting to be picked up by a parent\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Theme park exit\", \"destination\": \"User's home address\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is checking into a hotel in City Y, possibly for leisure or business travel.\nPersona Context: \nThe user appreciates comfort and amenities during their stay.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"hotel amenities and services in City Y\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing by a hotel pool during vacation, reading a book and enjoying the sunny weather.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is holding premium coffee maker in electronics store. Price tag shows $399.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"coffee maker\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a cafe, enjoying a conversation with a friend. The atmosphere is lively but relaxed, with no indication of urgency or need for assistance.\nPersona Context: \nSociable\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking in a park with a friend. The wind is getting stronger, and the sky is gray. There is a conversation: \"Hey, can you feel that breeze picking up? Do you think it's going to turn into a storm soon?\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a living room with friends watching TV. A conversation captures a suggestion to plan a road trip next weekend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for popular road trip destinations and planning tips.\", \"parameters\": {\"query\": \"road trip destinations and planning tips\"}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"road trip destination\", \"time\": \"next weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a group chat where team members are discussing the need to schedule a meeting about recent customer feedback. Team members are suggesting Thursday afternoon as a possible meeting time.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Customer Survey Results Discussion\", \"start_time\": \"2025-05-01 14:00:00\", \"meeting_location\": \"Conference Room A\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime and return all events as a summarized string.\", \"parameters\": {\"time\": \"2025-05-01 14:00:00\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Customer Survey Results Discussion\", \"time\": \"2025-05-01 14:00:00\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking in a shopping mall with a friend. Audio information shows there is a conversation between the user and others. The partner says: \"I want to buy a new watch. Do you know where the best watch stores are around here?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"watch stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"watch stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing code architecture diagrams on a whiteboard with TODO items. It's late afternoon (4:45 PM), and a colleague has just reminded them about API documentation updates needed before a client demo scheduled for tomorrow morning.\nPersona Context: \nA software developer.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete API documentation updates for client demo\", \"time\": \"Today 5:00 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing by the river, enjoying the soothing sounds of water and the act of skipping stones.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is receiving instructions from a physical therapist to perform specific stretches three times weekly and attend weekly Tuesday appointments for the next month.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Tuesdays for the next month\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Physical therapy stretching exercises\", \"time\": \"three times weekly\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is plating a completed meal of grilled chicken, roasted vegetables, and rice, focusing on the presentation.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a campsite with a tent set up and a campfire burning, with marshmallow roasting supplies ready.\nPersona Context: \nA weekend camper who enjoys traditional outdoor experiences like campfires and stargazing\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop with a suitcase, likely needing to reach Business Park for a meeting at 2 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current_location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"Business Park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for pet supplies, particularly interested in pet food options.\nPersona Context: \nThe user is a pet owner who is attentive to pet nutrition.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"pet food\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"nutritional information on pet food\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best pet food reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the initial stages of baking a cake, carefully measuring flour while following a recipe from a cookbook. All necessary ingredients are organized and ready for use.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is measuring flour into a bowl using a measuring cup, which suggests they are preparing to bake or cook.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is traveling by train, observing the scenery outside.\nPersona Context: \nA curious traveler interested in learning about new places and landscapes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can identify landmarks or regions.\", \"parameters\": {\"prompt\": \"Identify landmarks or regions visible from the train window.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API for historical or factual information.\", \"parameters\": {\"query\": \"Lake District\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is sitting in front of the computer, either working or studying. The user's fitness watch shows an elevated resting heart rate of 102 BPM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"advice on elevated heart rate and flushing.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"advice on elevated heart rate and flushing.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is practicing playing the guitar in a relaxed, home office environment.\nPersona Context: \nThe user is a music enthusiast who enjoys learning new guitar techniques.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Search the web for online guitar tutorials or sheet music.\", \"parameters\": {\"query\": \"online guitar tutorials or sheet music\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tips on improving guitar techniques\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the road.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking down a quiet residential street lined with trees and parked cars.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is with friends in a living room, suggesting a game night for the next Friday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Game night\", \"time\": \"next Friday\"}}, {\"name\": \"google_search\", \"description\": \"Search for popular board games and their rules.\", \"parameters\": {\"query\": \"popular board games for game night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for gaming laptops in an electronics store, comparing specifications and prices.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"gaming laptop\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"gaming laptop\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"gaming laptop\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a kitchen with ingredients like tomatoes, basil, and mozzarella, looking at a cookbook open to Italian cuisine.\nPersona Context: \nThe user enjoys trying authentic Italian recipes and experimenting with new flavors.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Caprese salad recipe with tomatoes, basil, and mozzarella\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a stretching exercise on a yoga mat in their living room.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a music store looking at a digital piano keyboard with weighted keys.\nPersona Context: \nThe user has recently started taking piano lessons and is looking to purchase their first serious instrument for home practice.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"digital piano weighted keys\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"digital piano reviews beginners intermediate bundle\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a rural bus stop with reduced service and a broken schedule display. They have a doctor's appointment at City Medical Center at 1:30 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"rural bus stop location\", \"destination\": \"City Medical Center\"}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"rural bus stop location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"rural bus stop location\", \"destination\": \"City Medical Center\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaging in a stretching routine in a peaceful outdoor setting.\nPersona Context: \nThe user practices yoga regularly for relaxation and fitness.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading an email from a marketing team member requesting to schedule a meeting for next week to discuss a Q2 campaign launch.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Q2 Campaign Discussion with Marketing\", \"start_time\": \"2025-05-06 14:00:00\", \"meeting_location\": \"Conference Room B\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime and return all events as a summarized string.\", \"parameters\": {\"time\": \"2025-05-06 14:00:00\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Q2 Campaign Discussion with Marketing\", \"time\": \"2025-05-06 14:00:00\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is walking through a shopping mall chatting with a colleague. Audio information shows there is a conversation between the user and the colleague. The partner says \"Have you tried that new Italian restaurant on the third floor? Everyone's talking about it.\"\nPersona Context: \nFoodie\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new Italian restaurant third floor shopping mall\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is checking the pasta menu at an Italian restaurant, focusing on gluten-free pasta and lighter sauce options.\nPersona Context: \nThe user is sensitive to gluten and wants to avoid any potential discomfort while enjoying Italian cuisine.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Gluten-free pasta options at this Italian restaurant\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Top-rated gluten-free friendly Italian restaurants near this location\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Safe gluten-free alternatives for pasta dishes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is sitting in a caf\u00e9 with a friend, discussing weekend plans. Audio information captures a conversation between the user and others. The partner says: \"What do you think about going to the barbecue this Sunday?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\":\"this Sunday\"}},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this Sunday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a yoga studio, engaging in a stretching routine on a yoga mat.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking in a kitchen. The individual is standing in front of a gas stove, holding a frying pan with what appears to be minced meat or ground beef..\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is standing in a park, stretching before a run.\nPersona Context: \nThe user is a fitness enthusiast who tracks their running performance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a restaurant, looking at a menu, and appears to be preparing to order food.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"Popular menu options at this restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a beach boardwalk with the sun setting, approaching an 'Oceanside Shuttle' bus shelter. There's a weather alert for a thunderstorm starting at 8:00 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"Oceanside Shuttle\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in his cubicle, focused on writing or responding to emails.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a cluster of unusual mushrooms growing at the base of a large oak tree in a forest setting.\nPersona Context: \nAn amateur naturalist who enjoys identifying local flora and fauna during outdoor excursions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"mushroom species Redwood National Forest oak tree base identification\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is tasked with preparing the final budget report by next Friday.\nPersona Context: \nThe user is a financial analyst responsible for budget management.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare final budget report\", \"time\": \"before next Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is seated at a small table in a coffee shop, with a cup of coffee and a laptop on the table.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the process of checking into a hotel. They are at the reception desk with no visible signs of confusion or need for assistance.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user has a packed schedule today with back-to-back meetings. A colleague is requesting to schedule a quick chat.\nPersona Context: \nThe user frequently manages a busy schedule and coordinates with multiple team members.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"today after 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is navigating through an airport terminal. They are surrounded by shops and other passengers, with no signs of confusion or immediate travel needs.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach, lying on a colorful towel under a large umbrella. They appear to be dozing with eyes closed, wearing sunglasses and swim attire. A paperback novel lies open and face-down on the towel beside them. The ocean waves can be seen gently rolling onto the shore a short distance away, and other beachgoers are visible enjoying the sunny day.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in focused document review, methodically reading and highlighting important sections of printed materials at their workspace.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park, enjoying a walk. It is a sunny day.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a kitchen supply store evaluating chef's knives, testing the weight and balance of at least one knife and comparing prices, suggesting they are considering purchasing a chef's knife.\nPersona Context: \nA cooking enthusiast who invests in quality kitchen tools and appreciates professional-grade equipment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best chef knives quality reviews maintenance value for money\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"chef's knife\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a book in a comfortable home setting with a hot beverage and pet companion.\nPersona Context: \nAn avid reader who enjoys immersing themselves in fiction during quiet evenings\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing at a trailhead with a map on a wooden signboard in front of them. A companion is saying: 'Which trail should we take? Do you know how long these hikes are?'.\nPersona Context: \nThe user enjoys hiking but prefers shorter trails due to a past knee injury.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"hiking trails near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bar, socializing with a group of friends.\nPersona Context: \nOutgoing\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport, checking flight details on a departure board. The user has a flight booked for 3:00 PM.\nPersona Context: \nThe user is a frequent traveler who values efficiency and time management.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Flight XY123 status and gate information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaged in sketching on a garden bench, surrounded by art supplies.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a caf\u00e9 with friends discussing a recent soccer match between Barcelona and Real Madrid, with particular focus on a goal scored by Lewandowski.\nPersona Context: \nThe user enjoys sports but isn't deeply knowledgeable about current soccer player statistics.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Robert Lewandowski Barcelona career statistics achievements\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person shows a person holding a smartphone with a messaging app open, standing inside an elevator. The elevator doors are closed.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a business meeting about quarterly sales performance, taking notes while listening to a presenter discuss positive results.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for baby monitors in a store and examining a high-end model priced at $299.99 with advanced features like HD video, temperature monitoring, and breathing tracking.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"HD video baby monitor with temperature and breathing tracking\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"high-end baby monitor parent reviews reliability\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"pediatrician recommended baby monitor features necessity of breathing monitors\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining an unfamiliar purple flowering plant while hiking on a forest trail, and appears to be reaching out to touch it.\nPersona Context: \nA nature enthusiast who enjoys identifying plants and wildlife during outdoor excursions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this purple flowering plant\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Digitalis purpurea toxicity\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is comparing different types of sunscreens (chemical vs. mineral) with different SPF ratings. Their arm shows evidence of a recent sunburn.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"chemical versus mineral sunscreen for sensitive skin SPF recommendations high UV index\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing in front of a bathroom mirror, looking at their reflection. There's a toothbrush and toothpaste on the sink counter, but they haven't started brushing yet.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a peaceful moment alone on a beach at sunset, collecting seashells and watching the waves.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mexican restaurant, browsing a menu with options such as tacos, burritos, and guacamole.\nPersona Context: \nThe user enjoys Mexican food but wants to make healthier choices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for tacos, burritos, and guacamole\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for tacos, burritos, and guacamole\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a leisurely hike on a well-marked forest trail, pausing occasionally to appreciate the natural surroundings.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a peaceful moment watching a sunset over a lake from a park bench.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a library, discussing a book with a classmate that could be helpful for a project.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mediterranean restaurant, scanning a menu featuring Greek salad, hummus with pita bread, and grilled salmon.\nPersona Context: \nThe user is health-conscious and prefers meals that are heart-healthy and rich in omega-3s.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health benefits of Greek salad, hummus with pita bread, and grilled salmon\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights and heart-health benefits of Greek salad, hummus, and grilled salmon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe image shows the user is holding a smartphone with both hands, and the screen displays a photo of a baby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is grating cheese over a bowl of pasta, likely as a finishing touch before serving.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a colleague are looking for a recently opened coffee shop in a downtown area, but they're unsure of its exact location.\nPersona Context: \nA coffee enthusiast who enjoys discovering new caf\u00e9s and specialty coffee shops\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"new coffee shop opened recently downtown [location based on coordinates]\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"[current coordinates]\", \"destination\": \"Artisan Brew coffee shop\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking at a stove, stirring a pot with a wooden spoon. Steam is rising, indicating the food is being cooked.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in gardening activities in a community garden, watering plants with proper tools available nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a woodworking project in their garage workshop, specifically sanding a small wooden table. They are wearing appropriate safety equipment and have their tools organized nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working at a desk, focused on coding, surrounded by papers and a computer monitor displaying code.\nPersona Context: \nThe user prefers listening to instrumental music while coding to maintain concentration.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at their desk where a stack of reports is visible next to an open laptop. The laptop screen shows a partially completed financial analysis spreadsheet. A calculator and several highlighters are neatly arranged nearby..\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friend are at a farmers market and have discovered a flyer for a food festival at Riverside Park happening today. They're considering visiting after finishing their shopping.\nPersona Context: \nA food enthusiast who enjoys culinary events and trying new cuisines\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"farmers market\", \"destination\": \"Riverside Park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a movie with friends, making comments about favorite scenes.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a parking lot with several cars, including a close-up view of a black car's interior. The clear blue sky indicates that it is a sunny day.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be preparing for a yoga or workout session in their living room. They have laid out a yoga mat and are dressed in appropriate attire for exercise.\nPersona Context: \nAn individual who practices mindfulness activities like yoga and meditation, preferring ambient or nature sounds as background music\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is seated in the driver's seat, driving a car. The interior of the vehicle is that of a Toyota, with a steering wheel and dashboard.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a crowded shopping mall, possibly looking to leave, and has a meeting scheduled at 6 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"meeting location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a yoga class, following an instructor's guidance, with their phone intentionally set to silent and Do Not Disturb modes.\nPersona Context: \nA mindful yoga practitioner who regularly attends classes to destress and improve flexibility\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a person in front of the user, sitting on the floor next to a bright green couch. It appears to be in a living room.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a dinner with friends discussing plans for their annual hiking trip to Mount Rainier planned for the 15th of next month.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"15th of next month\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Annual hiking trip to Mount Rainier\", \"time\": \"15th of next month\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bar, socializing with a group of friends.\nPersona Context: \nOutgoing\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a cafe, looking at a menu.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"popular cafe items or dietary-specific options\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friend are viewing a poster for a local music festival happening tonight and are discussing transportation options to get there.\nPersona Context: \nA music enthusiast who enjoys live performances and cultural events\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"music festival venue\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a casual evening stroll through a residential neighborhood, occasionally stargazing as they walk at a relaxed pace.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on a spreadsheet in an office environment.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a gym, standing in front of a set of free weights with a look of uncertainty.\nPersona Context: \nNew to fitness and unfamiliar with proper lifting techniques.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"proper lifting techniques for beginners\"}}, {\"name\": \"vllm\", \"description\": \" Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"correct form for lifting weights\",\"image_path\":\"\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a balcony, enjoying a sunset view of the city. The mood is serene and reflective.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a gym, standing next to a rowing machine and wearing athletic clothing, indicating they are about to start exercising.\nPersona Context: \nThe user enjoys guided workouts and tracking fitness progress.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"guided rowing workout plan\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is playing with a black and white cat using a string toy in their living room. The cat appears engaged and playful.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a scenic overlook during sunset, looking at mountains with an information plaque that's difficult to read due to shadows.\nPersona Context: \nA nature enthusiast who enjoys learning about geological formations and natural landmarks\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"use current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying quiet reading time in a garden setting with a cup of coffee nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in gardening activities in a well-maintained garden, planting flowers with proper tools and equipment readily available.\nPersona Context: \nA gardening enthusiast who finds joy in nurturing plants and creating beautiful outdoor spaces\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop in Central Park, New York City. The sky is darkening with storm clouds, suggesting imminent rain.\nPersona Context: \nA nature enthusiast who enjoys outdoor activities in urban parks\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"New York City\", \"time\": \"now\"}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for the user's current location.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a poster for an upcoming music festival with a friend. The friend expresses interest in attending the event.\nPersona Context: \nThe user is a music enthusiast who enjoys attending live performances and festivals.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"music festival dates\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Music Festival\", \"time\": \"festival dates\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"music festival ticket information and event details\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friends are playing frisbee in a park and plan to stop in 45 minutes to get food.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"45 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking in a forest and has encountered a distinctive red mushroom with white spots, which they are currently examining.\nPersona Context: \nAn amateur nature photographer who enjoys identifying flora and fauna during outdoor excursions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this mushroom species and determine if it's poisonous\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Amanita muscaria mushroom toxic properties\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a friend are enjoying the sunset at a beachside promenade and are interested in finding a nearby seafood restaurant.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"seafood restaurants near the beach with good ratings\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is jogging in a park and wearing a fitness tracker.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing for a board meeting scheduled for 2 PM tomorrow where they need to present a Q3 financial summary. They are currently reviewing financial reports with red annotations.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"tomorrow 2 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Board Meeting - Q3 Financial Presentation\", \"time\": \"tomorrow 2 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing in a grocery store aisle, looking at a variety of cereals.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"cereal\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"cereal nutritional information and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the kitchen, actively cooking and adjusting the seasoning of a pot of soup on the stove.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a steakhouse, browsing a menu with options such as ribeye steak, baked potato, and Caesar salad.\nPersona Context: \nThe user is health-conscious and wants to make an informed decision about their meal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for ribeye steak, baked potato, and Caesar salad\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for ribeye steak, baked potato, and Caesar salad\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in their kitchen, observing a container of protein powder and a shaker bottle.\nPersona Context: \nA gym enthusiast who uses protein supplements to aid muscle recovery\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a friend are strolling near a river at dusk. There is a conversation: \"Wow, it's getting colder than I expected. Should we head back before the sun sets?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking down a staircase.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a park, reading a book on birdwatching, indicating an interest in birdwatching activities.\nPersona Context: \nA nature enthusiast who enjoys birdwatching.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify birds around the user.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Northern Cardinal\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach chair, peacefully watching the sunset over the ocean.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining the contents of their refrigerator, possibly planning what to cook or looking for specific items.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a first-person perspective of someone walking a dog on a paved path. The scene appears to be outdoors, possibly in a residential area given the presence of a curb and grass along the side of the path.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a coffee shop, talking with a friend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining the contents of their refrigerator, possibly planning what to cook or eat.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at their desk organizing and sorting business cards into different categories.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a colleague are discussing ways to improve and automate a complex process in the office.\nPersona Context: \nThe user is a process improvement specialist.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"automation tools for business processes\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"business process automation strategies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is relaxing on a sofa, watching a nature documentary about monarch butterflies.\nPersona Context: \nThe user enjoys learning about wildlife and nature.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"monarch butterflies\"}}, {\"name\": \"google_search\", \"description\": \"Search the web for similar documentaries or educational content on wildlife.\", \"parameters\": {\"query\": \"similar documentaries on wildlife\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a park and is looking for a suitable trail for a quick walk.\nPersona Context: \nThe user enjoys short, leisurely walks.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"best trails for a quick walk in this park.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a sectional sofa priced at $2,499. They're taking measurements and photos, suggesting serious purchase consideration.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"beige modern sectional sofa\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"sectional sofa durability comfort reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a scheduled outdoor yoga class at a park, currently following the instructor's guidance on proper form for warrior pose.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing in their kitchen with various ingredients, including flour, eggs, and sugar, on the counter. The user is likely preparing to bake or cook something.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"recipe suggestion of flour, eggs, and sugar\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"recipe suggestion of flour, eggs, and sugar\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is scanning the dessert menu at a caf\u00e9. The menue inclues sugar-free or low-sugar alternatives, including fruit-based desserts and sugar substitutes.\nPersona Context: \nThe user monitors their sugar levels carefully and prefers healthier dessert choices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Low-sugar or sugar-free dessert options at this caf\u00e9\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Best low-sugar dessert caf\u00e9s nearby\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Recommended sugar substitutes for low-sugar diets\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a hammock in a garden, possibly enjoying a quiet moment or taking a nap.\nPersona Context: \nThe user enjoys reading and listening to audiobooks during relaxation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting at a piano in what appears to be a home living room. Their fingers are positioned on the keys, and sheet music is open on the piano stand. A metronome is visible on top of the piano, ticking steadily.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking a trail with a companion, planning to reach the summit and return before sunset. They're currently 2.5 miles from the summit with approximately 1.5 hours of hiking ahead, and need to begin their return journey by 4:30 PM to avoid incoming thunderstorms.\nPersona Context: \nAn avid weekend hiker who enjoys challenging trails but is safety-conscious about weather conditions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"1 hour 45 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a camera store looking at a DSLR camera with multiple lenses in a display case. The price tag shows $1,299 for the camera body and basic lens kit.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"DSLR camera kit with basic lens\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"DSLR camera beginner smartphone photographer transition reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a gym environment where people are exercising and personal trainers are assisting clients.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a plane flight, relaxing by looking out the window with reading material and a drink.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is boiling water on the stove for cooking or making a beverage.\nPersona Context: \nA home cook who likes to multitask while preparing meals\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"7 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and friends are preparing to watch a sports game that starts in 25 minutes, and they're currently setting up food and drinks.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"25 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a mountain viewpoint enjoying the scenery of a valley with towns below. They have a dinner reservation at 7:30 PM at La Trattoria restaurant in Millfield.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"mountain viewpoint\", \"destination\": \"La Trattoria, Millfield\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a park barbecue with friends and is cooking burgers that need to be flipped after 5 minutes.\nPersona Context: \nA social organizer who enjoys hosting gatherings and wants everyone to have a good time\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"5 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cleaning a bathroom sink using a blue scrub brush under running water from the faucet.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a living room, engaging in a relaxed conversation with family members. The environment is homely and comfortable.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is considering purchasing sunscreen, possibly to protect against UV exposure.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"SPF levels and product reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Search the web for information.\", \"parameters\": {\"query\": \"SPF levels and product recommendations\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"sunscreen\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a beach, sitting on the sand and watching the waves, indicating a serene and relaxing environment.\nPersona Context: \nThe user enjoys playing music that matches the natural ambiance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user has just arrived at the Grand Hyatt Singapore for a 3-night stay. They have a meeting scheduled with clients tomorrow at 9:00 AM at the Marina Bay Financial Centre. They are currently at the reception desk preparing to check in.\nPersona Context: \nA business executive who travels internationally for client meetings\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"Grand Hyatt Singapore\", \"destination\": \"Marina Bay Financial Centre\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"tomorrow 9:00 AM\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"7:00 AM tomorrow\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking up the stairs with a handrail on the left and a white wall on the right.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is shopping for electronics and is currently looking at different gadgets.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"latest model of the gadget\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"gadget reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on a client feedback summary that needs to be ready by next Monday.\nPersona Context: \nThe user is a client relations specialist responsible for preparing client documents.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Monday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare client feedback summary\", \"time\": \"before next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a meeting discussing a project timeline. The draft needs to be ready for review by next Tuesday.\nPersona Context: \nThe user is a project manager responsible for overseeing deadlines.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Tuesday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize project draft\", \"time\": \"before next Tuesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting at a dining table with a friend, with plates of food and drinks on the table. Audio information shows there is a conversation between the user and others. The friend says: 'I'm thinking about getting a new phone. Do you have any recommendations?'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"popular phones\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"phone reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working from a home office. The presence of books and a whiteboard suggests they are engaged in planning or research activities.\nPersona Context: \nResearcher\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lying on a picnic blanket in a meadow, reading a novel with soft sunlight filtering through the trees.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a shared office space with a laptop open to an email client. The conversation partner says: 'We should finalize the budget report by tomorrow afternoon.'\nPersona Context: \nThe user is responsible for financial planning and analysis.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"tomorrow afternoon\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Work on budget report\", \"time\": \"tomorrow afternoon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a beach, with a book and cooler nearby. The weather appears pleasant with other people also enjoying the beach.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is looking at a restaurant menu. GPS detects the user is near a popular dining area. The user's calendar shows no upcoming events.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"restaurant recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mediterranean restaurant, browsing a menu with options such as hummus, falafel, and grilled chicken.\nPersona Context: \nThe user is health-conscious and wants to make a nutritious choice.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for hummus, falafel, and grilled chicken\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for hummus, falafel, and grilled chicken\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user shopping in a vegetable market and looking at the vegetables.\nPersona Context: \nUser often struggles with deciding what to cook.. The user has mentioned they often feel unsure about what to cook.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"recipe ideas and suggest ingredients\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a hammock in their backyard, surrounded by nature.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting in a comfortable armchair in what appears to be a home library or study. They are holding an e-reader device and appear to be deeply engaged in reading. A cup of tea sits on a small table beside them.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is at a social gathering in a backyard, enjoying a barbecue with friends.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having coffee with a friend at an outdoor cafe. The friend is venting about work-related frustrations regarding overtime expectations from their boss.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a report with charts and data analysis results. A colleague suggests arranging a meeting to discuss the analysis results with the team.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Data Analysis Results Discussion\", \"start_time\": \"as soon as possible\", \"meeting_location\": \"conference room\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, browsing skincare products, and seems particularly interested in a specific brand.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"skincare product\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"skincare product reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a hiking trail entrance, preparing to go hiking. They're examining trail options on a map display. There's a weather alert for thunderstorms expected in the area after 3:00 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"today afternoon\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"hiking trail lengths and completion times at [current location]\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"hiking trail entrance\", \"destination\": \"Cedar Ridge Loop or Sunview Trail\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is cross-country skiing alone in remote terrain during a winter storm. Conditions include heavy snowfall, poor visibility, cold temperatures.\nPersona Context: \nThe user enjoys winter sports but has limited experience with navigation in backcountry conditions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at home watching a drama movie with popcorn in a comfortable, dimly lit living room setting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on the beach, indicating they might be planning to surf.\nPersona Context: \nThe user is a beginner surfer who is learning to surf.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Local beach\", \"time\": \"now\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"beginner surfing tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a garden, surrounded by blooming flowers and plants.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user examining tennis rackets at a sporting goods store, focusing on a professional model priced at $189.95.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"professional tennis racket\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"professional tennis racket reviews recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is carrying a suitcase. GPS detects that the user has arrived in a new city. The agenda shows that the user has a hotel check-in at Victoria Hotel at 7 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"Victoria Hotel\"}},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"Victoria Hotel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a leisurely caf\u00e9 experience in what appears to be a European city, taking in the local atmosphere while having coffee and a pastry.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the sidewalk of a road that appears to be going downhill, with an intersection ahead. There are many bushes on both sides of the road.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a digital intersection, crossing the road.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a leisurely lunch at a picnic table in a grassy area, surrounded by a few trees.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a leisurely walk through a botanical garden, appreciating the diverse plant life and occasional butterflies.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a vegan restaurant, browsing a menu with options such as quinoa salad, lentil soup, and tofu stir-fry.\nPersona Context: \nThe user follows a vegan diet and wants to ensure their meal is both healthy and satisfying.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for quinoa salad, lentil soup, and tofu stir-fry\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for quinoa salad, lentil soup, and tofu stir-fry\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a MacBook Air laptop priced at $1,299.99.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"MacBook Air M2 8GB RAM 256GB\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"MacBook Air M2 reviews recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a train journey, currently reading a book while enjoying the countryside views.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having dinner with friends. Someone has mentioned that The Lumineers will be performing at River Park on the 15th of next month, with tickets going on sale this Friday at 10 AM. The group seems interested in attending together.\nPersona Context: \nA music enthusiast who enjoys attending concerts with friends\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"River Park\", \"time\": \"15th of next month\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there are any time conflicts in the user's agenda.\", \"parameters\": {\"event\": \"The Lumineers concert\", \"date\": \"15th of next month\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"The Lumineers River Park concert ticket prices\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Lumineers tickets go on sale\", \"time\": \"Friday 10 AM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user enjoying the view of a sunset from a balcony.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a bus stop, talking to a fellow commuter. Audio information shows the user is talking with a friend the the friend is asking about the next bus arrival. The friend says: 'Do you know how long until the next bus arrives?'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current location'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a light stretching routine in front of a mirror, possibly as part of a morning ritual.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a craft fair, showing interest in handmade jewelry.\nPersona Context: \nThe user appreciates handcrafted items and unique designs.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"handmade jewelry artist information\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"craft fair\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach and interested in visiting the lighthouse, as indicated by their focus on the map of nearby attractions.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"beach\", \"destination\": \"lighthouse\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach with storm clouds approaching rapidly. Lightning can be seen in the distance over the water, but people are still swimming, seemingly unaware of the danger.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current_beach_location\", \"time\": \"now\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"lightning safety protocol beach evacuation\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking down a university hallway with a colleague discussing research collaboration. They've expressed mutual interest in collaborating on a grant proposal related to neural networks, and there's a relevant grant deadline coming up on June 15.\nPersona Context: \nA computer science professor specializing in machine learning and neural networks\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Neural Networks Research Collaboration for Grant Proposal\", \"start_time\": \"\", \"meeting_location\": \"meeting room\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a work brainstorming session, diagramming on a whiteboard while team members discuss process connections.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an electronics store, considering purchasing wireless headphones, possibly comparing features and prices.\nPersona Context: \nThe user is a tech enthusiast who values high-quality sound and innovative features.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"wireless headphones reviews and feature comparisons\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"wireless headphones\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a picnic with friends, enjoying food and socializing in a public park.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is chatting with friends at a cafe. Audio information shows there is a conversation between the user and others. The partner says:\"I heard that AI can now write stories\".\nPersona Context: \nTech-savvy. Creative\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining a bicycle with a flat rear tire that shows signs of damage to both the tire and inner tube. They have a cycling meetup scheduled for tomorrow morning, suggesting this is an urgent issue that needs addressing.\nPersona Context: \nA recreational cyclist who participates in regular group rides\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Assess the damage to this bicycle tire and determine if it needs professional repair or can be fixed at home\", \"image_path\": \"\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current location\", \"destination\": \"bicycle repair shop near me open now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is exploring a Thai market and has stopped at a fruit stall where a vendor is offering durian fruit for 200 baht. The user appears interested but possibly unfamiliar with the fruit.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this fruit in the image\", \"image_path\": \"user_view.jpg\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"durian fruit\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"average price of durian in Thailand market\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having coffee with a friend who is inviting them to a housewarming party on Saturday at 6 PM at 742 Maple Street, apartment 3B.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday 6 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Housewarming party at 742 Maple Street, apt 3B\", \"time\": \"Saturday 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a botanical garden entrance, curious about the duration of a walk along the main garden path.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"botanical garden entrance\", \"destination\": \"main garden path\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden, observing rare orchids.\nPersona Context: \nThe user is a plant enthusiast with a keen interest in botany.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the orchids the user is observing.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Ghost Orchid\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a science fair, observing a booth about solar panel technology.\nPersona Context: \nTech enthusiast\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"solar panel technology and benefits\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"latest advancements in solar energy\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting with friends in a garden, surrounded by plants and flowers. Audio captures a conversation where someone suggests hosting a garden party next weekend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"next weekend\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for decoration ideas and catering options for a garden party.\", \"parameters\": {\"query\": \"garden party ideas and catering\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Garden party\", \"time\": \"next weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a ferry, looking at the sea. The weather is sunny, and other passengers are enjoying the view.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sengaged in hand-washing clothes outdoors. \nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is seating in a classroom, chatting with a classmate. The classmate asks: \"Hey, did you know the fireworks display this weekend? It was supposed to be spectacular! Do you know if there are any more events like this coming up?'.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"the upcoming fireworks display this weekend.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is browsing a clothing store. GPS detects the user is at a shopping mall. The agenda shows the user has a meeting in 2 hours.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Get the route and travel time from the current location to the destination.\", \"parameters\": {\"current_location\":\"Shopping Mall\", \"destination\":\"Central Plaza\"}},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Shopping Mall\", \"destination\":\"Central Plaza\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working at their desk in an office, focused on typing on their laptop with reference documents nearby and a coffee cup within reach.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a technology museum, spending time examining a quantum computing exhibit with processor models and interactive displays.\nPersona Context: \nA technology enthusiast with interest in emerging computing technologies\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"quantum computing recent breakthroughs practical applications explained\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is setting up at a beach while dark clouds approach from the horizon. A lifeguard has raised a yellow caution flag, and a loudspeaker announcement mentions a thunderstorm warning. The user's phone has received a weather alert for a thunderstorm from 2:00 PM to 5:00 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current_beach_location\", \"time\": \"now\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current_beach_location\", \"destination\": \"nearest_indoor_shelter\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hanging clothes to dry outside, likely after completing a laundry cycle.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"3 hours\"}}, {\"name\": \"get_city_weather\", \"description\": \"Get the current weather conditions for the user's city.\", \"parameters\": {\"city\": \"user's current city\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sketching a sunset lake landscape while sitting on a park bench.\nPersona Context: \nAn amateur artist who listens to instrumental jazz while sketching outdoors to enhance creativity\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking the Pine Ridge Trail and has reached a junction with multiple path options. Trail markers are difficult to read, and there are signs of an approaching storm.\nPersona Context: \nAn avid hiker who prioritizes safety and careful navigation on wilderness trails\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API\", \"parameters\": {\"current_location\": \"current trail junction\", \"destination\": \"Pine Ridge Trail end point\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting by a lake, fishing. The environment is calm.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying breakfast at an outdoor caf\u00e9 in Paris on a pleasant sunny morning, listening to street musicians while taking in the historic surroundings.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a park where the Annual Spring Festival is being set up for this Saturday from 10 AM to 6 PM. The event will feature live music starting at noon, local food vendors, and children's activities in the north section of the park.\nPersona Context: \nA parent who enjoys taking their children to local community events and festivals\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday 10 AM to 6 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Annual Spring Festival at the park\", \"time\": \"Saturday 10 AM to 6 PM\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Annual Spring Festival local park details activities\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a sports equipment store, examining a pair of running shoes. The price tag shows $129.99. Several other running shoe models are visible on nearby shelves with various price points.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"running shoe model reviews long distance running\"}}, {\"name\": \"get_online_product_price\", \"description\": \"    Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a kitchen. A fruit bowl with apples and bananas is visible nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a book in a public library where silence is expected, as indicated by the 'Quiet Please' sign.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a clothing store, looking at jackets. They might be considering purchasing one.\nPersona Context: \nThe user is a fashion enthusiast who likes to stay updated with the latest trends.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can analyze fashion trends based on the given image.\", \"parameters\": {\"prompt\": \"Analyze the style of the jackets and suggest if they align with current fashion trends.\", \"image_path\": \"\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"jackets\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in programming work, referencing documentation while writing code.\nPersona Context: \nA mid-level software developer who prefers to work independently and solve problems through research rather than asking for help\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing for a beach trip by packing a beach bag with essential items like towels and sunscreen. There's a beach umbrella nearby, and the sky outside is partly cloudy.\nPersona Context: \nA casual beachgoer who values comfortable weather conditions for relaxation\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"Nearby Beaches\", \"time\": \"today\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is making a cup of tea, with water freshly boiled and sugar ready for sweetening. All necessary elements for preparing tea are visible and within reach.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a subway train, traveling through tunnels and looking out the window.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a break at a mountain overlook, enjoying the scenic natural landscape.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is tending to houseplants, likely watering them.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is frosting a two-layer chocolate cake with white frosting, with cake decoration supplies like sprinkles, food coloring, and candy pieces available nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a room filled with multiple individuals, all seated around a circular table, appearing to be gathered for a meeting. They are discussing novel techniques. The content of conversation is: \"Current solutions are not good. You should consider using techniques such as domain adaptation and contrastive learning to handle such research problems.\"\nPersona Context: \nThe user is responsible for the company's marketing.. Not familiar with advanced AI terminology.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"simplified explanation of domain adaptation and contrastive learning.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a book in a garden under a cherry tree, occasionally watching butterflies and the surrounding garden.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting and reading an open book. The book has text on both pages, and the reader's hands are holding it.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a taxi, traveling through a busy urban area. They are seated comfortably, and the driver appears to be handling the navigation.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the men's clothing section of a department store, browsing a sale rack. There isn't any indication the user is confused or in need of assistance.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is washing lettuce in the sink, preparing it for a salad or other dish.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a casual conversation with a friend in a caf\u00e9. They are planning to meet again next Thursday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Meeting with friend\", \"time\": \"next Thursday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in painting a landscape artwork on canvas with appropriate supplies.\nPersona Context: \nA hobby artist.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking in a shopping mall with a friend. Audio information shows there is a conversation between the user and others. The partner says: \"I want to buy a new smart speaker. Do you know where the best smart speaker stores are around here?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"smart speaker stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"smart speaker stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a live musical performance in a theater, surrounded by other audience members who are all engaged in watching the show.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing and highlighting a printed document in their home office, with reference materials organized nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the beach.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at what appears to be a family dinner, where relatives are reminiscing about shared memories and past family vacations while enjoying a meal together.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reminiscing about a past sports championship game while watching a current game with friends.\nPersona Context: \nThe user is a sports enthusiast.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"highlights of last year's championship game\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user seems to be following a recipe, potentially for a pasta dish, given the ingredients like pasta, cheese, and basil.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook rice, with water heating on the stove and a package of rice ready on the counter.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe visual information suggests the user is sitting in a bus station with a suitcase beside them.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'Botanical Garden'\"}}, {\"name\": \"book_uber\", \"description\": \"Book a ride to a specified location.\", \"parameters\": {\"current_location\":\"user current location\", \"destination\": \"User's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking in a kitchen. The individual is standing in front of a gas stove, holding a frying pan with what appears to be minced meat or ground beef.\nPersona Context: \nThe user is new to cooking and doesn't cook often.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"tips for cooking minced meat\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing the seafood menu at a coastal restaurant, looking at various shellfish dishes such as shrimp, crab, and lobster.\nPersona Context: \nThe user loves seafood flavors but must avoid shellfish due to a severe allergy.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Allergy-friendly seafood options at this coastal restaurant\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Allergen-friendly seafood restaurants near me\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Cross-contamination guidelines for shellfish allergies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a busy intersection, looking around.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen preparing food, using a red-handled knife to chop green onions on a cutting board.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the road. There are many trees on both sides of the road, and the road seems to be going uphill.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking through a corporate hallway, passing by closed offices and observing company displays on the walls.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is watching and photographing a sunset from a beachfront balcony with photography equipment set up.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an art museum, closely observing a well-known painting.\nPersona Context: \nAn art enthusiast who enjoys learning about the history and techniques behind famous artworks\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the painting in the image\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API for information about subjects.\", \"parameters\": {\"query\": \"The Starry Night Vincent van Gogh\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a gym, preparing to start their workout on a treadmill.\nPersona Context: \nThe user is new to fitness and concerned about heart rate during exercise.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"safe exercise heart rate guidelines\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a work meeting reviewing project timelines with urgent tasks that need to be completed before a client presentation on Monday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete urgent project tasks\", \"time\": \"Multiple blocks before Monday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Monday 9 AM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a trailer for 'Quantum Horizon' which is opening this Friday. Someone nearby has commented on the movie, asking 'Are you planning to see it this weekend?'.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Friday evening\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user at their desk with a document titled 'Client Proposal Draft'. The conversation involves submitting the proposal by this Friday.\nPersona Context: \nThe user is a project manager responsible for client proposals.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"Friday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize client proposal\", \"time\": \"Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a caf\u00e9 with a friend, holding an umbrella due to the rain. They mentioned needing to get to an art gallery quickly.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"art gallery\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is playing chess with an elderly opponent in a coffee shop, engaged in a friendly game that requires strategic thinking.\nPersona Context: \nA chess enthusiast who enjoys both the social and intellectual aspects of the game\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is focused on a virtual meeting, participating through video conferencing software.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing the steak menu at a steakhouse, focusing on different doneness levels, from rare to well-done.\nPersona Context: \nThe user wants a delicious steak but is cautious about the risks associated with undercooked meat.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Preferred steak doneness at this steakhouse\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Safe internal temperature guidelines for steak\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Food safety concerns with different steak doneness levels\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing an unusual flowering plant in a botanical garden. There's an information plaque that's difficult to read completely, and there's expressed curiosity about the plant from nearby visitors.\nPersona Context: \nAn amateur botanist who collects information about rare plant species\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this flowering plant with purple and yellow blooms\", \"image_path\": \"current view\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"rare flowering plant botanical information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a well-maintained forest trail with good visibility, surrounded by pine trees and wildlife in favorable weather conditions.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is jogging in a park, wearing running shoes, and holding a water bottle. GPS information suggests the user is jogging in a park.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a rare Himalayan Blue Poppy at a botanical garden. A nearby visitor has expressed interest in growing this unusual plant at home.\nPersona Context: \nA hobby gardener interested in exotic plant species\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"how to grow Himalayan Blue Poppy Meconopsis at home care requirements\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is browsing through a digital menu on a tablet at a restaurant.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"chef specials or trending items in this restaurant.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is kneading dough on a floured countertop, likely preparing to bake or make bread.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport lounge, discussing meal options with a fellow traveler before their flight.\nPersona Context: \nThe user is a frequent traveler and enjoys discovering new dining spots.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"best restaurants in airport\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at the entrance of a national park, interested in visiting the waterfall as they examine a trail map.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"national park entrance\", \"destination\": \"waterfall\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a guided meditation session in a calm, dimly lit room with other practitioners and an instructor providing guidance.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking down stairs with handrails and windows nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in artistic activity, sketching a scene in a park with children playing near an oak tree. They have organized their colored pencils nearby for their drawing session.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a sushi bar, browsing a menu with options such as nigiri, sashimi, and tempura.\nPersona Context: \nThe user is trying to maintain a healthy diet while enjoying their meal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for nigiri, sashimi, and tempura\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for nigiri, sashimi, and tempura\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is collaborating with a team on weekly goals. Audio indicates a deadline for completing a draft by Friday.\nPersona Context: \nThe user is a team lead responsible for overseeing project timelines.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this week\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Review draft progress\", \"time\": \"by this week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking alone on a forest trail during daytime, enjoying nature in a peaceful environment.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is cycling along a scenic path, enjoying the movement and the natural surroundings.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a gym, actively walking on a treadmill at a stable pace.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a washing machine in a department store, taking photos and notes of a specific model. A store employee is informing them about delivery options, stating that delivery would be available starting next Tuesday if purchased today.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Tuesday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Washing Machine Delivery (4-hour window)\", \"time\": \"next Tuesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe person is sitting at a caf\u00e9 with a friend, looking at travel brochures on the table. The conversation is: \"I\u2019m thinking about a quick getaway to Jeju Island. We could check out the beaches and hike Hallasan Mountain. What do you think?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Jeju Island\", \"time\": \"User's chosen trip days\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"User's chosen trip days\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a busy intersection with multiple bus stops in an unfamiliar city. They appear to be interested in visiting the Central Museum based on their search history, and a nearby tour guide mentioned it closes at 5 PM.\nPersona Context: \nA museum enthusiast visiting a new city without a planned itinerary\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current intersection\", \"destination\": \"Central Museum\"}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current location bus stops\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is waiting for their scheduled doctor's appointment in a medical office waiting room, passing time by reading a magazine while waiting to be called.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a yoga class where the instructor is guiding participants through a warrior pose.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is watering plants on a balcony with a small watering can.\nPersona Context: \nThe user loves gardening and enjoys spending time with their plants.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user has been working on their research paper for several hours without taking breaks and has been sitting and working for an extended period.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be in a hospital environment, observing medical professionals performing their regular duties. There's no indication the user is a patient or requires medical assistance.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a bus stop in the rain. Several other people are also waiting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current location bus stop\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"current GPS coordinates\", \"destination\": \"user's likely destination based on routine\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is jogging on an exposed beachfront during an extreme heat warning.\nPersona Context: \nThe user is a dedicated runner who trains consistently regardless of weather conditions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"heat exhaustion and heat stroke symptoms and emergency treatment\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a bench in a tranquil garden, observing koi fish swimming in a pond surrounded by lily pads, flowering plants, and bamboo.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in an office with colleagues, standing near a whiteboard filled with diagrams and notes. Audio information captures a conversation that includes: \"We need to finalize the project timeline by tomorrow.\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"finalize the project timeline\",\"time\": \"tomorrow\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to bake a frozen pizza, with the oven preheated and serving tools (pizza cutter and plates) ready for when cooking is complete.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a hiking trail with a view of a Tesla Gigafactory. Other hikers are showing interest in the factory and speculating about Tesla's stock performance.\nPersona Context: \nThe user is a tech enthusiast who follows developments in the electric vehicle industry\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"TSLA\", \"date\": \"current_date\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a simple picnic lunch in a park, with their meal partially consumed and other people enjoying similar activities nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user standing in a hallway. Audio information indicates the user is having a conversation with a colleague. The colleague asks: \"Hey, did you hear about the upcoming concert of that popular band happening next week? Any idea where it's taking place?\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"the upcoming concert of that popular band happening next week.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach, with a peaceful ocean view.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a break on a park bench, possibly after a workout, as indicated by the fitness tracker.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a social gathering in a backyard, enjoying a barbecue with friends.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attempting to fix a flat tire on their mountain bike while on a trail. They have some tools but appear to be in the process of removing or repairing the tire.\nPersona Context: \nA recreational mountain biker who enjoys weekend rides but has limited mechanical experience\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"how to repair mountain bike flat tire on trail step by step\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a living room, sitting on a couch with a pet dog.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a trail in a natural setting. The environment is peaceful.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting in a living room, massaging their temples with their fingertips. The user appears to be experiencing a headache or some stress.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"headache remedies and relaxation techniques\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working at a desk with multiple screens displaying stock charts and financial news. A colleague has asked about the stock price of ABC Corp, which is on the user's watchlist.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"ABC\", \"date\": \"today\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is transferring freshly baked chocolate chip cookies from a baking sheet to a cooling rack in a well-organized kitchen.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nTwo friends are chatting at a dinner table at home, with a laptop open to travel websites. They\u2019re interested in a cultural experience (Broadway) and also outdoor fun (Central Park), talking about a plan to visit New York. They want to catch a Broadway show and stroll through Central Park next week.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"New York\", \"time\": \"next week\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a botanical garden examining an unusual flowering plant with purple blooms. They're trying to read an information plaque that's partially obscured.\nPersona Context: \nAn amateur botanist who enjoys photographing and cataloging rare plant species during travels\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"What is this purple flowering plant?\", \"image_path\": \"current_visual_feed\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API.\", \"parameters\": {\"query\": \"Passiflora incarnata purple passionflower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is seasoning a steak while cooking it in a pan.\nPersona Context: \nA home chef confident in their ability to cook steak to perfection\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe visual information indicates that the user is sitting in front of a laptop with an open email client. The conversation includes the statement, \"I think we should finalize the project plan by next Monday. Maybe we can have a meeting in the afternoon that day?\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a bench in a park that has fitness facilities, observing others exercising but not participating in exercise themselves.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is socializing with friends in a living room with business news playing on TV. The conversation has turned to Tesla's new product announcement by Elon Musk, and one friend has specifically mentioned interest in Tesla's stock performance today.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"TSLA\", \"date\": \"2025-04-25\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bookstore, discussing a new bestseller with a friend. They are interested in finding the latest book by a popular author.\nPersona Context: \nThe user is an avid reader and enjoys keeping up with new releases.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"latest bestseller by that author\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual input indicates the user is in a hallway and an elevator is visible nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in the kitchen with basic baking ingredients like flour, eggs, and milk, possibly planning to bake something.\nPersona Context: \nUser is a beginner baker, often unsure about measurements.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"basic pancake recipe with flour, milk, eggs\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is pouring batter into a baking tray, preparing to bake.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user has been working at their computer for an extended period, showing signs of eye strain and poor posture.\nPersona Context: \nA software developer who often works long hours on complex coding projects\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"20-20-20 rule for eye strain prevention\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"ergonomics and eye health for computer users\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden, sketching flowers, suggesting an interest in art and botany.\nPersona Context: \nThe user is an amateur artist with an interest in plants.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify flowers in the sketch.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Hibiscus flower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking into what appears to be a Western restaurant.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"Popular menu options at this restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outdoors, enjoying the view of a lake. The visual information suggest a peaceful and relaxing environment.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a home gym, about to use a stationary bike for cardiovascular exercise.\nPersona Context: \nThe user prefers listening to podcasts or music that provides motivation during cardio workouts.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a board game night with friends in a comfortable home setting. The atmosphere is relaxed and social, with friendly banter occurring between players.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is checking the sushi menu at a Japanese restaurant, focusing on sushi rolls and sashimi options.\nPersona Context: \nThe user is a cautious eater who wants to avoid any health risks from raw fish.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Sushi rolls and sashimi options at this restaurant\"}},{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Top-rated fresh seafood suppliers near this Japanese restaurant\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Safety guidelines for consuming raw fish\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user has received an invitation to a neighbor's child's birthday party on Saturday from 3-6 PM.\nPersona Context: \nA social individual who values maintaining good relationships with neighbors and family\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday, May 15th, 3-6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a friend's house, sitting at a dining table with a group of people. Audio captures a conversation where someone suggests planning a weekend getaway to the mountains.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"mountains\", \"time\":\"this weekend\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for accommodation options and activities in the mountain area.\", \"parameters\": {\"query\":\"accommodation options and activities in mountain area\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for dog food, likely considering the best option for their pet.\nPersona Context: \nThe user is a pet owner who prioritizes high-quality nutrition for their dog.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"dog food\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"dog food nutritional info and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a park, sitting on a bench and observing the surroundings, which include children playing, people walking dogs, and joggers passing by.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on their laptop in a shared office space, surrounded by reminders on sticky notes. They seem focused on their task.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a dinner gathering with friends, sharing amusing memories about past experiences.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is relaxing in a hammock, reading a book in the sunlight.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing breakfast toast, spreading butter on one slice while waiting for another slice to finish toasting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden, taking in the sights of nature. The environment is serene and calming.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is standing in front of a mirror, trying on a new outfit.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"analyze the outfit and provide feedback on how it looks.\",\"image_path\":\"\"}},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"the new outfit the user is wearing.'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at their desk, possibly preparing to take vitamins or supplements.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"benefits of vitamins\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a leisurely baking activity, decorating cupcakes.\nPersona Context: \nThe user enjoys baking and experimenting with new recipes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"new cupcake decorating techniques or recipes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a walk with a friend who is sharing personal news about their sister planning to move abroad.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is doing a stretching routine, possibly as part of a morning exercise ritual.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is slicing a loaf of bread on a wooden cutting board with a serrated knife\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing by the stove, checking the temperature of a frying pan, likely preparing to cook.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a train station, examining a map of train routes, possibly trying to determine the best route to their destination.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"train station\", \"destination\": \"[user's destination]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a new smartphone. They are comparing different brands and models, as indicated by their prolonged focus on the price tags and specifications displayed on the shelf.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smartphone\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"smartphone reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a forest trail, observing nature around them. The weather appears to be pleasant with sunshine filtering through the tree canopy.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friend are in what appears to be a historical district, discussing local landmarks and trying to identify a building associated with a famous author.\nPersona Context: \nA history enthusiast who enjoys sharing interesting facts about local landmarks with friends\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Famous authors who lived in [current location]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a physical book in a cozy reading space at home, with a cup of tea nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting in a park under a tree, drawing in a sketchbook.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in an aerobic dance class, preparing to engage in a high-energy workout session.\nPersona Context: \nThe user likes to listen to high-energy music during workouts to enhance performance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is standing in front of a bookshelf in a library and is picking up a book titled 'Art of War.'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"book named 'Art of War.'\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"find reviews and similar book recommendations for the book 'Art of War.'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing outside a hotel in rainy weather, checking their watch frequently. There's a taxi stand but no taxis are available. Many people are waiting under the awning. The user has a flight to Chicago at 2:45 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's hotel location\", \"destination\": \"airport Terminal B\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"user's hotel location\", \"destination\": \"airport Terminal B\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a coffee shop, enjoying a conversation with a friend. The atmosphere is lively but relaxed, with no indication of urgency or need for assistance.\nPersona Context: \nSociable\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears relaxed, with no evident urgency or upcoming engagements based on GPS location data and agenda. Health data indicates a calm, resting heart rate. No specific tasks or deadlines are detected.\nPersona Context: \nThe user enjoys peaceful moments outdoors without unnecessary interruptions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing on a beach, looking out at the ocean. There are people swimming and playing in the water.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a friend are sitting on a park bench, enjoying a peaceful view of the pond and discussing finding a nearby caf\u00e9 for coffee.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"caf\\u00e9s near the park with good reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user ran for one hour on the school playground this evening.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"ran for one hour on the school playground this evening\",\"time\": \"this evening\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a spa, sitting in a lounge chair with a towel wrapped around their head.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a chess match in a park setting, carefully considering strategic moves against an opponent.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a rooftop patio with friends, enjoying the city skyline. Audio captures a conversation where a friend suggests planning a rooftop party for next Friday night.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"next Friday night\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday night\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Rooftop party\", \"time\": \"next Friday night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a pottery studio, seated at a pottery wheel. Their hands are covered in clay as they carefully shape a small bowl on the spinning wheel. Various pottery tools are arranged neatly on a nearby table, and several finished pieces in different stages of drying can be seen on shelves nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook, potentially something involving eggs, with a pan ready on the stove.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a shopping district and is considering walking to a theater with their friend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"shopping district\", \"destination\": \"theater\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking pancakes on a griddle and preparing to serve them on a plate. The process appears smooth and controlled.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a scenic overlook with a view of a city skyline. Nearby tourists are discussing company headquarters, including Apple, and expressing interest in stock performance.\nPersona Context: \nThe user is an amateur investor who enjoys tracking the stock market\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"AAPL\", \"date\": \"current_date\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to brush their teeth in their bathroom, with dental hygiene products laid out on the sink.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is washing fresh berries at the kitchen sink, with evidence that they're systematically cleaning different types of fruits, likely in preparation for consumption or a recipe.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a coffee shop, writing in a notebook while enjoying a cup of coffee.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a tech store, looking at a smartwatch priced at $299.\nPersona Context: \nTech enthusiast who enjoys staying updated with the latest gadgets.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smartwatch\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"smartwatch reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a coffee shop having a casual conversation with a friend about movies. Audio information indicates the user is having a conversation with others. The friend is asking about the latest Marvel movie: \"Have you seen the latest Marvel movie?\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"latest Marvel movie.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is discussing plans for a family dinner next Friday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime and return all events as a summarized string.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Family dinner\", \"time\": \"next Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in the hobby of model airplane building, currently in the middle of assembling a new model with organized parts.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a coastal walking path, looking at islands in the distance with a lighthouse nearby. Their mobile device indicates rain is expected in about 90 minutes.\nPersona Context: \nA nature enthusiast who regularly takes weekend hikes and enjoys exploring new trails\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"now\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"coastal path current location\", \"destination\": [\"visitor center\", \"parking lot\", \"trailhead\"]}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a break on a park bench, possibly after a workout, as indicated by the fitness tracker.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining a gaming console bundle in an electronics store. The package shows a PlayStation 5 with two controllers and a game, priced at $599.99.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"PlayStation 5 bundle with two controllers\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a patio, enjoying a cup of coffee while looking at the mountains.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a garden, watering plants.\nPersona Context: \nThe user is new to gardening and does not water plants regularly.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Tips for planting and watering flowers\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a park bench, chatting with a neighbor. Audio information indicates a conversation about a new farmers' market. The neighbor says: 'Have you heard about the new farmers' market opening next weekend?'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new farmers' market next weekend downtown\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a train journey, seated in a quiet compartment watching the scenery pass by.\nPersona Context: \nThe user enjoys listening to calm and relaxing music during travels.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a park bench, watching ducks in a pond on a pleasant sunny day. Other people are enjoying the park as well.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a meeting, likely discussing work-related topics with colleagues. There is no clear indication of confusion or the need for immediate assistance.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a bench by a lake, enjoying the tranquility of the calm water and the setting sun.\nPersona Context: \nThe user likes relaxing music to unwind in peaceful settings.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at an Italian restaurant, browsing a menu with options such as pizza, pasta, and gelato.\nPersona Context: \nThe user enjoys Italian food but is looking for healthier options.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for pizza, pasta, and gelato\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for pizza, pasta, and gelato\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing a hot sandwich using a panini press, with chips and water ready to complete their meal.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is shopping in a supermarket. The user is looking at the vegetables in the mall.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"Detect the freshness of the vegetable.\",\"image_path\":\"\"}},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is sewing a black fabric patch onto a white cloth using a needle and thread. The workspace includes a desk lamp, a container with sewing supplies, and other crafting materials.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a mall with a friend, expressing interest in purchasing a new tablet. They are curious about current deals.\nPersona Context: \nThe user is tech-savvy and enjoys finding the best deals.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"tablet\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a quiet moment by a mountain stream in a forested area, observing nature.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a rooftop bar with friends during sunset, and someone in the group has asked about a distinctive tall building with a spire that's visible in the city skyline.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tall building in use current location\"}}, {\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"What is the tall building with the spire in this skyline?\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"tall building in use current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach with friends, suggesting a beach volleyball game for the next Saturday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"beach\", \"time\": \"next Saturday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Beach volleyball game\", \"time\": \"next Saturday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a tennis court with friends who are suggesting playing tennis on Saturday morning. There are some clouds visible in the distance, and one friend is gesturing toward the sky.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"Current Location\", \"time\": \"Saturday morning\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday morning\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in an electronics store, focusing on different tablet models.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"tablet\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tablet reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tablet specifications and comparisons\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is doing a stretching routine, possibly as part of a morning exercise ritual.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a yoga studio, engaging in a stretching routine on a yoga mat.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a sporting goods store, considering purchasing hiking boots.\nPersona Context: \nOutdoor enthusiast, frequently goes on hiking trips.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"hiking boots\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"hiking boots reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in their car, and the dashboard is displaying an engine warning light. The fuel gauge is also indicating that the car is nearly out of fuel.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"nearest gas station\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"amber engine warning light meaning and recommended actions\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is exploring a city square, capturing photos with their smartphone.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a hammock while reading 'The Silent Patient' novel, with refreshment nearby, indicating a peaceful leisure activity.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at the entrance of a busy conference center, holding a conference badge, suggesting they are attending a conference at 3 PM at the City Convention Center.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"City Convention Center\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is consuming a healthy meal, consisting of a salad with various vegetables, at their dining table.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a hiking trail with darkening skies and signs of approaching bad weather. Other hikers are leaving the area due to concerns about forecasted thunderstorms.\nPersona Context: \nAn amateur hiker who enjoys weekend trails.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"current time\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"trailhead\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a garden with friends, suggesting a dinner party for the upcoming Saturday night.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"garden\", \"time\": \"next Saturday night\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday night\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Garden dinner party\", \"time\": \"next Saturday night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in their kitchen with ingredients such as chicken, tomatoes, onions, and spices laid out.\nPersona Context: \nUser enjoys trying new recipes but often feels unsure about ingredient measurements.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"chicken curry recipe with ingredient measurements\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be waiting at a busy city bus stop, carrying a laptop bag. They have a meeting scheduled at 9:00 AM downtown.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"downtown\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a sporting goods store, focusing on a display of different bicycle models.\nPersona Context: \nInterested in fitness and outdoor activities.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"bicycle\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"beginner bicycle reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"choosing the right bicycle for fitness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a friend's house, sitting in the living room with several others, and there is a board game on the table. Audio information captures a conversation. One friend says, 'Maybe we should try out that new escape room this weekend?'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}},{\"name\": \"google_search\", \"description\": \"Search for escape room options, availability, and any special deals in the area\", \"parameters\": {\"query\":\"escape room options this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a scenic mountain viewpoint. Multiple mountain peaks are visible in the distance with distinctive shapes and features. A few clouds hang around the tallest peaks. The lighting suggests it's mid-morning with clear visibility. Conversation indicates the user is curious about which peak that tallest one is over there.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the mountain peaks visible in this view based on the location.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Mount in current location\"}}, {\"name\": \"google_search\", \"description\": \"Tool that searches the Google API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Mount in current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying leisure time at a caf\u00e9, working on a jigsaw puzzle while having coffee in a relaxed atmosphere.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a live theater performance of what appears to be Shakespeare's Hamlet, seated in the audience.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a relaxing time in the park with a friend, sharing ice cream.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is camping in what appears to be the Mojave Desert (based on GPS coordinates) at night, gazing at stars and constellations in the night sky.\nPersona Context: \nA casual stargazer with limited knowledge of astronomy but enthusiasm for learning about space\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify stars and constellations visible in this night sky image\", \"image_path\": \"\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Betelgeuse star Orion constellation\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, looking at a coffee maker. The price tag indicates it costs $150.\nPersona Context: \nThe user enjoys coffee and values high-quality appliances.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"coffee maker\"}},{\"name\": \"search_rednote\", \"description\": \"Search for user reviews and recommendations.\", \"parameters\": {\"query\": \"coffee maker reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a shopping mall parking lot, likely looking for transportation. They have a lunch date with a friend at 1 PM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"lunch location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing in a queue at a coffee shop, waiting to place an order.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a picnic table in a park, surrounded by trees and nature.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in or observing a yoga class where an instructor is actively guiding participants through poses.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen, preparing to use spices and herbs for cooking. The task appears to be straightforward.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is watching a movie in a theater.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe image shows the user is standing in front of a kitchen sink, which is divided into two basins. The individual is holding a small black object, possibly a filter or a lid, with their left hand.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a dining table with a plate of food that includes pasta, grilled chicken, and a side of salad.\nPersona Context: \nThe user has a history of managing Type 2 diabetes.. The user is health-conscious and actively manages their diet to control blood sugar levels.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Foods to stabilize blood sugar levels.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at home, reading a novel in a comfortable setting with a cup of tea nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting on a bench in a park, looking pale and holding their chest.\nPersona Context: \nThe user has a history of heart problems.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"heart problem symptoms and first aid\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a balcony with a view of the city skyline at sunset, engaged in a casual conversation about the beautiful scenery.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an aquarium, viewing a tropical fish exhibit. A child nearby has expressed curiosity about a specific blue fish.\nPersona Context: \nA parent\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the blue fish in the aquarium\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API for information about subjects.\", \"parameters\": {\"query\": \"Blue Tang fish\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user went hiking today for approximately eight hours.\nPersona Context: \nThe user enjoys keeping daily logs of their activities on various apps because they like to document their life.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"went hiking today for approximately eight hours\",\"time\": \"today\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a coffee shop with a friend. The audio captures a casual conversation about coffee habits.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking in a busy city area.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a park, surrounded by various leisure activities like jogging, dog walking, and children playing. The atmosphere is lively and relaxing.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a casual conversation with a colleague or friend in a coffee shop, discussing career updates.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bookstore examining a fantasy novel priced at $32.99. A conversation nearby suggests it's part of a popular series.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"fantasy novel hardcover\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"fantasy novel series reviews bundle deals\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a game night with friends, playing what appears to be Monopoly, engaged in friendly competitive banter.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a coffee shop with a friend, looking at a map spread out on the table. Audio information captures a conversation between the user and the friend. The friend says, 'How about we take a road trip this weekend to explore some small towns?'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"small towns\", \"time\":\"this weekend\"}},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}},{\"name\": \"google_search\", \"description\": \"Search for local attractions or events in the small towns\", \"parameters\": {\"query\":\"local attractions or events in small towns this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on multiple monitors with coding and project management tools. A manager requests the code review to be completed by the end of the day.\nPersona Context: \nThe user is a software developer responsible for reviewing and writing code.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"end of the day\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete code review\", \"time\": \"end of the day\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe visual information suggest that the user appears to be waiting for a bus at night.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'Park'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in personal journaling in a quiet, comfortable setting with a cup of tea nearby.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bookstore examining a James Patterson thriller novel. Their friend mentions mixed reviews about the book, suggesting uncertainty about whether to purchase it.\nPersona Context: \nA mystery and thriller enthusiast.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"James Patterson new thriller novel professional reviews ratings\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"James Patterson thriller novel reviews\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"James Patterson thriller novel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is playing a board game with friends, and they have a restaurant reservation they need to leave for in 20 minutes.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"20 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user's friend has had too much to drink and needs to go home to rest.\nPersona Context: \nA responsible individual who looks out for friends' wellbeing and safety\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination\", \"parameters\": {\"current_location\": \"Skyline Nightclub\", \"destination\": \"Friend's home address\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a gym, discussing their exercise routine with a friend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is inspecting a houseplant that shows possible signs of stress or disease with yellowing leaf edges.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a book under a tree in a park. They have a picnic setup with snacks nearby, indicating a leisurely outing.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining premium wireless headphones in an electronics store. A nearby conversation reveals information about the product's noise cancellation feature and battery life.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"premium wireless headphones noise cancellation\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"premium wireless headphones sound quality noise cancellation travel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a crowded bus stop, indicating a high demand for information about bus arrivals.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is gathering printed materials from an industrial printer and organizing them into folders, while a coworker has inquired about the documents.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a sports store, checking out various types of running shoes, likely with the intention of buying a pair.\nPersona Context: \nThe user is a fitness enthusiast who values performance and comfort in footwear.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best running shoes for performance and comfort\"}}, {\"name\": \"google_search\", \"description\": \"Search the web for information.\", \"parameters\": {\"query\": \"best running shoes for performance and comfort\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user at their desk with screens displaying financial data. Audio captures a phone call. A colleague discussing the need to present quarterly results to the board next Monday.\nPersona Context: \nThe user is a financial manager responsible for preparing financial presentations.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Monday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare for quarterly results presentation\", \"time\": \"next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at Malibu Beach which closes at 8PM, and it's currently 7:35 PM. The beach is emptying as sunset approaches. The user's phone battery is critically low at 12%.\nPersona Context: \nA tourist visiting California beaches for the first time\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Malibu Beach\", \"destination\": \"User's accommodation\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at their desk, likely working on email correspondence with multiple documents open. There is no indication of urgency or confusion.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is staying at a hotel with check-out time at 11:00 AM tomorrow. They have a return flight scheduled for 4:30 PM tomorrow and need to arrange airport transportation.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Hotel Check-out\", \"time\": \"Tomorrow, 11:00 AM\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Hotel\", \"destination\": \"Airport\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a shopping mall entrance with a friend, holding several shopping bags. They mention the inconvenience of carrying them home by bus.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"home\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach, reading a novel and enjoying the peaceful scenery.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user has been sitting in front of the computer in the office for an extended period.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking along a well-maintained hiking trail through a forest. The path ahead is clear and well-marked with trail signs.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a family birthday celebration where relatives are sharing nostalgic stories and engaging in good-natured teasing, creating a warm, humorous atmosphere.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a grocery store comparing different brands of olive oil. Their shopping list confirms they intend to purchase olive oil.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"olive oil brands\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best olive oil brands reviews quality comparison\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a bar, engaging in conversation with the bartender.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaged in a friendly conversation with friends at a caf\u00e9.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing a document with dense legal text. There are no visible annotations or highlights.\nPersona Context: \nThe user is not a legal expert but occasionally deals with contracts.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"explanation of key legal terms.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a person's hands holding a small black bird, possibly a chick, on a wooden surface. The setting appears to be outdoors, possibly in a rural or semi-rural area.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is making toast with butter and jam, a simple breakfast preparation. They have multiple slices ready and have already opened the jam jar in preparation for the next step.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a caf\u00e9, sipping coffee, and reading a newspaper.\nPersona Context: \nThe user appreciates quiet moments with a cup of coffee and reading material.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a workstation with two computer monitors displaying code editors.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook pasta, following a recipe from a cookbook with ingredients already gathered on the counter.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user considering purchasing chips in a grocery store.\nPersona Context: \nAn individual managing hypertension through diet and lifestyle changes\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"diet recommendations for hypertension management\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"low-sodium snack alternatives for hypertension\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is working on a computer, typing on a keyboard in an office.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is researching technical specifications in a corporate library or resource center, consulting printed materials while taking notes.\nPersona Context: \nA mechanical engineer who prefers consulting physical reference materials before digital resources\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a remote mountain trail and has suffered a fall resulting in a leg injury. They are 3.5 miles from the trailhead in a somewhat isolated location.\nPersona Context: \nA recreational hiker who enjoys weekend adventures but has limited first aid knowledge\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"first aid for cuts and scrapes while hiking in remote areas\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a book club discussion where members are sharing their literary analysis and personal impressions of a book they've read.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is leading a presentation or brainstorming session in a conference room, drawing on a whiteboard while colleagues observe and provide positive feedback.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is visiting an art gallery and contemplating an abstract painting, surrounded by the quiet atmosphere typical of art museums.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a restaurant, looking at a menu with various food options such as pasta, steak, and salad.\nPersona Context: \nThe user is health-conscious and wants to make informed decisions about their diet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \" calorie counts and heating information of pasta, steak, and salad.\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related information about pasta, steak, and salad.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop near a business center, carrying a portfolio, and has an interview at 11:00 AM.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"business center\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking and has stopped to check a trail map at a junction.\nPersona Context: \nThe user is an avid hiker who enjoys exploring new trails.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"hiking trails information for current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in an art gallery, observing a painting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is eating a pasta meal with a side salad at a dining table, appearing to enjoy their food in a relaxed setting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at pastries in a bakery. The user is likely deciding which pastry to purchase.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a museum, viewing what appears to be a Kandinsky painting from the Bauhaus period, as mentioned by someone nearby.\nPersona Context: \nAn art enthusiast visiting a museum who enjoys learning about artistic movements and techniques\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Wassily Kandinsky Bauhaus period paintings and significance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting with friends in a park, surrounded by picnic items. Audio captures a conversation where a friend suggests organizing a movie night next Friday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Friday\"}}, {\"name\": \"google_search\", \"description\": \"Search for popular movie options or themes.\", \"parameters\": {\"query\":\"popular movie options for movie night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a car rental counter, deciding which vehicle to rent for their trip. They might be considering factors like price, size, and features.\nPersona Context: \nCost-conscious traveler\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"car rental prices at [current location]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friends are enjoying a view from a rooftop bar and are curious about the distance to a nearby music festival.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"rooftop bar\", \"destination\": \"music festival\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in focused software development work in an open office environment, writing code while referencing handwritten notes.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows that the user is in a grocery store, holding a carton of milk while looking at a shopping list on their phone.\nPersona Context: \nUser is lactose intolerant.. User avoids dairy and prefers lactose-free alternatives.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"lactose-free milk\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a concert venue late at night after attending the Summer Music Festival. A friend is asking about transportation back to their hotel, which is 5.3 miles away at the Bayview Resort.\nPersona Context: \nA music enthusiast visiting from out of town to attend a summer festival series\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get directions and estimated time to a destination.\", \"parameters\": {\"origin\": \"current location\", \"destination\": \"Bayview Resort\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Summer Music Festival venue\", \"destination\": \"Bayview Resort\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is shopping in a grocery store, with lots of vegetables and eggs in front of him.\nPersona Context: \nUser often struggles with deciding what to cook.. The user prefers quick and easy recipes due to their busy schedule.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"quick and easy recipes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a conference room with colleagues, viewing a presentation titled 'Annual Sales Strategy'. The conversation involves finalizing the strategy by next Wednesday for a board meeting.\nPersona Context: \nThe user is a sales manager responsible for preparing strategic presentations.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Wednesday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare for board meeting\", \"time\": \"next Wednesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is working.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having dinner with what appears to be their parents and another family member, who are reminiscing about the user's childhood eating habits and subsequent lifestyle changes.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a mountain lodge, enjoying a warm beverage by the fireplace, creating a cozy and relaxing atmosphere.\nPersona Context: \nThe user appreciates listening to jazz music during cozy moments.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing a cheese board with different types of cheese, grapes, and has opened a bottle of red wine to breathe.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working in a coworking space, focusing on their laptop amidst papers and coffee.\nPersona Context: \nFreelancer\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a park bench, focused on setting up a digital camera.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying an evening campfire at a campsite, roasting marshmallows as the sun sets in a forest setting.\nPersona Context: \nAn outdoor enthusiast who enjoys traditional camping experiences without technological distractions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park with friends playing frisbee. Audio captures a conversation where a friend suggests organizing a picnic next Saturday.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"park\", \"time\": \"next Saturday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a city square with historic buildings and is interested in seeing the cathedral.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"city square\", \"destination\": \"cathedral\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a conference room, sitting at a table with a laptop and a notebook open.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Chinese restaurant, browsing a menu with options like steamed dumplings, vegetable stir-fry, and hot and sour soup.\nPersona Context: \nThe user wants to reduce their fat intake while enjoying a flavorful meal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"fat content in steamed dumplings, vegetable stir-fry, and hot and sour soup\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"tips for choosing low-fat options at a Chinese restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lounging on a sofa with a blanket, watching TV. \nPersona Context: \nThe user enjoys relaxing with TV shows in their downtime.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a waiting room with a few other people, some reading magazines, others using their phones.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows The user is sitting on a park bench, holding their chest. The sound of heavy breathing and faint traffic noise is heard. The user appears to be experiencing discomfort or pain in their chest while sitting outdoors.\nPersona Context: \nThe user has a history of mild heart issues but has not reported any recent episodes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"chest pain emergency steps.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is looking in the mirror while wearing summer clothes, such as short sleeves and shorts.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a large office building and has a meeting scheduled at 10 AM at the Downtown Office. It appears the user is preparing to head to the meeting.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"Downtown Office\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing dough for cookies, using a rolling pin to flatten it before cutting shapes with cookie cutters.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a deserted bus stop with no visible schedule information on the digital display.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user working on financial documents. Audio indicates a deadline for the financial report by tomorrow.\nPersona Context: \nThe user is a financial analyst responsible for reporting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"tomorrow\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize financial report\", \"time\": \"tomorrow's 5 p.m.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing gold necklaces in a jewelry store, taking their time to view the different options displayed in the glass case. A sales associate is present but giving the user space to browse.\nPersona Context: \nA discerning shopper who enjoys the experience of viewing luxury items in person and prefers to take their time before making significant purchase decisions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach at sunset, enjoying the natural scenery in a peaceful environment.\nPersona Context: \nA nature enthusiast who appreciates quiet moments of natural beauty\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is packing a suitcase with spring or autumn clothes like light sweaters and trousers. The agenda shows that the user is departing for Japan.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Japan\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual data indicates user stands under a glass-paneled bus shelter, seems looking at the bus stop sign.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"check_bus_schedule\", \"description\": \"Check real-time bus schedules for a specific route.\", \"parameters\": {\"bus_stop\": \"user current location\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"},{\"name\": \"book_uber\", \"description\": \"Book a ride to a specified location.\", \"parameters\": {\"current_location\":\"user current location\", \"destination\": \"User's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be recovering from a minor knee injury. The user may recently completed an intensive workout.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"advice on managing minor knee injuries.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"advice on managing minor knee injuries.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is waiting in line for a food truck.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lying on a blanket in a park, gazing at the clouds, suggesting a moment of relaxation and reflection.\nPersona Context: \nThe user appreciates ambient music during moments of relaxation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen, using an electric mixer to blend ingredients in a bowl.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking in the park and talking to a friend. Audio information shows there is a conversation between the user and the friend. The friend says: 'Did you hear about the big soccer game this weekend?'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"big soccer game, including its showtimes or ticket price\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a hobby shop examining a high-end drone kit with a controller and accessories.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"high-end drone kit with controller\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"drone kit reviews specifications flight time camera quality\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is jogging in a park. The environment is serene with green trees and a clear sky, suggesting a pleasant day for outdoor exercise.\nPersona Context: \nThe user enjoys listening to energetic music while exercising.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a public library and is seeking recommendations for a good mystery novel.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"top-rated mystery novels\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"mystery novels reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a kitchen preparing to cook with fresh vegetables, a cutting board, and a pot on the stove.\nPersona Context: \nThe user enjoys trying new and healthy recipes but often seeks guidance on cooking techniques.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"vegetable stir-fry recipe with fresh vegetables\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining an unusual flowering plant with purple blooms in what seems to be a botanical garden or park setting.\nPersona Context: \nA casual gardening enthusiast who enjoys learning about unique plant species\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this flowering plant with purple flowers\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Passionflower Passiflora species characteristics cultivation uses\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is watching a sports game with friends in a living room. Someone has suggested going to a new Italian restaurant to celebrate John's birthday next Saturday.\nPersona Context: \nA social coordinator who often plans gatherings and special occasions for friend groups\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday evening\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"new Italian restaurant reservation information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is charging their electric vehicle at a public charging station.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"2 hours\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing a presentation on team performance metrics due by the end of the week.\nPersona Context: \nThe user is a team leader responsible for performance assessments.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"end of the week\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete performance metrics presentation\", \"time\": \"by the end of the week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is multitasking, managing several project documents and has a deadline to send an updated project plan by noon.\nPersona Context: \nThe user is a project coordinator.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize and send project plan\", \"time\": \"noon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a specialty food store looking at an expensive bottle of imported Italian olive oil called 'Olio Supremo' priced at $45.99.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Olio Supremo olive oil expert reviews price comparison alternatives\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Olio Supremo olive oil reviews\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Olio Supremo olive oil\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a news article about tech stocks tumbling due to inflation concerns, with specific mentions of Apple (AAPL) and Microsoft (MSFT).\nPersona Context: \nA retail investor who regularly monitors market news and maintains a portfolio of technology stocks\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"AAPL\", \"date\": \"2025-04-25\"}}, {\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"MSFT\", \"date\": \"2025-04-25\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a beach with friends, sitting under a beach umbrella. Audio captures a conversation. A friend says, 'Let's plan a bonfire night here next Saturday!'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"beach\", \"time\":\"next Saturday\"}},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Saturday\"}},{\"name\": \"google_search\", \"description\": \"Search for information on beach bonfire regulations and permits\", \"parameters\": {\"query\":\"beach bonfire regulations and permits\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is conversing with a colleague in an open-plan office, near a window that looks out over a cityscape. There is a conversation: \"I was thinking of flying to Sydney this Friday. Maybe we can see the Opera House and go to Bondi Beach.\".\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Sydney\", \"time\": \"this Friday\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows that the user is shopping for running shoes, examining the price of a specific pair.\nPersona Context: \nThe user is budget-conscious and prefers finding deals online before making purchases.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the current price of a product from online retailers.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is sitting on a couch with a tablet, browsing a travel website.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Popular tourist destinations and tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a historical museum, observing an exhibit labeled 'Ancient Egypt Artifacts.'\nPersona Context: \nHistory enthusiast\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Ancient Egyptian artifacts and cultural significance\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"historical context and significance of Ancient Egyptian artifacts\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is viewing a computer screen with a complex spreadsheet open, filled with numerical data.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a table with friends, sharing a meal.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a diner, browsing a breakfast menu with options such as pancakes, scrambled eggs, and bacon.\nPersona Context: \nThe user is interested in starting their day with a balanced and healthy meal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for pancakes, scrambled eggs, and bacon\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for pancakes, scrambled eggs, and bacon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a doctor's office during a medical appointment, receiving feedback about improved blood pressure readings following a medication adjustment.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a camping trip, inside a tent, enjoying a natural setting with no immediate indicators of assistance needs.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is relaxing in a hammock in their backyard, surrounded by plants and a small water fountain.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nUser appears to be waiting for a bus while actively using their phone, possibly checking for updates.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen, with various fresh fruits on the counter. The user appears to be preparing to make a fruit salad or snack.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport terminal where their flight UA789 to Chicago has been delayed by 2 hours due to weather conditions.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"alternative flights to Chicago O'Hare today\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"3:45 PM to 6:00 PM today\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current terminal gate\", \"destination\": \"airport lounges and restaurants\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing a physical document with handwritten notes at their desk.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing in front of a bus station.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a beach with friends, sitting under a beach umbrella. Audio captures a conversation. A friend says, 'Let's plan a bonfire night here next Saturday!'\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"beach\", \"time\": \"next Saturday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday\"}}, {\"name\": \"google_search\", \"description\": \"Search for information on beach bonfire regulations and permits\", \"parameters\": {\"query\": \"beach bonfire regulations and permits\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Bonfire night at the beach\", \"time\": \"next Saturday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a resturant, looking at a brunch menu featuring egg-based dishes, such as omelets and eggs Benedict.\nPersona Context: \nThe user wants to balance delicious brunch choices with heart health considerations.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Low-cholesterol brunch options at this restaurant\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Heart-healthy brunch tips\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Recommended daily cholesterol intake and egg consumption guidelines\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on the sofa and holding his stomach, appears to be experiencing some stomach discomfort.\nPersona Context: \nThe user has a history of digestive issues and prefers low-acidic foods.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"digestive issues\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a bench overlooking a beach at sunset.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a zoo, observing tigers in their enclosure.\nPersona Context: \nAnimal lover\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Tigers habitat and conservation\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tiger conservation efforts and their importance in the ecosystem.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a friend's house, sitting in the backyard with a group of people. Audio captures a conversation where someone suggests organizing a barbecue this weekend.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\":\"this weekend\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for barbecue recipes and tips.\", \"parameters\": {\"query\":\"barbecue recipes and tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting by a pond, feeding ducks.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is working on a 1000-piece jigsaw puzzle of a mountain landscape at a desk in what seems to be their home office. They have organized pieces by color and completed the border.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is taking a walk in the park while wearing a fitness tracker. It is a sunny day, and the park is relatively busy.\nPersona Context: \nThe user is health-conscious and enjoys tracking their fitness activities.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is receiving professional physical therapy treatment with specific instructions from their therapist for shoulder rehabilitation exercises.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a workout session at the gym, actively lifting weights and referring to a workout plan on a tablet.\nPersona Context: \nThe user is a fitness enthusiast who follows a structured workout routine.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"weightlifting tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in concentrated data analysis work at their desk, comparing information between digital spreadsheets and printed materials.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bookstore looking at a flyer for a book signing by author J.K. Morgan for the novel 'Midnight Chronicles' this Thursday at 6 PM. A bookstore employee mentioned that it will be a popular event with a big turnout, suggesting arriving early.\nPersona Context: \nAn avid reader who collects signed first editions\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Thursday 5 PM to 8 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is conversing with a partner on the road. Audio information shows there is a conversation between the user and others. The partner says \"Hi, how about organizing a team-building hike this weekend? We haven't had a team-building event in a long time.\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\": \"this weekend\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is peeling potatoes, a repetitive and simple task, with peeled potatoes and a pot of water ready for further cooking.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a conference room with colleagues, viewing a presentation titled 'Quarterly Financial Report'. Conversation content: 'We need to prepare for the next meeting with the investors scheduled for next week.'\nPersona Context: \nThe user is a financial analyst responsible for preparing financial reports.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next week\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Investor meeting\", \"time\": \"next week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is shopping in a supermarket and is standing in front of the olive oil section, where the price is displayed as $150.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"olive oil\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"product selection tips for olive oil\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"basic knowledge for olive oil\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at home folding and organizing laundry, methodically sorting different clothing items into neat piles.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a large shopping mall, looking at a directory board. They are unsure about the location of the electronics store.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"shopping mall entrance\", \"destination\": \"electronics store\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a piano with complex sheet music displayed on the stand. Their recent search and viewing history suggests they are a beginner learning to play piano and read music.\nPersona Context: \nA music enthusiast who recently started learning to play the piano\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this sheet music piece and assess its difficulty level for piano players\", \"image_path\": \"\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Moonlight Sonata simplified version for beginners piano tutorial\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a gym, standing in front of a treadmill.\nPersona Context: \nThe user is new to fitness and does not exercise regularly.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"identify the equipment they currently use.\",\"image_path\":\"\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"suitable fitness tips based on the user's fitness level.\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Tips for using this equipment in the gym.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a relaxing picnic in a public park, reading a book under a tree while observing the casual activities of others in the park.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing at a bus stop, looking at the bus station.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is slicing bread, a simple kitchen task, using a bread knife to make even slices.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cracking eggs into a bowl, with some shells visible on the counter.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an electronics store, considering purchasing a gaming laptop. A conversation suggests they are interested in its gaming performance.\nPersona Context: \nThe user is a gamer who frequently upgrades his gaming gear for better performance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"gaming laptop\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"gaming laptop reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe image shows the user engaged in gardening indoors. The user is wearing black gloves and appears to be tending to a plant in a terracotta pot.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an elevator where other passengers are making small talk about the weather forecast.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"\", \"time\": \"\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in an office cubicle with an email thread about 'Team Project Review'. The conversation involves completing the project review by Friday.\nPersona Context: \nThe user is a team leader responsible for project reviews.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"Friday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete project review\", \"time\": \"Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying leisure time at a coffee shop, reading a book while having coffee and a pastry in a comfortable, ambient environment.\nPersona Context: \nAn avid reader who enjoys the atmosphere of coffee shops as a third place for relaxation and literary escape\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking up a steep mountain trail at high elevation (8,500 feet) in hot weather (85\u00b0F). Their labored breathing is audible, and they appear to be exerting significant physical effort.\nPersona Context: \nThe user is a recreational hiker who occasionally tackles challenging trails but is not accustomed to high-altitude hiking.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"high altitude hiking safety and symptoms of altitude sickness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mexican restaurant, browsing a menu with options like chicken fajitas, shrimp tacos, and a black bean bowl.\nPersona Context: \nThe user is prioritizing protein intake for muscle recovery and wants to choose a healthy option.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"protein content in chicken fajitas, shrimp tacos, and black bean bowls\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"tips for balancing macros in a high-protein diet\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVision information suggests the person is engaging in a conversation with a colleague in an office. The user is talking to a partner. The content of conversation is: \"Hi, how about going to Hong Kong this weekend? I want to go to the Disneyland and Victoria Harbour.\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\": \"this weekend\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaged in painting a landscape on a canvas positioned near a window.\nPersona Context: \nA hobbyist painter who enjoys creating landscapes and still-life compositions during free time\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at their spice collection in a kitchen cabinet, possibly selecting seasonings for a dish.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is photographing a mountain landscape from a vantage point during early morning golden hour, with hiking gear nearby.\nPersona Context: \nA landscape photographer who prioritizes capturing natural scenes without technological distractions during the creative process\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a poster for a Spring Festival happening this Saturday from 11 AM to 8 PM at a local park. The event features live music, food trucks, and family activities.\nPersona Context: \nA parent who enjoys finding family-friendly weekend activities\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Saturday 11 AM to 8 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is actively engaged in typing, likely drafting a document or responding to emails in their office cubicle.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is seated in a library, quietly talking to a friend. Audio information shows there is a conversation between the user and the partner. The friend says: 'I can\u2019t believe the final exam schedule just came out.'\nPersona Context: \nStudent\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVision information suggests the person is talking to a colleague in an office. There is a conversation. \"Hey, how about visiting Singapore next weekend? I'm really excited to see Sentosa and Gardens by the Bay.\"\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Singapore\", \"time\": \"next weekend\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is inspecting various smartphones at an electronics store, specifically focused on two brands, labeled Model X at $899 and Model Y at $799.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"smartphone models\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"feature comparison of Model X and Model Y smartphones\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a long-distance bus ride, viewing the countryside scenery.\nPersona Context: \nThe user enjoys listening to podcasts during long journeys.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song or podcast from the user's library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is reading a book in a public library.\nPersona Context: \nThe user is an avid reader who frequently visits the library.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user expresses a desire to improve their diet.\nPersona Context: \nRecent health checkup showed high cholesterol\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"healthy recipes for patients with high cholesterol\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a shopping mall, surrounded by various clothing and accessory stores. The environment is lively with announcements about ongoing sales.\nPersona Context: \nThe user enjoys listening to music while shopping to enhance their experience.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a classic car show, looking at what appears to be a 1960s Cadillac Eldorado, as mentioned in nearby conversation.\nPersona Context: \nA casual automotive enthusiast who appreciates classic cars but doesn't have deep technical knowledge about them\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"1960s Cadillac Eldorado features history significance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a casual conversation with a friend at a coffee shop. The user is discussing feeling tired despite adequate sleep.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"tips for improving energy levels and sleep quality\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a gym, lifting weights.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"identify the equipment they currently use.\",\"image_path\":\"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"guidance on properly using the current equipment.\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"guidance on properly using the current equipment.\"}},{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in organizing and potentially reclassifying physical files in an office filing system.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is cooking pancakes on a griddle, flipping some that are currently cooking while a plate of finished pancakes sits nearby. A bowl of remaining batter is available to make more.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is participating in a group pilates class and is currently on a mat, ready to start the session.\nPersona Context: \nThe user enjoys listening to serene music during pilates to maintain focus and rhythm.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing by a hotel pool, casually reading a magazine about local attractions while enjoying a beverage.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a library looking at a poster for a free financial planning for retirement workshop happening next Tuesday at 6 PM.\nPersona Context: \nA mid-career professional interested in planning for the future\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Tuesday 6 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Financial Planning for Retirement Workshop\", \"time\": \"next Tuesday 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is sitting on a balcony, enjoying a cup of coffee with a view of the garden below.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a grocery store examining an expensive bottle of imported Italian extra virgin olive oil priced at $19.99.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Italian extra virgin olive oil cold-pressed\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best quality extra virgin olive oil comparison\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is seated in a coffee shop talking to a friend. Audio information shows there is a conversation between the user and the friend. The friend says: 'Have you watched the new superhero movie that just came out?'\nPersona Context: \nThe user is not frequently watching movies.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new superhero movie showtimes and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a meeting focused on project timelines. Audio indicates a discussion about meeting quarterly deadlines.\nPersona Context: \nThe user is a project manager responsible for ensuring project completion within deadlines.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"end of quarter\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Project phase reminders\", \"time\": \"before end of quarter\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the person is packing lightweight hiking gear like trekking pants, boots, and a windbreaker. The agenda indicates that the user is departing for New Zealand.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"New Zealand\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a lakeside, skipping stones on the water in the late afternoon.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is navigating through an office hallway, casually observing meeting rooms as they pass by.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is watching a movie in a theater, enjoying popcorn while an action film plays.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is using a dryer to dry their clothes.\nPersona Context: \nA busy professional doing laundry during their free time\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"50 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is considering purchasing vitamin D supplements, potentially to improve bone health.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"benefits and recommended dosages of vitamin D\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Vitamin D\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments.\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a meditation session at home.\nPersona Context: \n\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  }
]