[
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a pharmacy comparing different pain relievers, specifically ibuprofen and acetaminophen.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"ibuprofen versus acetaminophen for migraine treatment effectiveness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is stirring a pot of soup on the stove. The task seems to be progressing without any issues.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is camping in a remote wooded area and shows signs of a possible allergic reaction with swelling and red marks while setting up camp.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"managing mild allergic reactions in remote wilderness settings\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a small meeting room, possibly reviewing or preparing notes on the whiteboard.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing a souvenir shop with clearly marked prices, examining various local items and crafts while other customers are also shopping.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is consuming a healthy meal, consisting of a salad with various vegetables, at their dining table.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a meeting about performance reviews. Audio indicates a deadline for completing reviews by next Monday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Monday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete performance reviews\", \"time\": \"before next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is enjoying a meal at a restaurant.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at home, watching a movie on their TV.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a desk, focused on a slide presentation on a large computer monitor.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a workspace with a computer setup. The main focus is on a large monitor displaying a colorful desktop background featuring geometric shapes in vibrant colors. The user may be working.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing at a bus stop with a timetable visible on a nearby pole.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting on a park bench, gazing at a small pond where ducks are swimming. The park is peaceful with trees providing shade.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is washing fresh vegetables in the kitchen sink, a routine task in meal preparation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a fast-food restaurant, browsing a digital menu with options like a double cheeseburger, large fries, and a milkshake.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for double cheeseburger, large fries, and milkshake\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for double cheeseburger, large fries, and milkshake\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a public beach, sitting on a towel while observing other beachgoers swimming and sunbathing. A lifeguard station is visible nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is chatting with a colleague in a break room. There\u2019s a small whiteboard showing brainstorm notes in the background. There is a conversation: \"How about a weekend trip to Seoul? I really want to explore Myeongdong and maybe go up N Seoul Tower.\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Seoul\", \"time\": \"this weekend\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is socializing with friends or family in a living room setting, where someone is sharing a humorous anecdote about their cousin's embarrassing situation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is washing lettuce, likely preparing ingredients for a salad. They have the necessary tools (colander, cutting board, knife) ready for food preparation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook pasta on the stove.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tips for cooking pasta and quick sauce recipes\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"10 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a farmer's market examining unusual heirloom eggplants called 'Listada de Gandia'. The vendor mentioned they're less bitter and good for grilling.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Listada de Gandia eggplant recipes cooking methods origin\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API.\", \"parameters\": {\"query\": \"Listada de Gandia eggplant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a meal at home, eating a sandwich in their kitchen.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a light stretching routine in front of a mirror, possibly as part of a morning ritual.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having dinner at a restaurant with someone they haven't seen in a while, engaging in casual catch-up conversation about their lives.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a flyer for a blood donation drive happening this Saturday from 9 AM to 4 PM at the local community center.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Saturday 9 AM to 4 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Blood Donation Drive at Community Center\", \"time\": \"this Saturday 10 AM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in the kitchen with various spices on the counter.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"international recipes using spices\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is peeling potatoes, with some already peeled in a bowl and others waiting to be peeled. They're using a peeler and have a knife ready on a cutting board.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the process of food preparation, specifically chopping vegetables including bell pepper and onion.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting on a park bench, enjoying the view of children playing.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is knitting with blue yarn in their living room, following a pattern from an open book nearby. They have tea within reach and a cat sleeping on a couch in the same room.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a hammock in their backyard, enjoying the sunlight filtering through the trees.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is carefully reviewing printed documents, which suggests focused and detailed work.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a video conference with several participants, likely discussing work-related topics.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a grocery store comparing different pasta sauce options, appearing indecisive.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"low sodium pasta sauce options\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"low sodium pasta sauce\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"low sodium pasta sauce\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working in a cubicle, likely reviewing or preparing a progress report on their desktop computer, surrounded by relevant files.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is constructing a model airplane.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to bake a dessert following a recipe from the cookbook.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"measuring techniques and conversion charts for baking\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is weighing themselves on a bathroom scale as part of what appears to be a personal health monitoring routine.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is waiting in line at a theme park for a roller coaster ride.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is practicing golf at a driving range.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a doctor's office, reading a pamphlet on a small table.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop with a suitcase, likely heading to JFK Airport for a flight at 3 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current_location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"JFK Airport\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is performing a precise technical repair or maintenance task on an electronic device, following a methodical process with organized tools and reference materials.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is driving a car, with their hand on the steering wheel. The sky is clear and blue, indicating a sunny day.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a hotel lobby browsing tourist information about local attractions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"top-rated attractions in [location]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a scenic mountain viewpoint. Several mountain peaks are visible in the distance, with snow caps visible on the tallest ones. A wooden information board stands nearby but is too far to read clearly.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Rocky Mountain National Park notable peaks Longs Peak\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is discussing their upcoming half-marathon participation while consuming caffeine at a coffee shop.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a bakery, browsing a display with options such as croissants, muffins, and cookies.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for croissants, muffins, and cookies\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for croissants, muffins, and cookies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is collecting printed documents from a functioning printer in an office setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a panoramic view from a hilltop, with a valley below and mountains in the distance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a forest trail and has encountered a distinctive bright red mushroom with white spots growing near the path.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Amanita muscaria fly agaric mushroom identification toxicity\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a grocery store aisle, examining pasta sauces and possibly having trouble reading the labels, which might indicate a need for assistance with nutritional information or price comparison.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"pasta sauce\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"pasta sauce nutritional information health ratings\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is setting up camp as daylight is fading. They have started to set up their tent but haven't completed the process.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"quick tent setup guide and cold weather camping preparation tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking through a park, holding a take-out coffee cup.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden photographing a distinctive purple flowering plant. Someone nearby has asked about the identity of the plant, suggesting interest in learning more about it.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this purple flowering plant species\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Passiflora incarnata purple passionflower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual informatin shows the user is standing in front of a shelf in a grocery store, looking at different brands of cereal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Brand A cereal, Brand B cereal, Brand C cereal\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"nutritional information for cereal brands\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is boiling pasta in a pot of water on the stove.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a park with a group of friends enjoying a picnic. Audio captures a suggestion to play some music to enhance the atmosphere.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in an open-plan office with a whiteboard showing project timelines. Audio captures a conversation. A colleague says: 'Let's schedule a team meeting to go over the project milestones next Thursday.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Thursday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Team meeting to discuss project milestones\", \"time\": \"next Thursday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a meeting about submitting the marketing strategy document by Wednesday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Wednesday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete marketing strategy document\", \"time\": \"by Wednesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is operating a forklift, transporting pallets of boxes within a warehouse.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a train station platform viewing a departures board showing delayed trains. They appear concerned about time, repeatedly checking their watch. According to their mobile data, they have a client meeting at Millennium Tower scheduled for 10:30 AM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current train station\", \"destination\": \"Millennium Tower\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"current train station\", \"destination\": \"Millennium Tower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an art gallery, observing a painting labeled 'Impressionism.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Impressionism and artist information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining a series of animal tracks in mud along a woodland trail. The tracks appear to be from a medium-sized animal with four toes and claw marks..\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify what animal made these tracks based on paw print pattern and size\", \"image_path\": \"\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Coyote behavior Pacific Northwest wildlife safety\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport where their flight to San Francisco has been delayed by over 3 hours, from 2:15 PM to 5:30 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Today evening after 7:30 PM in San Francisco\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a bus stop in heavy rain. Their view shows several people huddled under the small shelter, which is already crowded. Water is pooling on the ground and the user's shoes are visible at the bottom of the frame, getting soaked.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current location bus stop\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"current GPS coordinates\", \"destination\": \"user's likely destination based on routine\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is hiking in a forest. The audio information shows the user appears lost and unsure of their location.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Use Google Maps to provide navigation instructions.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"trailhead\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a technology expo, interested in smart home technology.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"smart home technology features and compatibility\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"smart home technology\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a caf\u00e9 in a foreign city, enjoying a drink and the view of passersby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is enjoying a comedy movie with friends in a living room setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach, lying on a towel with personal items nearby, and appears to be enjoying the sunshine and peaceful atmosphere.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to bake chocolate chip cookies, following a recipe from a cookbook. They have gathered ingredients including flour, eggs, sugar, and butter.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tips for perfect chocolate chip cookies\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"baking time\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a hike on a well-marked trail with clear weather conditions. The environment is calm and scenic.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a park while reading a book. The environment is peaceful with other park visitors engaged in their own activities.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the person is packing a suitcase with summer clothes like t-shirts and shorts. The agenda indicates that the user is departing for Switzerland.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Switzerland\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a Chinese restaurant, browsing a menu with various options such as Kung Pao chicken, sweet and sour pork, and fried rice.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information of these foods for Kung Pao chicken, sweet and sour pork, fried rice\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts and heating information about Kung Pao chicken, sweet and sour pork, and fried rice\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting at a park bench. Audio information shows the user is engaged in a conversation with a friend. The friend says: \"I heard there's a great jazz concert happening downtown this Saturday. Do you know anything about it?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"jazz concert downtown this Saturday.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user has been sitting at the desk at home, studying for an extended period.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user standing at a bus stop with a suitcase, looking at the bus schedule.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook a vegetable stir-fry. They have fresh vegetables ready on a cutting board, and a pot of water is starting to boil on the stove. They're following a recipe displayed on a tablet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"optimal cooking times for vegetables in stir-fry\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"vegetable blanching time\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a companion are on a beach as the sky darkens. There is a conversation: \"These waves look stronger than usual. Do you think a storm\u2019s rolling in?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is studying from a textbook in a library, taking notes and using highlighters to mark important information in a quiet, focused environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing fiction books in a bookstore.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a sunset view from their balcony, surrounded by potted plants while birds fly across the colorful evening sky.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is setting up a campsite in a forest clearing at sunset, having pitched a tent and now arranging logs for a campfire.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a 4-person camping tent priced at $329.95 in an outdoor equipment store.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"4-person premium camping tent\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"camping tent waterproof rating rain performance setup time\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a coffee shop with a friend. Audio captures a conversation where a friend suggests going to an art exhibition this weekend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for details about the art exhibition.\", \"parameters\": {\"query\": \"art exhibition this weekend\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Visit art exhibition\", \"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is exploring a community garden with medicinal plants and herbs, overhearing a conversation about the plants' healing properties.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a focused coding session at their desk in an open-plan office, referencing documentation while writing code.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the middle of a structured arm workout at the gym, following what appears to be a planned routine tracked on their fitness app. They're maintaining proper form and staying hydrated.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an art gallery that's closing soon. It's dark and raining heavily outside. They have a dinner reservation at Bella Italia Restaurant at 8:30 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get directions and estimated time to a destination.\", \"parameters\": {\"origin\": \"current location\", \"destination\": \"Bella Italia Restaurant\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Art Gallery\", \"destination\": \"Bella Italia Restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop, indicating potential travel plans.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading and taking notes in a library environment, with other people studying nearby in the quiet space.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a knitting project in a comfortable home environment, with organized supplies and a relaxed setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting in a park, observing children playing soccer in an open field. The atmosphere is lively and joyful.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a professional panel discussion on AI in supply chain optimization. The speaker's name and company are visible, and they are discussing AI-driven logistics.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"Acme Corp AI initiatives in logistics.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is hiking on a trail in a dense forest under a clear blue sky.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing zucchini noodles with a spiralizer, with a pan heating on the stove and sauce ingredients ready nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a kitchen, carefully chopping vegetables in an organized manner, suggesting they are preparing ingredients for a meal. The process appears deliberate and controlled.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is rolling out dough on a countertop, likely preparing to bake or cook.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop near an office park, holding a briefcase, and has an important presentation scheduled for 11:00 AM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"office park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a library, browsing titles.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is walking near a busy street and looking at a bus stop named 'University.'.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'University'\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a theme park that's closing. A text message indicates their expected ride has had car troubles and can't pick them up.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Theme park exit\", \"destination\": \"User's home address\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is checking into a hotel in City Y, possibly for leisure or business travel.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"hotel amenities and services in City Y\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing by a hotel pool during vacation, reading a book and enjoying the sunny weather.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is holding premium coffee maker in electronics store. Price tag shows $399.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"coffee maker\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a cafe, enjoying a conversation with a friend. The atmosphere is lively but relaxed, with no indication of urgency or need for assistance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking in a park with a friend. The wind is getting stronger, and the sky is gray. There is a conversation: \"Hey, can you feel that breeze picking up? Do you think it's going to turn into a storm soon?\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a living room with friends watching TV. A conversation captures a suggestion to plan a road trip next weekend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for popular road trip destinations and planning tips.\", \"parameters\": {\"query\": \"road trip destinations and planning tips\"}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"road trip destination\", \"time\": \"next weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a group chat where team members are discussing the need to schedule a meeting about recent customer feedback. Team members are suggesting Thursday afternoon as a possible meeting time.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Customer Survey Results Discussion\", \"start_time\": \"2025-05-01 14:00:00\", \"meeting_location\": \"Conference Room A\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime and return all events as a summarized string.\", \"parameters\": {\"time\": \"2025-05-01 14:00:00\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Customer Survey Results Discussion\", \"time\": \"2025-05-01 14:00:00\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking in a shopping mall with a friend. Audio information shows there is a conversation between the user and others. The partner says: \"I want to buy a new watch. Do you know where the best watch stores are around here?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"watch stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"watch stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing code architecture diagrams on a whiteboard with TODO items. It's late afternoon (4:45 PM), and a colleague has just reminded them about API documentation updates needed before a client demo scheduled for tomorrow morning.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete API documentation updates for client demo\", \"time\": \"Today 5:00 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing by the river, enjoying the soothing sounds of water and the act of skipping stones.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is receiving instructions from a physical therapist to perform specific stretches three times weekly and attend weekly Tuesday appointments for the next month.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Tuesdays for the next month\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Physical therapy stretching exercises\", \"time\": \"three times weekly\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is plating a completed meal of grilled chicken, roasted vegetables, and rice, focusing on the presentation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a campsite with a tent set up and a campfire burning, with marshmallow roasting supplies ready.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop with a suitcase, likely needing to reach Business Park for a meeting at 2 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current_location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"Business Park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for pet supplies, particularly interested in pet food options.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"pet food\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"nutritional information on pet food\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best pet food reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the initial stages of baking a cake, carefully measuring flour while following a recipe from a cookbook. All necessary ingredients are organized and ready for use.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is measuring flour into a bowl using a measuring cup, which suggests they are preparing to bake or cook.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is traveling by train, observing the scenery outside.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can identify landmarks or regions.\", \"parameters\": {\"prompt\": \"Identify landmarks or regions visible from the train window.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API for historical or factual information.\", \"parameters\": {\"query\": \"Lake District\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is sitting in front of the computer, either working or studying. The user's fitness watch shows an elevated resting heart rate of 102 BPM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"advice on elevated heart rate and flushing.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"advice on elevated heart rate and flushing.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is practicing playing the guitar in a relaxed, home office environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Search the web for online guitar tutorials or sheet music.\", \"parameters\": {\"query\": \"online guitar tutorials or sheet music\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tips on improving guitar techniques\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the road.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking down a quiet residential street lined with trees and parked cars.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is with friends in a living room, suggesting a game night for the next Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Game night\", \"time\": \"next Friday\"}}, {\"name\": \"google_search\", \"description\": \"Search for popular board games and their rules.\", \"parameters\": {\"query\": \"popular board games for game night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for gaming laptops in an electronics store, comparing specifications and prices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"gaming laptop\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"gaming laptop\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"gaming laptop\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a kitchen with ingredients like tomatoes, basil, and mozzarella, looking at a cookbook open to Italian cuisine.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Caprese salad recipe with tomatoes, basil, and mozzarella\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a stretching exercise on a yoga mat in their living room.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a music store looking at a digital piano keyboard with weighted keys.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"digital piano weighted keys\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"digital piano reviews beginners intermediate bundle\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a rural bus stop with reduced service and a broken schedule display. They have a doctor's appointment at City Medical Center at 1:30 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"rural bus stop location\", \"destination\": \"City Medical Center\"}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"rural bus stop location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"rural bus stop location\", \"destination\": \"City Medical Center\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaging in a stretching routine in a peaceful outdoor setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading an email from a marketing team member requesting to schedule a meeting for next week to discuss a Q2 campaign launch.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Q2 Campaign Discussion with Marketing\", \"start_time\": \"2025-05-06 14:00:00\", \"meeting_location\": \"Conference Room B\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime and return all events as a summarized string.\", \"parameters\": {\"time\": \"2025-05-06 14:00:00\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Q2 Campaign Discussion with Marketing\", \"time\": \"2025-05-06 14:00:00\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is walking through a shopping mall chatting with a colleague. Audio information shows there is a conversation between the user and the colleague. The partner says \"Have you tried that new Italian restaurant on the third floor? Everyone's talking about it.\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new Italian restaurant third floor shopping mall\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is checking the pasta menu at an Italian restaurant, focusing on gluten-free pasta and lighter sauce options.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Gluten-free pasta options at this Italian restaurant\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Top-rated gluten-free friendly Italian restaurants near this location\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Safe gluten-free alternatives for pasta dishes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is sitting in a caf\u00e9 with a friend, discussing weekend plans. Audio information captures a conversation between the user and others. The partner says: \"What do you think about going to the barbecue this Sunday?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\":\"this Sunday\"}},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this Sunday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a yoga studio, engaging in a stretching routine on a yoga mat.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking in a kitchen. The individual is standing in front of a gas stove, holding a frying pan with what appears to be minced meat or ground beef..\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is standing in a park, stretching before a run.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a restaurant, looking at a menu, and appears to be preparing to order food.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"Popular menu options at this restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a beach boardwalk with the sun setting, approaching an 'Oceanside Shuttle' bus shelter. There's a weather alert for a thunderstorm starting at 8:00 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"Oceanside Shuttle\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in his cubicle, focused on writing or responding to emails.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a cluster of unusual mushrooms growing at the base of a large oak tree in a forest setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"mushroom species Redwood National Forest oak tree base identification\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is tasked with preparing the final budget report by next Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare final budget report\", \"time\": \"before next Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is seated at a small table in a coffee shop, with a cup of coffee and a laptop on the table.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the process of checking into a hotel. They are at the reception desk with no visible signs of confusion or need for assistance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user has a packed schedule today with back-to-back meetings. A colleague is requesting to schedule a quick chat.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"today after 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is navigating through an airport terminal. They are surrounded by shops and other passengers, with no signs of confusion or immediate travel needs.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach, lying on a colorful towel under a large umbrella. They appear to be dozing with eyes closed, wearing sunglasses and swim attire. A paperback novel lies open and face-down on the towel beside them. The ocean waves can be seen gently rolling onto the shore a short distance away, and other beachgoers are visible enjoying the sunny day.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in focused document review, methodically reading and highlighting important sections of printed materials at their workspace.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park, enjoying a walk. It is a sunny day.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a kitchen supply store evaluating chef's knives, testing the weight and balance of at least one knife and comparing prices, suggesting they are considering purchasing a chef's knife.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best chef knives quality reviews maintenance value for money\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"chef's knife\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a book in a comfortable home setting with a hot beverage and pet companion.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing at a trailhead with a map on a wooden signboard in front of them. A companion is saying: 'Which trail should we take? Do you know how long these hikes are?'.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"hiking trails near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bar, socializing with a group of friends.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport, checking flight details on a departure board. The user has a flight booked for 3:00 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Flight XY123 status and gate information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaged in sketching on a garden bench, surrounded by art supplies.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a caf\u00e9 with friends discussing a recent soccer match between Barcelona and Real Madrid, with particular focus on a goal scored by Lewandowski.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Robert Lewandowski Barcelona career statistics achievements\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person shows a person holding a smartphone with a messaging app open, standing inside an elevator. The elevator doors are closed.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a business meeting about quarterly sales performance, taking notes while listening to a presenter discuss positive results.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for baby monitors in a store and examining a high-end model priced at $299.99 with advanced features like HD video, temperature monitoring, and breathing tracking.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"HD video baby monitor with temperature and breathing tracking\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"high-end baby monitor parent reviews reliability\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"pediatrician recommended baby monitor features necessity of breathing monitors\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining an unfamiliar purple flowering plant while hiking on a forest trail, and appears to be reaching out to touch it.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this purple flowering plant\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Digitalis purpurea toxicity\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is comparing different types of sunscreens (chemical vs. mineral) with different SPF ratings. Their arm shows evidence of a recent sunburn.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"chemical versus mineral sunscreen for sensitive skin SPF recommendations high UV index\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing in front of a bathroom mirror, looking at their reflection. There's a toothbrush and toothpaste on the sink counter, but they haven't started brushing yet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a peaceful moment alone on a beach at sunset, collecting seashells and watching the waves.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mexican restaurant, browsing a menu with options such as tacos, burritos, and guacamole.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for tacos, burritos, and guacamole\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for tacos, burritos, and guacamole\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a leisurely hike on a well-marked forest trail, pausing occasionally to appreciate the natural surroundings.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a peaceful moment watching a sunset over a lake from a park bench.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a library, discussing a book with a classmate that could be helpful for a project.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mediterranean restaurant, scanning a menu featuring Greek salad, hummus with pita bread, and grilled salmon.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health benefits of Greek salad, hummus with pita bread, and grilled salmon\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights and heart-health benefits of Greek salad, hummus, and grilled salmon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe image shows the user is holding a smartphone with both hands, and the screen displays a photo of a baby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is grating cheese over a bowl of pasta, likely as a finishing touch before serving.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a colleague are looking for a recently opened coffee shop in a downtown area, but they're unsure of its exact location.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"new coffee shop opened recently downtown [location based on coordinates]\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"[current coordinates]\", \"destination\": \"Artisan Brew coffee shop\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking at a stove, stirring a pot with a wooden spoon. Steam is rising, indicating the food is being cooked.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in gardening activities in a community garden, watering plants with proper tools available nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a woodworking project in their garage workshop, specifically sanding a small wooden table. They are wearing appropriate safety equipment and have their tools organized nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working at a desk, focused on coding, surrounded by papers and a computer monitor displaying code.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at their desk where a stack of reports is visible next to an open laptop. The laptop screen shows a partially completed financial analysis spreadsheet. A calculator and several highlighters are neatly arranged nearby..\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friend are at a farmers market and have discovered a flyer for a food festival at Riverside Park happening today. They're considering visiting after finishing their shopping.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"farmers market\", \"destination\": \"Riverside Park\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a movie with friends, making comments about favorite scenes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a parking lot with several cars, including a close-up view of a black car's interior. The clear blue sky indicates that it is a sunny day.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be preparing for a yoga or workout session in their living room. They have laid out a yoga mat and are dressed in appropriate attire for exercise.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is seated in the driver's seat, driving a car. The interior of the vehicle is that of a Toyota, with a steering wheel and dashboard.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a crowded shopping mall, possibly looking to leave, and has a meeting scheduled at 6 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"meeting location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a yoga class, following an instructor's guidance, with their phone intentionally set to silent and Do Not Disturb modes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a person in front of the user, sitting on the floor next to a bright green couch. It appears to be in a living room.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a dinner with friends discussing plans for their annual hiking trip to Mount Rainier planned for the 15th of next month.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"15th of next month\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Annual hiking trip to Mount Rainier\", \"time\": \"15th of next month\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bar, socializing with a group of friends.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a cafe, looking at a menu.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"popular cafe items or dietary-specific options\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friend are viewing a poster for a local music festival happening tonight and are discussing transportation options to get there.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"music festival venue\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a casual evening stroll through a residential neighborhood, occasionally stargazing as they walk at a relaxed pace.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on a spreadsheet in an office environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a gym, standing in front of a set of free weights with a look of uncertainty.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"proper lifting techniques for beginners\"}}, {\"name\": \"vllm\", \"description\": \" Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"correct form for lifting weights\",\"image_path\":\"\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a balcony, enjoying a sunset view of the city. The mood is serene and reflective.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a gym, standing next to a rowing machine and wearing athletic clothing, indicating they are about to start exercising.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"guided rowing workout plan\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is playing with a black and white cat using a string toy in their living room. The cat appears engaged and playful.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a scenic overlook during sunset, looking at mountains with an information plaque that's difficult to read due to shadows.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"use current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying quiet reading time in a garden setting with a cup of coffee nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in gardening activities in a well-maintained garden, planting flowers with proper tools and equipment readily available.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop in Central Park, New York City. The sky is darkening with storm clouds, suggesting imminent rain.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"New York City\", \"time\": \"now\"}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for the user's current location.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a poster for an upcoming music festival with a friend. The friend expresses interest in attending the event.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"music festival dates\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Music Festival\", \"time\": \"festival dates\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"music festival ticket information and event details\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friends are playing frisbee in a park and plan to stop in 45 minutes to get food.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"45 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking in a forest and has encountered a distinctive red mushroom with white spots, which they are currently examining.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this mushroom species and determine if it's poisonous\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Amanita muscaria mushroom toxic properties\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a friend are enjoying the sunset at a beachside promenade and are interested in finding a nearby seafood restaurant.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"seafood restaurants near the beach with good ratings\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is jogging in a park and wearing a fitness tracker.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing for a board meeting scheduled for 2 PM tomorrow where they need to present a Q3 financial summary. They are currently reviewing financial reports with red annotations.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"tomorrow 2 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Board Meeting - Q3 Financial Presentation\", \"time\": \"tomorrow 2 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing in a grocery store aisle, looking at a variety of cereals.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"cereal\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"cereal nutritional information and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the kitchen, actively cooking and adjusting the seasoning of a pot of soup on the stove.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a steakhouse, browsing a menu with options such as ribeye steak, baked potato, and Caesar salad.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for ribeye steak, baked potato, and Caesar salad\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for ribeye steak, baked potato, and Caesar salad\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in their kitchen, observing a container of protein powder and a shaker bottle.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a friend are strolling near a river at dusk. There is a conversation: \"Wow, it's getting colder than I expected. Should we head back before the sun sets?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking down a staircase.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a park, reading a book on birdwatching, indicating an interest in birdwatching activities.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify birds around the user.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Northern Cardinal\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach chair, peacefully watching the sunset over the ocean.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining the contents of their refrigerator, possibly planning what to cook or looking for specific items.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a first-person perspective of someone walking a dog on a paved path. The scene appears to be outdoors, possibly in a residential area given the presence of a curb and grass along the side of the path.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a coffee shop, talking with a friend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining the contents of their refrigerator, possibly planning what to cook or eat.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at their desk organizing and sorting business cards into different categories.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a colleague are discussing ways to improve and automate a complex process in the office.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"automation tools for business processes\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"business process automation strategies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is relaxing on a sofa, watching a nature documentary about monarch butterflies.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"monarch butterflies\"}}, {\"name\": \"google_search\", \"description\": \"Search the web for similar documentaries or educational content on wildlife.\", \"parameters\": {\"query\": \"similar documentaries on wildlife\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a park and is looking for a suitable trail for a quick walk.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"best trails for a quick walk in this park.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a sectional sofa priced at $2,499. They're taking measurements and photos, suggesting serious purchase consideration.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"beige modern sectional sofa\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"sectional sofa durability comfort reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a scheduled outdoor yoga class at a park, currently following the instructor's guidance on proper form for warrior pose.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing in their kitchen with various ingredients, including flour, eggs, and sugar, on the counter. The user is likely preparing to bake or cook something.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"recipe suggestion of flour, eggs, and sugar\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"recipe suggestion of flour, eggs, and sugar\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is scanning the dessert menu at a caf\u00e9. The menue inclues sugar-free or low-sugar alternatives, including fruit-based desserts and sugar substitutes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Low-sugar or sugar-free dessert options at this caf\u00e9\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Best low-sugar dessert caf\u00e9s nearby\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Recommended sugar substitutes for low-sugar diets\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a hammock in a garden, possibly enjoying a quiet moment or taking a nap.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting at a piano in what appears to be a home living room. Their fingers are positioned on the keys, and sheet music is open on the piano stand. A metronome is visible on top of the piano, ticking steadily.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking a trail with a companion, planning to reach the summit and return before sunset. They're currently 2.5 miles from the summit with approximately 1.5 hours of hiking ahead, and need to begin their return journey by 4:30 PM to avoid incoming thunderstorms.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"1 hour 45 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a camera store looking at a DSLR camera with multiple lenses in a display case. The price tag shows $1,299 for the camera body and basic lens kit.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"DSLR camera kit with basic lens\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"DSLR camera beginner smartphone photographer transition reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a gym environment where people are exercising and personal trainers are assisting clients.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a plane flight, relaxing by looking out the window with reading material and a drink.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is boiling water on the stove for cooking or making a beverage.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"7 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and friends are preparing to watch a sports game that starts in 25 minutes, and they're currently setting up food and drinks.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"25 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a mountain viewpoint enjoying the scenery of a valley with towns below. They have a dinner reservation at 7:30 PM at La Trattoria restaurant in Millfield.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"mountain viewpoint\", \"destination\": \"La Trattoria, Millfield\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a park barbecue with friends and is cooking burgers that need to be flipped after 5 minutes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"5 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cleaning a bathroom sink using a blue scrub brush under running water from the faucet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a living room, engaging in a relaxed conversation with family members. The environment is homely and comfortable.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is considering purchasing sunscreen, possibly to protect against UV exposure.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"SPF levels and product reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Search the web for information.\", \"parameters\": {\"query\": \"SPF levels and product recommendations\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"sunscreen\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a beach, sitting on the sand and watching the waves, indicating a serene and relaxing environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user has just arrived at the Grand Hyatt Singapore for a 3-night stay. They have a meeting scheduled with clients tomorrow at 9:00 AM at the Marina Bay Financial Centre. They are currently at the reception desk preparing to check in.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"Grand Hyatt Singapore\", \"destination\": \"Marina Bay Financial Centre\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"tomorrow 9:00 AM\"}}, {\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"7:00 AM tomorrow\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking up the stairs with a handrail on the left and a white wall on the right.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is shopping for electronics and is currently looking at different gadgets.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"latest model of the gadget\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"gadget reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on a client feedback summary that needs to be ready by next Monday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Monday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare client feedback summary\", \"time\": \"before next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a meeting discussing a project timeline. The draft needs to be ready for review by next Tuesday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Tuesday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize project draft\", \"time\": \"before next Tuesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting at a dining table with a friend, with plates of food and drinks on the table. Audio information shows there is a conversation between the user and others. The friend says: 'I'm thinking about getting a new phone. Do you have any recommendations?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"popular phones\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"phone reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working from a home office. The presence of books and a whiteboard suggests they are engaged in planning or research activities.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lying on a picnic blanket in a meadow, reading a novel with soft sunlight filtering through the trees.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a shared office space with a laptop open to an email client. The conversation partner says: 'We should finalize the budget report by tomorrow afternoon.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"tomorrow afternoon\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Work on budget report\", \"time\": \"tomorrow afternoon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a beach, with a book and cooler nearby. The weather appears pleasant with other people also enjoying the beach.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is looking at a restaurant menu. GPS detects the user is near a popular dining area. The user's calendar shows no upcoming events.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"restaurant recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mediterranean restaurant, browsing a menu with options such as hummus, falafel, and grilled chicken.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for hummus, falafel, and grilled chicken\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for hummus, falafel, and grilled chicken\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user shopping in a vegetable market and looking at the vegetables.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"recipe ideas and suggest ingredients\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a hammock in their backyard, surrounded by nature.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting in a comfortable armchair in what appears to be a home library or study. They are holding an e-reader device and appear to be deeply engaged in reading. A cup of tea sits on a small table beside them.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is at a social gathering in a backyard, enjoying a barbecue with friends.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having coffee with a friend at an outdoor cafe. The friend is venting about work-related frustrations regarding overtime expectations from their boss.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a report with charts and data analysis results. A colleague suggests arranging a meeting to discuss the analysis results with the team.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Data Analysis Results Discussion\", \"start_time\": \"as soon as possible\", \"meeting_location\": \"conference room\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, browsing skincare products, and seems particularly interested in a specific brand.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"skincare product\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"skincare product reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a hiking trail entrance, preparing to go hiking. They're examining trail options on a map display. There's a weather alert for thunderstorms expected in the area after 3:00 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"today afternoon\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"hiking trail lengths and completion times at [current location]\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"hiking trail entrance\", \"destination\": \"Cedar Ridge Loop or Sunview Trail\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is cross-country skiing alone in remote terrain during a winter storm. Conditions include heavy snowfall, poor visibility, cold temperatures.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at home watching a drama movie with popcorn in a comfortable, dimly lit living room setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on the beach, indicating they might be planning to surf.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Local beach\", \"time\": \"now\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"beginner surfing tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a garden, surrounded by blooming flowers and plants.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user examining tennis rackets at a sporting goods store, focusing on a professional model priced at $189.95.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"professional tennis racket\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"professional tennis racket reviews recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is carrying a suitcase. GPS detects that the user has arrived in a new city. The agenda shows that the user has a hotel check-in at Victoria Hotel at 7 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"Victoria Hotel\"}},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Hong Kong\", \"destination\":\"Victoria Hotel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a leisurely caf\u00e9 experience in what appears to be a European city, taking in the local atmosphere while having coffee and a pastry.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the sidewalk of a road that appears to be going downhill, with an intersection ahead. There are many bushes on both sides of the road.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a digital intersection, crossing the road.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a leisurely lunch at a picnic table in a grassy area, surrounded by a few trees.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a leisurely walk through a botanical garden, appreciating the diverse plant life and occasional butterflies.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a vegan restaurant, browsing a menu with options such as quinoa salad, lentil soup, and tofu stir-fry.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for quinoa salad, lentil soup, and tofu stir-fry\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for quinoa salad, lentil soup, and tofu stir-fry\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a MacBook Air laptop priced at $1,299.99.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"MacBook Air M2 8GB RAM 256GB\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"MacBook Air M2 reviews recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a train journey, currently reading a book while enjoying the countryside views.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having dinner with friends. Someone has mentioned that The Lumineers will be performing at River Park on the 15th of next month, with tickets going on sale this Friday at 10 AM. The group seems interested in attending together.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"River Park\", \"time\": \"15th of next month\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there are any time conflicts in the user's agenda.\", \"parameters\": {\"event\": \"The Lumineers concert\", \"date\": \"15th of next month\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"The Lumineers River Park concert ticket prices\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Lumineers tickets go on sale\", \"time\": \"Friday 10 AM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user enjoying the view of a sunset from a balcony.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a bus stop, talking to a fellow commuter. Audio information shows the user is talking with a friend the the friend is asking about the next bus arrival. The friend says: 'Do you know how long until the next bus arrives?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current location'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a light stretching routine in front of a mirror, possibly as part of a morning ritual.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a craft fair, showing interest in handmade jewelry.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"handmade jewelry artist information\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"craft fair\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach and interested in visiting the lighthouse, as indicated by their focus on the map of nearby attractions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"beach\", \"destination\": \"lighthouse\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach with storm clouds approaching rapidly. Lightning can be seen in the distance over the water, but people are still swimming, seemingly unaware of the danger.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current_beach_location\", \"time\": \"now\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"lightning safety protocol beach evacuation\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking down a university hallway with a colleague discussing research collaboration. They've expressed mutual interest in collaborating on a grant proposal related to neural networks, and there's a relevant grant deadline coming up on June 15.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"add_meeting\", \"description\": \"This API allows users to make a reservation for a meeting and store the meeting information (e.g., topic, time, location, attendees) in the database.\", \"parameters\": {\"meeting_topic\": \"Neural Networks Research Collaboration for Grant Proposal\", \"start_time\": \"\", \"meeting_location\": \"meeting room\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a work brainstorming session, diagramming on a whiteboard while team members discuss process connections.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an electronics store, considering purchasing wireless headphones, possibly comparing features and prices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"wireless headphones reviews and feature comparisons\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"wireless headphones\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a picnic with friends, enjoying food and socializing in a public park.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is chatting with friends at a cafe. Audio information shows there is a conversation between the user and others. The partner says:\"I heard that AI can now write stories\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining a bicycle with a flat rear tire that shows signs of damage to both the tire and inner tube. They have a cycling meetup scheduled for tomorrow morning, suggesting this is an urgent issue that needs addressing.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Assess the damage to this bicycle tire and determine if it needs professional repair or can be fixed at home\", \"image_path\": \"\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current location\", \"destination\": \"bicycle repair shop near me open now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is exploring a Thai market and has stopped at a fruit stall where a vendor is offering durian fruit for 200 baht. The user appears interested but possibly unfamiliar with the fruit.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this fruit in the image\", \"image_path\": \"user_view.jpg\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"durian fruit\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"average price of durian in Thailand market\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having coffee with a friend who is inviting them to a housewarming party on Saturday at 6 PM at 742 Maple Street, apartment 3B.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday 6 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Housewarming party at 742 Maple Street, apt 3B\", \"time\": \"Saturday 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a botanical garden entrance, curious about the duration of a walk along the main garden path.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"botanical garden entrance\", \"destination\": \"main garden path\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden, observing rare orchids.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the orchids the user is observing.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Ghost Orchid\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a science fair, observing a booth about solar panel technology.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"solar panel technology and benefits\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"latest advancements in solar energy\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting with friends in a garden, surrounded by plants and flowers. Audio captures a conversation where someone suggests hosting a garden party next weekend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"next weekend\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for decoration ideas and catering options for a garden party.\", \"parameters\": {\"query\": \"garden party ideas and catering\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Garden party\", \"time\": \"next weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a ferry, looking at the sea. The weather is sunny, and other passengers are enjoying the view.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sengaged in hand-washing clothes outdoors. \n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is seating in a classroom, chatting with a classmate. The classmate asks: \"Hey, did you know the fireworks display this weekend? It was supposed to be spectacular! Do you know if there are any more events like this coming up?'.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"the upcoming fireworks display this weekend.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is browsing a clothing store. GPS detects the user is at a shopping mall. The agenda shows the user has a meeting in 2 hours.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"google_map\", \"description\": \"Get the route and travel time from the current location to the destination.\", \"parameters\": {\"current_location\":\"Shopping Mall\", \"destination\":\"Central Plaza\"}},{\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"Shopping Mall\", \"destination\":\"Central Plaza\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working at their desk in an office, focused on typing on their laptop with reference documents nearby and a coffee cup within reach.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a technology museum, spending time examining a quantum computing exhibit with processor models and interactive displays.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"quantum computing recent breakthroughs practical applications explained\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is setting up at a beach while dark clouds approach from the horizon. A lifeguard has raised a yellow caution flag, and a loudspeaker announcement mentions a thunderstorm warning. The user's phone has received a weather alert for a thunderstorm from 2:00 PM to 5:00 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current_beach_location\", \"time\": \"now\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current_beach_location\", \"destination\": \"nearest_indoor_shelter\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hanging clothes to dry outside, likely after completing a laundry cycle.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"3 hours\"}}, {\"name\": \"get_city_weather\", \"description\": \"Get the current weather conditions for the user's city.\", \"parameters\": {\"city\": \"user's current city\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sketching a sunset lake landscape while sitting on a park bench.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking the Pine Ridge Trail and has reached a junction with multiple path options. Trail markers are difficult to read, and there are signs of an approaching storm.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"user current location\", \"time\": \"now\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API\", \"parameters\": {\"current_location\": \"current trail junction\", \"destination\": \"Pine Ridge Trail end point\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting by a lake, fishing. The environment is calm.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying breakfast at an outdoor caf\u00e9 in Paris on a pleasant sunny morning, listening to street musicians while taking in the historic surroundings.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a park where the Annual Spring Festival is being set up for this Saturday from 10 AM to 6 PM. The event will feature live music starting at noon, local food vendors, and children's activities in the north section of the park.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday 10 AM to 6 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Annual Spring Festival at the park\", \"time\": \"Saturday 10 AM to 6 PM\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Annual Spring Festival local park details activities\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a sports equipment store, examining a pair of running shoes. The price tag shows $129.99. Several other running shoe models are visible on nearby shelves with various price points.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"running shoe model reviews long distance running\"}}, {\"name\": \"get_online_product_price\", \"description\": \"    Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a kitchen. A fruit bowl with apples and bananas is visible nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a book in a public library where silence is expected, as indicated by the 'Quiet Please' sign.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a clothing store, looking at jackets. They might be considering purchasing one.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can analyze fashion trends based on the given image.\", \"parameters\": {\"prompt\": \"Analyze the style of the jackets and suggest if they align with current fashion trends.\", \"image_path\": \"\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"jackets\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in programming work, referencing documentation while writing code.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing for a beach trip by packing a beach bag with essential items like towels and sunscreen. There's a beach umbrella nearby, and the sky outside is partly cloudy.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"Nearby Beaches\", \"time\": \"today\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is making a cup of tea, with water freshly boiled and sugar ready for sweetening. All necessary elements for preparing tea are visible and within reach.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a subway train, traveling through tunnels and looking out the window.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a break at a mountain overlook, enjoying the scenic natural landscape.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is tending to houseplants, likely watering them.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is frosting a two-layer chocolate cake with white frosting, with cake decoration supplies like sprinkles, food coloring, and candy pieces available nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a room filled with multiple individuals, all seated around a circular table, appearing to be gathered for a meeting. They are discussing novel techniques. The content of conversation is: \"Current solutions are not good. You should consider using techniques such as domain adaptation and contrastive learning to handle such research problems.\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"simplified explanation of domain adaptation and contrastive learning.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a book in a garden under a cherry tree, occasionally watching butterflies and the surrounding garden.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting and reading an open book. The book has text on both pages, and the reader's hands are holding it.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a taxi, traveling through a busy urban area. They are seated comfortably, and the driver appears to be handling the navigation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in the men's clothing section of a department store, browsing a sale rack. There isn't any indication the user is confused or in need of assistance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is washing lettuce in the sink, preparing it for a salad or other dish.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a casual conversation with a friend in a caf\u00e9. They are planning to meet again next Thursday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Meeting with friend\", \"time\": \"next Thursday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in painting a landscape artwork on canvas with appropriate supplies.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user walking in a shopping mall with a friend. Audio information shows there is a conversation between the user and others. The partner says: \"I want to buy a new smart speaker. Do you know where the best smart speaker stores are around here?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"smart speaker stores\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"smart speaker stores near me\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a live musical performance in a theater, surrounded by other audience members who are all engaged in watching the show.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing and highlighting a printed document in their home office, with reference materials organized nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the beach.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at what appears to be a family dinner, where relatives are reminiscing about shared memories and past family vacations while enjoying a meal together.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reminiscing about a past sports championship game while watching a current game with friends.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"highlights of last year's championship game\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user seems to be following a recipe, potentially for a pasta dish, given the ingredients like pasta, cheese, and basil.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook rice, with water heating on the stove and a package of rice ready on the counter.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe visual information suggests the user is sitting in a bus station with a suitcase beside them.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'Botanical Garden'\"}}, {\"name\": \"book_uber\", \"description\": \"Book a ride to a specified location.\", \"parameters\": {\"current_location\":\"user current location\", \"destination\": \"User's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking in a kitchen. The individual is standing in front of a gas stove, holding a frying pan with what appears to be minced meat or ground beef.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"tips for cooking minced meat\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing the seafood menu at a coastal restaurant, looking at various shellfish dishes such as shrimp, crab, and lobster.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Allergy-friendly seafood options at this coastal restaurant\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Allergen-friendly seafood restaurants near me\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Cross-contamination guidelines for shellfish allergies\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a busy intersection, looking around.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen preparing food, using a red-handled knife to chop green onions on a cutting board.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking on the road. There are many trees on both sides of the road, and the road seems to be going uphill.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking through a corporate hallway, passing by closed offices and observing company displays on the walls.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is watching and photographing a sunset from a beachfront balcony with photography equipment set up.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an art museum, closely observing a well-known painting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the painting in the image\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API for information about subjects.\", \"parameters\": {\"query\": \"The Starry Night Vincent van Gogh\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a gym, preparing to start their workout on a treadmill.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"safe exercise heart rate guidelines\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a work meeting reviewing project timelines with urgent tasks that need to be completed before a client presentation on Monday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete urgent project tasks\", \"time\": \"Multiple blocks before Monday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Monday 9 AM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a trailer for 'Quantum Horizon' which is opening this Friday. Someone nearby has commented on the movie, asking 'Are you planning to see it this weekend?'.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Friday evening\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user at their desk with a document titled 'Client Proposal Draft'. The conversation involves submitting the proposal by this Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"Friday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize client proposal\", \"time\": \"Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a caf\u00e9 with a friend, holding an umbrella due to the rain. They mentioned needing to get to an art gallery quickly.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"art gallery\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is playing chess with an elderly opponent in a coffee shop, engaged in a friendly game that requires strategic thinking.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is focused on a virtual meeting, participating through video conferencing software.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing the steak menu at a steakhouse, focusing on different doneness levels, from rare to well-done.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Preferred steak doneness at this steakhouse\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Safe internal temperature guidelines for steak\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Food safety concerns with different steak doneness levels\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing an unusual flowering plant in a botanical garden. There's an information plaque that's difficult to read completely, and there's expressed curiosity about the plant from nearby visitors.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this flowering plant with purple and yellow blooms\", \"image_path\": \"current view\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"rare flowering plant botanical information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a well-maintained forest trail with good visibility, surrounded by pine trees and wildlife in favorable weather conditions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is jogging in a park, wearing running shoes, and holding a water bottle. GPS information suggests the user is jogging in a park.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a rare Himalayan Blue Poppy at a botanical garden. A nearby visitor has expressed interest in growing this unusual plant at home.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"how to grow Himalayan Blue Poppy Meconopsis at home care requirements\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is browsing through a digital menu on a tablet at a restaurant.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"chef specials or trending items in this restaurant.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is kneading dough on a floured countertop, likely preparing to bake or make bread.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport lounge, discussing meal options with a fellow traveler before their flight.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"best restaurants in airport\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at the entrance of a national park, interested in visiting the waterfall as they examine a trail map.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"national park entrance\", \"destination\": \"waterfall\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a guided meditation session in a calm, dimly lit room with other practitioners and an instructor providing guidance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking down stairs with handrails and windows nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in artistic activity, sketching a scene in a park with children playing near an oak tree. They have organized their colored pencils nearby for their drawing session.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a sushi bar, browsing a menu with options such as nigiri, sashimi, and tempura.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for nigiri, sashimi, and tempura\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for nigiri, sashimi, and tempura\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is collaborating with a team on weekly goals. Audio indicates a deadline for completing a draft by Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this week\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Review draft progress\", \"time\": \"by this week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking alone on a forest trail during daytime, enjoying nature in a peaceful environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is cycling along a scenic path, enjoying the movement and the natural surroundings.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a gym, actively walking on a treadmill at a stable pace.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a washing machine in a department store, taking photos and notes of a specific model. A store employee is informing them about delivery options, stating that delivery would be available starting next Tuesday if purchased today.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Tuesday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Washing Machine Delivery (4-hour window)\", \"time\": \"next Tuesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe person is sitting at a caf\u00e9 with a friend, looking at travel brochures on the table. The conversation is: \"I\u2019m thinking about a quick getaway to Jeju Island. We could check out the beaches and hike Hallasan Mountain. What do you think?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Jeju Island\", \"time\": \"User's chosen trip days\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"User's chosen trip days\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a busy intersection with multiple bus stops in an unfamiliar city. They appear to be interested in visiting the Central Museum based on their search history, and a nearby tour guide mentioned it closes at 5 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current intersection\", \"destination\": \"Central Museum\"}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current location bus stops\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is waiting for their scheduled doctor's appointment in a medical office waiting room, passing time by reading a magazine while waiting to be called.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a yoga class where the instructor is guiding participants through a warrior pose.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is watering plants on a balcony with a small watering can.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user has been working on their research paper for several hours without taking breaks and has been sitting and working for an extended period.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be in a hospital environment, observing medical professionals performing their regular duties. There's no indication the user is a patient or requires medical assistance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a bus stop in the rain. Several other people are also waiting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"current location bus stop\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"current GPS coordinates\", \"destination\": \"user's likely destination based on routine\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is jogging on an exposed beachfront during an extreme heat warning.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"heat exhaustion and heat stroke symptoms and emergency treatment\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a bench in a tranquil garden, observing koi fish swimming in a pond surrounded by lily pads, flowering plants, and bamboo.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in an office with colleagues, standing near a whiteboard filled with diagrams and notes. Audio information captures a conversation that includes: \"We need to finalize the project timeline by tomorrow.\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"finalize the project timeline\",\"time\": \"tomorrow\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to bake a frozen pizza, with the oven preheated and serving tools (pizza cutter and plates) ready for when cooking is complete.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a hiking trail with a view of a Tesla Gigafactory. Other hikers are showing interest in the factory and speculating about Tesla's stock performance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"TSLA\", \"date\": \"current_date\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a simple picnic lunch in a park, with their meal partially consumed and other people enjoying similar activities nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user standing in a hallway. Audio information indicates the user is having a conversation with a colleague. The colleague asks: \"Hey, did you hear about the upcoming concert of that popular band happening next week? Any idea where it's taking place?\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"the upcoming concert of that popular band happening next week.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach, with a peaceful ocean view.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a break on a park bench, possibly after a workout, as indicated by the fitness tracker.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a social gathering in a backyard, enjoying a barbecue with friends.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attempting to fix a flat tire on their mountain bike while on a trail. They have some tools but appear to be in the process of removing or repairing the tire.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"how to repair mountain bike flat tire on trail step by step\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a living room, sitting on a couch with a pet dog.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a trail in a natural setting. The environment is peaceful.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is sitting in a living room, massaging their temples with their fingertips. The user appears to be experiencing a headache or some stress.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"headache remedies and relaxation techniques\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working at a desk with multiple screens displaying stock charts and financial news. A colleague has asked about the stock price of ABC Corp, which is on the user's watchlist.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"ABC\", \"date\": \"today\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is transferring freshly baked chocolate chip cookies from a baking sheet to a cooling rack in a well-organized kitchen.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nTwo friends are chatting at a dinner table at home, with a laptop open to travel websites. They\u2019re interested in a cultural experience (Broadway) and also outdoor fun (Central Park), talking about a plan to visit New York. They want to catch a Broadway show and stroll through Central Park next week.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"New York\", \"time\": \"next week\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a botanical garden examining an unusual flowering plant with purple blooms. They're trying to read an information plaque that's partially obscured.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"What is this purple flowering plant?\", \"image_path\": \"current_visual_feed\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API.\", \"parameters\": {\"query\": \"Passiflora incarnata purple passionflower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is seasoning a steak while cooking it in a pan.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe visual information indicates that the user is sitting in front of a laptop with an open email client. The conversation includes the statement, \"I think we should finalize the project plan by next Monday. Maybe we can have a meeting in the afternoon that day?\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a bench in a park that has fitness facilities, observing others exercising but not participating in exercise themselves.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is socializing with friends in a living room with business news playing on TV. The conversation has turned to Tesla's new product announcement by Elon Musk, and one friend has specifically mentioned interest in Tesla's stock performance today.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"TSLA\", \"date\": \"2025-04-25\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bookstore, discussing a new bestseller with a friend. They are interested in finding the latest book by a popular author.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"latest bestseller by that author\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual input indicates the user is in a hallway and an elevator is visible nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in the kitchen with basic baking ingredients like flour, eggs, and milk, possibly planning to bake something.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"basic pancake recipe with flour, milk, eggs\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is pouring batter into a baking tray, preparing to bake.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user has been working at their computer for an extended period, showing signs of eye strain and poor posture.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"20-20-20 rule for eye strain prevention\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"ergonomics and eye health for computer users\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden, sketching flowers, suggesting an interest in art and botany.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify flowers in the sketch.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Hibiscus flower\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking into what appears to be a Western restaurant.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"Popular menu options at this restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outdoors, enjoying the view of a lake. The visual information suggest a peaceful and relaxing environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a home gym, about to use a stationary bike for cardiovascular exercise.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a board game night with friends in a comfortable home setting. The atmosphere is relaxed and social, with friendly banter occurring between players.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is checking the sushi menu at a Japanese restaurant, focusing on sushi rolls and sashimi options.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Sushi rolls and sashimi options at this restaurant\"}},{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Top-rated fresh seafood suppliers near this Japanese restaurant\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Safety guidelines for consuming raw fish\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user has received an invitation to a neighbor's child's birthday party on Saturday from 3-6 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday, May 15th, 3-6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a friend's house, sitting at a dining table with a group of people. Audio captures a conversation where someone suggests planning a weekend getaway to the mountains.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"mountains\", \"time\":\"this weekend\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for accommodation options and activities in the mountain area.\", \"parameters\": {\"query\":\"accommodation options and activities in mountain area\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for dog food, likely considering the best option for their pet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"dog food\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"dog food nutritional info and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a park, sitting on a bench and observing the surroundings, which include children playing, people walking dogs, and joggers passing by.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on their laptop in a shared office space, surrounded by reminders on sticky notes. They seem focused on their task.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a dinner gathering with friends, sharing amusing memories about past experiences.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is relaxing in a hammock, reading a book in the sunlight.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing breakfast toast, spreading butter on one slice while waiting for another slice to finish toasting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a botanical garden, taking in the sights of nature. The environment is serene and calming.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is standing in front of a mirror, trying on a new outfit.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"analyze the outfit and provide feedback on how it looks.\",\"image_path\":\"\"}},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"the new outfit the user is wearing.'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at their desk, possibly preparing to take vitamins or supplements.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"benefits of vitamins\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaging in a leisurely baking activity, decorating cupcakes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"new cupcake decorating techniques or recipes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a walk with a friend who is sharing personal news about their sister planning to move abroad.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is doing a stretching routine, possibly as part of a morning exercise ritual.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is slicing a loaf of bread on a wooden cutting board with a serrated knife\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing by the stove, checking the temperature of a frying pan, likely preparing to cook.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a train station, examining a map of train routes, possibly trying to determine the best route to their destination.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"train station\", \"destination\": \"[user's destination]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is shopping for a new smartphone. They are comparing different brands and models, as indicated by their prolonged focus on the price tags and specifications displayed on the shelf.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smartphone\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"smartphone reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a forest trail, observing nature around them. The weather appears to be pleasant with sunshine filtering through the tree canopy.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friend are in what appears to be a historical district, discussing local landmarks and trying to identify a building associated with a famous author.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Famous authors who lived in [current location]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a physical book in a cozy reading space at home, with a cup of tea nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting in a park under a tree, drawing in a sketchbook.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in an aerobic dance class, preparing to engage in a high-energy workout session.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is standing in front of a bookshelf in a library and is picking up a book titled 'Art of War.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"book named 'Art of War.'\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"find reviews and similar book recommendations for the book 'Art of War.'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing outside a hotel in rainy weather, checking their watch frequently. There's a taxi stand but no taxis are available. Many people are waiting under the awning. The user has a flight to Chicago at 2:45 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's hotel location\", \"destination\": \"airport Terminal B\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"user's hotel location\", \"destination\": \"airport Terminal B\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a coffee shop, enjoying a conversation with a friend. The atmosphere is lively but relaxed, with no indication of urgency or need for assistance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears relaxed, with no evident urgency or upcoming engagements based on GPS location data and agenda. Health data indicates a calm, resting heart rate. No specific tasks or deadlines are detected.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing on a beach, looking out at the ocean. There are people swimming and playing in the water.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and a friend are sitting on a park bench, enjoying a peaceful view of the pond and discussing finding a nearby caf\u00e9 for coffee.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"caf\\u00e9s near the park with good reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user ran for one hour on the school playground this evening.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"ran for one hour on the school playground this evening\",\"time\": \"this evening\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a spa, sitting in a lounge chair with a towel wrapped around their head.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a chess match in a park setting, carefully considering strategic moves against an opponent.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a rooftop patio with friends, enjoying the city skyline. Audio captures a conversation where a friend suggests planning a rooftop party for next Friday night.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"next Friday night\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Friday night\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Rooftop party\", \"time\": \"next Friday night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a pottery studio, seated at a pottery wheel. Their hands are covered in clay as they carefully shape a small bowl on the spinning wheel. Various pottery tools are arranged neatly on a nearby table, and several finished pieces in different stages of drying can be seen on shelves nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook, potentially something involving eggs, with a pan ready on the stove.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a shopping district and is considering walking to a theater with their friend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"shopping district\", \"destination\": \"theater\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cooking pancakes on a griddle and preparing to serve them on a plate. The process appears smooth and controlled.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a scenic overlook with a view of a city skyline. Nearby tourists are discussing company headquarters, including Apple, and expressing interest in stock performance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"AAPL\", \"date\": \"current_date\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to brush their teeth in their bathroom, with dental hygiene products laid out on the sink.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is washing fresh berries at the kitchen sink, with evidence that they're systematically cleaning different types of fruits, likely in preparation for consumption or a recipe.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a coffee shop, writing in a notebook while enjoying a cup of coffee.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a tech store, looking at a smartwatch priced at $299.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"smartwatch\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"smartwatch reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a coffee shop having a casual conversation with a friend about movies. Audio information indicates the user is having a conversation with others. The friend is asking about the latest Marvel movie: \"Have you seen the latest Marvel movie?\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"latest Marvel movie.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is discussing plans for a family dinner next Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime and return all events as a summarized string.\", \"parameters\": {\"time\": \"next Friday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Family dinner\", \"time\": \"next Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in the hobby of model airplane building, currently in the middle of assembling a new model with organized parts.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a coastal walking path, looking at islands in the distance with a lighthouse nearby. Their mobile device indicates rain is expected in about 90 minutes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"now\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"coastal path current location\", \"destination\": [\"visitor center\", \"parking lot\", \"trailhead\"]}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a break on a park bench, possibly after a workout, as indicated by the fitness tracker.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining a gaming console bundle in an electronics store. The package shows a PlayStation 5 with two controllers and a game, priced at $599.99.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"PlayStation 5 bundle with two controllers\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a patio, enjoying a cup of coffee while looking at the mountains.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a garden, watering plants.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Tips for planting and watering flowers\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a park bench, chatting with a neighbor. Audio information indicates a conversation about a new farmers' market. The neighbor says: 'Have you heard about the new farmers' market opening next weekend?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new farmers' market next weekend downtown\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a train journey, seated in a quiet compartment watching the scenery pass by.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a park bench, watching ducks in a pond on a pleasant sunny day. Other people are enjoying the park as well.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a meeting, likely discussing work-related topics with colleagues. There is no clear indication of confusion or the need for immediate assistance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a bench by a lake, enjoying the tranquility of the calm water and the setting sun.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at an Italian restaurant, browsing a menu with options such as pizza, pasta, and gelato.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and health information for pizza, pasta, and gelato\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and health information for pizza, pasta, and gelato\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing a hot sandwich using a panini press, with chips and water ready to complete their meal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is shopping in a supermarket. The user is looking at the vegetables in the mall.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"Detect the freshness of the vegetable.\",\"image_path\":\"\"}},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is sewing a black fabric patch onto a white cloth using a needle and thread. The workspace includes a desk lamp, a container with sewing supplies, and other crafting materials.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a mall with a friend, expressing interest in purchasing a new tablet. They are curious about current deals.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"tablet\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is taking a quiet moment by a mountain stream in a forested area, observing nature.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a rooftop bar with friends during sunset, and someone in the group has asked about a distinctive tall building with a spire that's visible in the city skyline.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tall building in use current location\"}}, {\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"What is the tall building with the spire in this skyline?\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"tall building in use current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a beach with friends, suggesting a beach volleyball game for the next Saturday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"beach\", \"time\": \"next Saturday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Beach volleyball game\", \"time\": \"next Saturday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a tennis court with friends who are suggesting playing tennis on Saturday morning. There are some clouds visible in the distance, and one friend is gesturing toward the sky.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time\", \"parameters\": {\"city\": \"Current Location\", \"time\": \"Saturday morning\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"Saturday morning\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in an electronics store, focusing on different tablet models.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"tablet\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"tablet reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tablet specifications and comparisons\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is doing a stretching routine, possibly as part of a morning exercise ritual.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a yoga studio, engaging in a stretching routine on a yoga mat.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a sporting goods store, considering purchasing hiking boots.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"hiking boots\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"hiking boots reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in their car, and the dashboard is displaying an engine warning light. The fuel gauge is also indicating that the car is nearly out of fuel.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"nearest gas station\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"amber engine warning light meaning and recommended actions\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is exploring a city square, capturing photos with their smartphone.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing in a hammock while reading 'The Silent Patient' novel, with refreshment nearby, indicating a peaceful leisure activity.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at the entrance of a busy conference center, holding a conference badge, suggesting they are attending a conference at 3 PM at the City Convention Center.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"City Convention Center\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is consuming a healthy meal, consisting of a salad with various vegetables, at their dining table.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a hiking trail with darkening skies and signs of approaching bad weather. Other hikers are leaving the area due to concerns about forecasted thunderstorms.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\": \"current time\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"trailhead\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a garden with friends, suggesting a dinner party for the upcoming Saturday night.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"garden\", \"time\": \"next Saturday night\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday night\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Garden dinner party\", \"time\": \"next Saturday night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in their kitchen with ingredients such as chicken, tomatoes, onions, and spices laid out.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"chicken curry recipe with ingredient measurements\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be waiting at a busy city bus stop, carrying a laptop bag. They have a meeting scheduled at 9:00 AM downtown.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"downtown\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a sporting goods store, focusing on a display of different bicycle models.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"bicycle\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"beginner bicycle reviews and recommendations\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"choosing the right bicycle for fitness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a friend's house, sitting in the living room with several others, and there is a board game on the table. Audio information captures a conversation. One friend says, 'Maybe we should try out that new escape room this weekend?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}},{\"name\": \"google_search\", \"description\": \"Search for escape room options, availability, and any special deals in the area\", \"parameters\": {\"query\":\"escape room options this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is standing at a scenic mountain viewpoint. Multiple mountain peaks are visible in the distance with distinctive shapes and features. A few clouds hang around the tallest peaks. The lighting suggests it's mid-morning with clear visibility. Conversation indicates the user is curious about which peak that tallest one is over there.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the mountain peaks visible in this view based on the location.\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Mount in current location\"}}, {\"name\": \"google_search\", \"description\": \"Tool that searches the Google API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Mount in current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying leisure time at a caf\u00e9, working on a jigsaw puzzle while having coffee in a relaxed atmosphere.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is attending a live theater performance of what appears to be Shakespeare's Hamlet, seated in the audience.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a relaxing time in the park with a friend, sharing ice cream.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is camping in what appears to be the Mojave Desert (based on GPS coordinates) at night, gazing at stars and constellations in the night sky.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify stars and constellations visible in this night sky image\", \"image_path\": \"\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Betelgeuse star Orion constellation\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a store, looking at a coffee maker. The price tag indicates it costs $150.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"coffee maker\"}},{\"name\": \"search_rednote\", \"description\": \"Search for user reviews and recommendations.\", \"parameters\": {\"query\": \"coffee maker reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a shopping mall parking lot, likely looking for transportation. They have a lunch date with a friend at 1 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"lunch location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing in a queue at a coffee shop, waiting to place an order.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a picnic table in a park, surrounded by trees and nature.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in or observing a yoga class where an instructor is actively guiding participants through poses.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen, preparing to use spices and herbs for cooking. The task appears to be straightforward.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is watching a movie in a theater.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe image shows the user is standing in front of a kitchen sink, which is divided into two basins. The individual is holding a small black object, possibly a filter or a lid, with their left hand.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a dining table with a plate of food that includes pasta, grilled chicken, and a side of salad.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Foods to stabilize blood sugar levels.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at home, reading a novel in a comfortable setting with a cup of tea nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user sitting on a bench in a park, looking pale and holding their chest.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"heart problem symptoms and first aid\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a balcony with a view of the city skyline at sunset, engaged in a casual conversation about the beautiful scenery.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an aquarium, viewing a tropical fish exhibit. A child nearby has expressed curiosity about a specific blue fish.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify the blue fish in the aquarium\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API for information about subjects.\", \"parameters\": {\"query\": \"Blue Tang fish\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user went hiking today for approximately eight hours.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"went hiking today for approximately eight hours\",\"time\": \"today\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a coffee shop with a friend. The audio captures a casual conversation about coffee habits.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking in a busy city area.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a park, surrounded by various leisure activities like jogging, dog walking, and children playing. The atmosphere is lively and relaxing.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a casual conversation with a colleague or friend in a coffee shop, discussing career updates.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a bookstore examining a fantasy novel priced at $32.99. A conversation nearby suggests it's part of a popular series.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"fantasy novel hardcover\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"fantasy novel series reviews bundle deals\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a game night with friends, playing what appears to be Monopoly, engaged in friendly competitive banter.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a coffee shop with a friend, looking at a map spread out on the table. Audio information captures a conversation between the user and the friend. The friend says, 'How about we take a road trip this weekend to explore some small towns?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"small towns\", \"time\":\"this weekend\"}},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}},{\"name\": \"google_search\", \"description\": \"Search for local attractions or events in the small towns\", \"parameters\": {\"query\":\"local attractions or events in small towns this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working on multiple monitors with coding and project management tools. A manager requests the code review to be completed by the end of the day.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"end of the day\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete code review\", \"time\": \"end of the day\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe visual information suggest that the user appears to be waiting for a bus at night.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'Park'\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in personal journaling in a quiet, comfortable setting with a cup of tea nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bookstore examining a James Patterson thriller novel. Their friend mentions mixed reviews about the book, suggesting uncertainty about whether to purchase it.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"James Patterson new thriller novel professional reviews ratings\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"James Patterson thriller novel reviews\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"James Patterson thriller novel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is playing a board game with friends, and they have a restaurant reservation they need to leave for in 20 minutes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"20 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user's friend has had too much to drink and needs to go home to rest.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination\", \"parameters\": {\"current_location\": \"Skyline Nightclub\", \"destination\": \"Friend's home address\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a gym, discussing their exercise routine with a friend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is inspecting a houseplant that shows possible signs of stress or disease with yellowing leaf edges.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying a book under a tree in a park. They have a picnic setup with snacks nearby, indicating a leisurely outing.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining premium wireless headphones in an electronics store. A nearby conversation reveals information about the product's noise cancellation feature and battery life.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"premium wireless headphones noise cancellation\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"premium wireless headphones sound quality noise cancellation travel\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a crowded bus stop, indicating a high demand for information about bus arrivals.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is gathering printed materials from an industrial printer and organizing them into folders, while a coworker has inquired about the documents.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a sports store, checking out various types of running shoes, likely with the intention of buying a pair.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best running shoes for performance and comfort\"}}, {\"name\": \"google_search\", \"description\": \"Search the web for information.\", \"parameters\": {\"query\": \"best running shoes for performance and comfort\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user at their desk with screens displaying financial data. Audio captures a phone call. A colleague discussing the need to present quarterly results to the board next Monday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Monday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare for quarterly results presentation\", \"time\": \"next Monday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at Malibu Beach which closes at 8PM, and it's currently 7:35 PM. The beach is emptying as sunset approaches. The user's phone battery is critically low at 12%.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Malibu Beach\", \"destination\": \"User's accommodation\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at their desk, likely working on email correspondence with multiple documents open. There is no indication of urgency or confusion.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is staying at a hotel with check-out time at 11:00 AM tomorrow. They have a return flight scheduled for 4:30 PM tomorrow and need to arrange airport transportation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Hotel Check-out\", \"time\": \"Tomorrow, 11:00 AM\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Hotel\", \"destination\": \"Airport\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a shopping mall entrance with a friend, holding several shopping bags. They mention the inconvenience of carrying them home by bus.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user current location\", \"destination\": \"home\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach, reading a novel and enjoying the peaceful scenery.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user has been sitting in front of the computer in the office for an extended period.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"recommendations on how long to sit before resting, the duration of rest needed, suggested exercises, and what physiological indicators are considered abnormal.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is walking along a well-maintained hiking trail through a forest. The path ahead is clear and well-marked with trail signs.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a family birthday celebration where relatives are sharing nostalgic stories and engaging in good-natured teasing, creating a warm, humorous atmosphere.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a grocery store comparing different brands of olive oil. Their shopping list confirms they intend to purchase olive oil.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"olive oil brands\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best olive oil brands reviews quality comparison\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a bar, engaging in conversation with the bartender.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaged in a friendly conversation with friends at a caf\u00e9.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing a document with dense legal text. There are no visible annotations or highlights.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"explanation of key legal terms.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows a person's hands holding a small black bird, possibly a chick, on a wooden surface. The setting appears to be outdoors, possibly in a rural or semi-rural area.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is making toast with butter and jam, a simple breakfast preparation. They have multiple slices ready and have already opened the jam jar in preparation for the next step.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a caf\u00e9, sipping coffee, and reading a newspaper.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a workstation with two computer monitors displaying code editors.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing to cook pasta, following a recipe from a cookbook with ingredients already gathered on the counter.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user considering purchasing chips in a grocery store.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"diet recommendations for hypertension management\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"low-sodium snack alternatives for hypertension\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is working on a computer, typing on a keyboard in an office.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is researching technical specifications in a corporate library or resource center, consulting printed materials while taking notes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking on a remote mountain trail and has suffered a fall resulting in a leg injury. They are 3.5 miles from the trailhead in a somewhat isolated location.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"first aid for cuts and scrapes while hiking in remote areas\"}}, {\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is participating in a book club discussion where members are sharing their literary analysis and personal impressions of a book they've read.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is leading a presentation or brainstorming session in a conference room, drawing on a whiteboard while colleagues observe and provide positive feedback.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is visiting an art gallery and contemplating an abstract painting, surrounded by the quiet atmosphere typical of art museums.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a restaurant, looking at a menu with various food options such as pasta, steak, and salad.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \" calorie counts and heating information of pasta, steak, and salad.\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related information about pasta, steak, and salad.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bus stop near a business center, carrying a portfolio, and has an interview at 11:00 AM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"current_location\", \"destination\": \"business center\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking and has stopped to check a trail map at a junction.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"hiking trails information for current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in an art gallery, observing a painting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is eating a pasta meal with a side salad at a dining table, appearing to enjoy their food in a relaxed setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at pastries in a bakery. The user is likely deciding which pastry to purchase.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a museum, viewing what appears to be a Kandinsky painting from the Bauhaus period, as mentioned by someone nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Wassily Kandinsky Bauhaus period paintings and significance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting with friends in a park, surrounded by picnic items. Audio captures a conversation where a friend suggests organizing a movie night next Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Friday\"}}, {\"name\": \"google_search\", \"description\": \"Search for popular movie options or themes.\", \"parameters\": {\"query\":\"popular movie options for movie night\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a car rental counter, deciding which vehicle to rent for their trip. They might be considering factors like price, size, and features.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"car rental prices at [current location]\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user and their friends are enjoying a view from a rooftop bar and are curious about the distance to a nearby music festival.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"rooftop bar\", \"destination\": \"music festival\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in focused software development work in an open office environment, writing code while referencing handwritten notes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows that the user is in a grocery store, holding a carton of milk while looking at a shopping list on their phone.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"lactose-free milk\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a concert venue late at night after attending the Summer Music Festival. A friend is asking about transportation back to their hotel, which is 5.3 miles away at the Bayview Resort.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get directions and estimated time to a destination.\", \"parameters\": {\"origin\": \"current location\", \"destination\": \"Bayview Resort\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber ride from the current location to the destination.\", \"parameters\": {\"current_location\": \"Summer Music Festival venue\", \"destination\": \"Bayview Resort\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is shopping in a grocery store, with lots of vegetables and eggs in front of him.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"vegetables\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"quick and easy recipes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a conference room with colleagues, viewing a presentation titled 'Annual Sales Strategy'. The conversation involves finalizing the strategy by next Wednesday for a board meeting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Wednesday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Prepare for board meeting\", \"time\": \"next Wednesday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is working.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having dinner with what appears to be their parents and another family member, who are reminiscing about the user's childhood eating habits and subsequent lifestyle changes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a mountain lodge, enjoying a warm beverage by the fireplace, creating a cozy and relaxing atmosphere.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing a cheese board with different types of cheese, grapes, and has opened a bottle of red wine to breathe.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is working in a coworking space, focusing on their laptop amidst papers and coffee.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a park bench, focused on setting up a digital camera.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying an evening campfire at a campsite, roasting marshmallows as the sun sets in a forest setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a park with friends playing frisbee. Audio captures a conversation where a friend suggests organizing a picnic next Saturday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"park\", \"time\": \"next Saturday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a city square with historic buildings and is interested in seeing the cathedral.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": {}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"city square\", \"destination\": \"cathedral\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a conference room, sitting at a table with a laptop and a notebook open.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Chinese restaurant, browsing a menu with options like steamed dumplings, vegetable stir-fry, and hot and sour soup.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"fat content in steamed dumplings, vegetable stir-fry, and hot and sour soup\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"tips for choosing low-fat options at a Chinese restaurant\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lounging on a sofa with a blanket, watching TV. \n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting in a waiting room with a few other people, some reading magazines, others using their phones.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows The user is sitting on a park bench, holding their chest. The sound of heavy breathing and faint traffic noise is heard. The user appears to be experiencing discomfort or pain in their chest while sitting outdoors.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"chest pain emergency steps.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is looking in the mirror while wearing summer clothes, such as short sleeves and shorts.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a large office building and has a meeting scheduled at 10 AM at the Downtown Office. It appears the user is preparing to head to the meeting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\": \"user's current location\", \"destination\": \"Downtown Office\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing dough for cookies, using a rolling pin to flatten it before cutting shapes with cookie cutters.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a deserted bus stop with no visible schedule information on the digital display.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\": \"user current location\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user working on financial documents. Audio indicates a deadline for the financial report by tomorrow.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"tomorrow\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize financial report\", \"time\": \"tomorrow's 5 p.m.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is browsing gold necklaces in a jewelry store, taking their time to view the different options displayed in the glass case. A sales associate is present but giving the user space to browse.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing on a beach at sunset, enjoying the natural scenery in a peaceful environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is packing a suitcase with spring or autumn clothes like light sweaters and trousers. The agenda shows that the user is departing for Japan.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Japan\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual data indicates user stands under a glass-paneled bus shelter, seems looking at the bus stop sign.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"check_bus_schedule\", \"description\": \"Check real-time bus schedules for a specific route.\", \"parameters\": {\"bus_stop\": \"user current location\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"},{\"name\": \"book_uber\", \"description\": \"Book a ride to a specified location.\", \"parameters\": {\"current_location\":\"user current location\", \"destination\": \"User's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user appears to be recovering from a minor knee injury. The user may recently completed an intensive workout.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"advice on managing minor knee injuries.\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\":{\"query\":\"advice on managing minor knee injuries.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is waiting in line for a food truck.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is lying on a blanket in a park, gazing at the clouds, suggesting a moment of relaxation and reflection.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen, using an electric mixer to blend ingredients in a bowl.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is walking in the park and talking to a friend. Audio information shows there is a conversation between the user and the friend. The friend says: 'Did you hear about the big soccer game this weekend?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"big soccer game, including its showtimes or ticket price\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a hobby shop examining a high-end drone kit with a controller and accessories.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"high-end drone kit with controller\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"drone kit reviews specifications flight time camera quality\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is jogging in a park. The environment is serene with green trees and a clear sky, suggesting a pleasant day for outdoor exercise.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a public library and is seeking recommendations for a good mystery novel.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"top-rated mystery novels\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"mystery novels reviews and recommendations\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in a kitchen preparing to cook with fresh vegetables, a cutting board, and a pot on the stove.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"vegetable stir-fry recipe with fresh vegetables\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is examining an unusual flowering plant with purple blooms in what seems to be a botanical garden or park setting.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this flowering plant with purple flowers\", \"image_path\": \"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Passionflower Passiflora species characteristics cultivation uses\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is watching a sports game with friends in a living room. Someone has suggested going to a new Italian restaurant to celebrate John's birthday next Saturday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday evening\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"new Italian restaurant reservation information\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is charging their electric vehicle at a public charging station.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"2 hours\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is preparing a presentation on team performance metrics due by the end of the week.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"end of the week\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete performance metrics presentation\", \"time\": \"by the end of the week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is multitasking, managing several project documents and has a deadline to send an updated project plan by noon.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Finalize and send project plan\", \"time\": \"noon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a specialty food store looking at an expensive bottle of imported Italian olive oil called 'Olio Supremo' priced at $45.99.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Olio Supremo olive oil expert reviews price comparison alternatives\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Olio Supremo olive oil reviews\"}}, {\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Olio Supremo olive oil\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reading a news article about tech stocks tumbling due to inflation concerns, with specific mentions of Apple (AAPL) and Microsoft (MSFT).\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"AAPL\", \"date\": \"2025-04-25\"}}, {\"name\": \"query_stock\", \"description\": \"This API queries the stock price of a given stock code and date.\", \"parameters\": {\"stock_code\": \"MSFT\", \"date\": \"2025-04-25\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a beach with friends, sitting under a beach umbrella. Audio captures a conversation. A friend says, 'Let's plan a bonfire night here next Saturday!'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"beach\", \"time\":\"next Saturday\"}},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next Saturday\"}},{\"name\": \"google_search\", \"description\": \"Search for information on beach bonfire regulations and permits\", \"parameters\": {\"query\":\"beach bonfire regulations and permits\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the person is conversing with a colleague in an open-plan office, near a window that looks out over a cityscape. There is a conversation: \"I was thinking of flying to Sydney this Friday. Maybe we can see the Opera House and go to Bondi Beach.\".\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Sydney\", \"time\": \"this Friday\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows that the user is shopping for running shoes, examining the price of a specific pair.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the current price of a product from online retailers.\", \"parameters\": {\"product_name\": \"running shoes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is sitting on a couch with a tablet, browsing a travel website.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Popular tourist destinations and tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a historical museum, observing an exhibit labeled 'Ancient Egypt Artifacts.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Ancient Egyptian artifacts and cultural significance\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"historical context and significance of Ancient Egyptian artifacts\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is viewing a computer screen with a complex spreadsheet open, filled with numerical data.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting at a table with friends, sharing a meal.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in a diner, browsing a breakfast menu with options such as pancakes, scrambled eggs, and bacon.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"calorie counts and heating information for pancakes, scrambled eggs, and bacon\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"health-related insights, calorie counts, and heating information for pancakes, scrambled eggs, and bacon\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a doctor's office during a medical appointment, receiving feedback about improved blood pressure readings following a medication adjustment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a camping trip, inside a tent, enjoying a natural setting with no immediate indicators of assistance needs.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is relaxing in a hammock in their backyard, surrounded by plants and a small water fountain.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nUser appears to be waiting for a bus while actively using their phone, possibly checking for updates.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is in the kitchen, with various fresh fruits on the counter. The user appears to be preparing to make a fruit salad or snack.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at an airport terminal where their flight UA789 to Chicago has been delayed by 2 hours due to weather conditions.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"alternative flights to Chicago O'Hare today\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"3:45 PM to 6:00 PM today\"}}, {\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"current terminal gate\", \"destination\": \"airport lounges and restaurants\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is reviewing a physical document with handwritten notes at their desk.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing in front of a bus station.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a beach with friends, sitting under a beach umbrella. Audio captures a conversation. A friend says, 'Let's plan a bonfire night here next Saturday!'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"beach\", \"time\": \"next Saturday\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Saturday\"}}, {\"name\": \"google_search\", \"description\": \"Search for information on beach bonfire regulations and permits\", \"parameters\": {\"query\": \"beach bonfire regulations and permits\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Bonfire night at the beach\", \"time\": \"next Saturday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a resturant, looking at a brunch menu featuring egg-based dishes, such as omelets and eggs Benedict.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Low-cholesterol brunch options at this restaurant\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Heart-healthy brunch tips\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \" Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"Recommended daily cholesterol intake and egg consumption guidelines\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on the sofa and holding his stomach, appears to be experiencing some stomach discomfort.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"digestive issues\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting on a bench overlooking a beach at sunset.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a zoo, observing tigers in their enclosure.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Tigers habitat and conservation\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"tiger conservation efforts and their importance in the ecosystem.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a friend's house, sitting in the backyard with a group of people. Audio captures a conversation where someone suggests organizing a barbecue this weekend.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"current location\", \"time\":\"this weekend\"}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}}, {\"name\": \"google_search\", \"description\": \"Search for barbecue recipes and tips.\", \"parameters\": {\"query\":\"barbecue recipes and tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is sitting by a pond, feeding ducks.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is working on a 1000-piece jigsaw puzzle of a mountain landscape at a desk in what seems to be their home office. They have organized pieces by color and completed the border.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is taking a walk in the park while wearing a fitness tracker. It is a sunny day, and the park is relatively busy.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is receiving professional physical therapy treatment with specific instructions from their therapist for shoulder rehabilitation exercises.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a workout session at the gym, actively lifting weights and referring to a workout plan on a tablet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": medium\n  \"Proactive score\": 3\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"weightlifting tips\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in concentrated data analysis work at their desk, comparing information between digital spreadsheets and printed materials.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a bookstore looking at a flyer for a book signing by author J.K. Morgan for the novel 'Midnight Chronicles' this Thursday at 6 PM. A bookstore employee mentioned that it will be a popular event with a big turnout, suggesting arriving early.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Thursday 5 PM to 8 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is conversing with a partner on the road. Audio information shows there is a conversation between the user and others. The partner says \"Hi, how about organizing a team-building hike this weekend? We haven't had a team-building event in a long time.\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\": \"this weekend\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is peeling potatoes, a repetitive and simple task, with peeled potatoes and a pot of water ready for further cooking.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is in a conference room with colleagues, viewing a presentation titled 'Quarterly Financial Report'. Conversation content: 'We need to prepare for the next meeting with the investors scheduled for next week.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"next week\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Investor meeting\", \"time\": \"next week\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is shopping in a supermarket and is standing in front of the olive oil section, where the price is displayed as $150.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"olive oil\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"product selection tips for olive oil\"}},{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\":\"basic knowledge for olive oil\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at home folding and organizing laundry, methodically sorting different clothing items into neat piles.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is outside a large shopping mall, looking at a directory board. They are unsure about the location of the electronics store.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_map\", \"description\": \"Get the route and distance from the current location to the destination using Google Maps API.\", \"parameters\": {\"current_location\": \"shopping mall entrance\", \"destination\": \"electronics store\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at a piano with complex sheet music displayed on the stand. Their recent search and viewing history suggests they are a beginner learning to play piano and read music.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"Visual Large Language Model (VLM) that can answer the user's questions based on the given image.\", \"parameters\": {\"prompt\": \"Identify this sheet music piece and assess its difficulty level for piano players\", \"image_path\": \"\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\": \"Moonlight Sonata simplified version for beginners piano tutorial\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests that the user is in a gym, standing in front of a treadmill.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\":\"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"identify the equipment they currently use.\",\"image_path\":\"\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"suitable fitness tips based on the user's fitness level.\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"Tips for using this equipment in the gym.\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is having a relaxing picnic in a public park, reading a book under a tree while observing the casual activities of others in the park.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is standing at a bus stop, looking at the bus station.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": \"None\"}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": \"None\"}, {\"name\": \"check_bus_schedule\", \"description\": \"Check the bus schedule for a specific bus stop.\", \"parameters\": {\"bus_stop\":\"'current_location'\"}}, {\"name\": \"book_uber\", \"description\": \"Book an Uber from the current location to the destination.\", \"parameters\": {\"current_location\":\"current_location\", \"destination\":\"user's destination\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is slicing bread, a simple kitchen task, using a bread knife to make even slices.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is cracking eggs into a bowl, with some shells visible on the counter.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an electronics store, considering purchasing a gaming laptop. A conversation suggests they are interested in its gaming performance.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"gaming laptop\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"gaming laptop reviews and performance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe image shows the user engaged in gardening indoors. The user is wearing black gloves and appears to be tending to a plant in a terracotta pot.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in an elevator where other passengers are making small talk about the weather forecast.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user.\", \"parameters\": {}},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"\", \"time\": \"\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user in an office cubicle with an email thread about 'Team Project Review'. The conversation involves completing the project review by Friday.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"Friday\"}},{\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Complete project review\", \"time\": \"Friday\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is enjoying leisure time at a coffee shop, reading a book while having coffee and a pastry in a comfortable, ambient environment.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is hiking up a steep mountain trail at high elevation (8,500 feet) in hot weather (85\u00b0F). Their labored breathing is audible, and they appear to be exerting significant physical effort.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"high altitude hiking safety and symptoms of altitude sickness\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is at a Mexican restaurant, browsing a menu with options like chicken fajitas, shrimp tacos, and a black bean bowl.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"protein content in chicken fajitas, shrimp tacos, and black bean bowls\"}}, {\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"tips for balancing macros in a high-protein diet\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVision information suggests the person is engaging in a conversation with a colleague in an office. The user is talking to a partner. The content of conversation is: \"Hi, how about going to Hong Kong this weekend? I want to go to the Disneyland and Victoria Harbour.\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Hong Kong\", \"time\": \"this weekend\"}},{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"},{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\":\"this weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is engaged in painting a landscape on a canvas positioned near a window.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is looking at their spice collection in a kitchen cabinet, possibly selecting seasonings for a dish.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is photographing a mountain landscape from a vantage point during early morning golden hour, with hiking gear nearby.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is viewing a poster for a Spring Festival happening this Saturday from 11 AM to 8 PM at a local park. The event features live music, food trucks, and family activities.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time.\", \"parameters\": {}}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"this Saturday 11 AM to 8 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is actively engaged in typing, likely drafting a document or responding to emails in their office cubicle.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is seated in a library, quietly talking to a friend. Audio information shows there is a conversation between the user and the partner. The friend says: 'I can\u2019t believe the final exam schedule just came out.'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVision information suggests the person is talking to a colleague in an office. There is a conversation. \"Hey, how about visiting Singapore next weekend? I'm really excited to see Sentosa and Gardens by the Bay.\"\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"Singapore\", \"time\": \"next weekend\"}}, {\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next weekend\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is inspecting various smartphones at an electronics store, specifically focused on two brands, labeled Model X at $899 and Model Y at $799.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay\", \"parameters\": {\"product_name\":\"smartphone models\"}},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"feature comparison of Model X and Model Y smartphones\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is on a long-distance bus ride, viewing the countryside scenery.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song or podcast from the user's library.\", \"parameters\": {}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is reading a book in a public library.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user expresses a desire to improve their diet.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"},{\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\":\"healthy recipes for patients with high cholesterol\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a shopping mall, surrounded by various clothing and accessory stores. The environment is lively with announcements about ongoing sales.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a classic car show, looking at what appears to be a 1960s Cadillac Eldorado, as mentioned in nearby conversation.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"1960s Cadillac Eldorado features history significance\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a casual conversation with a friend at a coffee shop. The user is discussing feeling tired despite adequate sleep.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"tips for improving energy levels and sleep quality\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a gym, lifting weights.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n [{\"name\": \"vllm\", \"description\": \"\", \"parameters\":{\"prompt\": \"identify the equipment they currently use.\",\"image_path\":\"\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\":\"guidance on properly using the current equipment.\"}}, {\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"guidance on properly using the current equipment.\"}},{\"name\": \"get_health_data\", \"description\": \"Get health data from the user's smart device.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in organizing and potentially reclassifying physical files in an office filing system.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is cooking pancakes on a griddle, flipping some that are currently cooking while a plate of finished pancakes sits nearby. A bowl of remaining batter is available to make more.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 2\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates the user is participating in a group pilates class and is currently on a mat, ready to start the session.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"play_music\", \"description\": \"Play a song from the user's music library.\", \"parameters\": \"None\"}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing by a hotel pool, casually reading a magazine about local attractions while enjoying a beverage.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is at a library looking at a poster for a free financial planning for retirement workshop happening next Tuesday at 6 PM.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"next Tuesday 6 PM\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Financial Planning for Retirement Workshop\", \"time\": \"next Tuesday 6 PM\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information indicates that the user is sitting on a balcony, enjoying a cup of coffee with a view of the garden below.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is in a grocery store examining an expensive bottle of imported Italian extra virgin olive oil priced at $19.99.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_online_product_price\", \"description\": \"Get the price of a product from an online store such as Amazon or eBay.\", \"parameters\": {\"product_name\": \"Italian extra virgin olive oil cold-pressed\"}}, {\"name\": \"search_rednote\", \"description\": \"A platform where people share tips on travel, fitness, cooking, and more. You can use it to search for relevant strategies there.\", \"parameters\": {\"query\": \"best quality extra virgin olive oil comparison\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information shows the user is seated in a coffee shop talking to a friend. Audio information shows there is a conversation between the user and the friend. The friend says: 'Have you watched the new superhero movie that just came out?'\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"google_search\", \"description\": \"Performs a Google search for the given query, retrieves the top search result URLs and description from the page.\", \"parameters\": {\"query\":\"new superhero movie showtimes and reviews\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the user is in a meeting focused on project timelines. Audio indicates a discussion about meeting quarterly deadlines.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"get_current_datetime\", \"description\": \"Get the current date and time\", \"parameters\": \"None\"}, {\"name\": \"check_agenda_time_conflict\", \"description\": \"Check if there is a time conflict in the user's agenda for a given datetime.\", \"parameters\": {\"time\": \"end of quarter\"}}, {\"name\": \"add_to_agenda\", \"description\": \"Add an event to the user's agenda.\", \"parameters\": {\"event\": \"Project phase reminders\", \"time\": \"before end of quarter\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nVisual information suggests the person is packing lightweight hiking gear like trekking pants, boots, and a windbreaker. The agenda indicates that the user is departing for New Zealand.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_current_gps_coordinates\", \"description\": \"Get the current GPS coordinates of the user\", \"parameters\": \"None\"},{\"name\": \"get_city_weather\", \"description\": \"Get the weather for a specified city at a given time.\", \"parameters\": {\"city\": \"New Zealand\", \"time\":\"now\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is relaxing at a lakeside, skipping stones on the water in the late afternoon.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is navigating through an office hallway, casually observing meeting rooms as they pass by.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is watching a movie in a theater, enjoying popcorn while an action film plays.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is using a dryer to dry their clothes.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 5\n  ## Tool Calling:\n [{\"name\": \"set_timer\", \"description\": \"Set a timer for a specific duration.\", \"parameters\": {\"duration\": \"50 minutes\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is considering purchasing vitamin D supplements, potentially to improve bone health.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": true\n  \"Proactive score\": 4\n  ## Tool Calling:\n [{\"name\": \"get_medical_knowledge\", \"description\": \"Get medical expert knowledge from the up-to-date medical knowledge database.\", \"parameters\": {\"query\": \"benefits and recommended dosages of vitamin D\"}}, {\"name\": \"wikipedia_search\", \"description\": \"Tool that searches the Wikipedia API. Useful for when you need to answer general questions about people, places, companies, facts, historical events, or other subjects.\", \"parameters\": {\"query\": \"Vitamin D\"}}]\n"
  },
  {
    "instruction": "You are a proactive LLM agent. You will receive both sensory and persona contexts. The sensory contexts are captured by the multi-modal sensors on the user\u2019s wearable devices, such as smart glasses and earphone. Persona context is the personal information like identity and preference. Based on these contexts, you need to generate a thought and determine whether to initiate a proactive service for the user or not. Only propose assistance when you fully understand the user's actions. When generating the response, consider whether you need to call external tools to complete the task. The following are the tool names and their arguments. Please only select tools from the specified tool sets and make sure to use the correct format for their arguments\n\n## Tool set:\nfunctions = {\n    \"get_city_weather\": arguments: (city, time),\n    \"get_current_datetime()\": arguments: None,\n    \"get_current_gps_coordinates\": arguments: None,\n    \"wikipedia_search\": arguments: query,\n    \"google_search\": arguments: query,\n    \"check_agenda_time_conflict\": arguments: time,\n    \"get_online_product_price\": arguments: product_name,\n    \"get_health_data\": arguments: None,\n    \"get_medical_knowledge\": arguments: query,\n    \"vllm\": arguments: (prompt, image_path),\n    \"google_map\": arguments: (current_location, destination),\n    \"book_uber\": arguments: (current_location, destination),\n    \"play_music\": arguments: None,\n    \"add_to_agenda\": arguments: (event, time),\n    \"check_bus_schedule\": arguments: bus_stop,\n    \"set_timer\": arguments: duration,\n    \"search_rednote\": arguments: query,\n    }\n\nNow you will receive the sensory and persona contexts.",
    "input": "Sensory Context: \nThe user is engaged in a meditation session at home.\n",
    "output": " ## Proactive Predictions\n  \"Proactive index\": false\n  \"Proactive score\": 1\n  ## Tool Calling:\n None\n"
  }
]